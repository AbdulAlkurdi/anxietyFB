{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fb testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pickle\n",
    "import dask as pd\n",
    "import pandas as pd_old\n",
    "import warnings\n",
    "import utils\n",
    "import heartpy as hp\n",
    "from ECG_feature_extractor_1001 import *\n",
    "# import time \n",
    "import time\n",
    "from datetime import datetime\n",
    "from biosppy.signals import ecg\n",
    "from feature_extraction import SubjectData, compute_features, get_samples, combine_files\n",
    "\n",
    "# To ignore all warnings:\n",
    "warnings.filterwarnings(\"ignore\", module=\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_IN_SECONDS = 60\n",
    "stride = 1\n",
    "label_dict = {'baseline': 1, 'stress': 2, 'amusement': 0}\n",
    "int_to_label = {1: 'baseline', 2: 'stress', 0: 'amusement'}\n",
    "feat_names = None\n",
    "loadPath = '../data/WESAD'\n",
    "savePath = '../data/GN-WESAD'\n",
    "subject_feature_path = '/subject_feats'\n",
    "\n",
    "n_samples = 10\n",
    "subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "snrs = [0.0001, 0.001, 0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6]  # 0.00001,\n",
    "fb_model_list = ['DT', 'RF', 'LDA', 'KNN', 'AdaBoost', 'SVM']\n",
    "\n",
    "if not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "if not os.path.exists(savePath + subject_feature_path):\n",
    "    os.makedirs(savePath + subject_feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processing_status(snrs, subject_ids, onedrive, n_samples=10):\n",
    "    # bads are the ones that do not have the gaussian-modified data.\n",
    "    bads = []\n",
    "    bad_snrs = []\n",
    "    bad_subjects = []\n",
    "    bad_ns = []\n",
    "    completed_snrs = []\n",
    "    for n_i in range(n_samples):\n",
    "        for snr in snrs:\n",
    "            for subject_id in subject_ids:\n",
    "                # print(snr)\n",
    "\n",
    "                # print(f'{onedrive}/n_{n_i}/snr_{snr}/S{subject_id}/{a}')\n",
    "                try:\n",
    "                    a = os.listdir(f'{onedrive}/n_{n_i}/snr_{str(snr)}/S{subject_id}')\n",
    "                    a[0]\n",
    "                    completed_snrs.append(snr)\n",
    "                except:\n",
    "                    bads.append(f'n_{n_i}/snr_{snr}/S{subject_id}')\n",
    "                    bad_snrs.append(snr)\n",
    "                    bad_subjects.append(subject_id)\n",
    "                    bad_ns.append(n_i)\n",
    "\n",
    "    bad_snrs = sorted(set(bad_snrs))\n",
    "    bad_subjects = sorted(set(bad_subjects))\n",
    "    bad_ns = sorted(set(bad_ns))\n",
    "    completed_snrs = sorted(set(completed_snrs))\n",
    "    # printing after checking\n",
    "    print(f'completed snrs :{completed_snrs}')\n",
    "    print(f'incomplete snrs :{bad_snrs}')\n",
    "\n",
    "\n",
    "get_processing_status(snrs, subject_ids, onedrive, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "\n",
    "for each_dataset in dataset_list:\n",
    "    for snr in snrs:\n",
    "        for model in fb_model_list:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "savePath = 'C:/Users/alkurdi/Downloads/WESAD/GN-WESAD'\n",
    "n_samples = [9]\n",
    "subject_ids = [2]\n",
    "snrs = [0.01]\n",
    "for n_i in n_samples:\n",
    "    if not os.path.exists(savePath + '/n_' + str(n_i)):\n",
    "        os.makedirs(savePath + '/n_' + str(n_i))\n",
    "    for snr in snrs:\n",
    "        if not os.path.exists(savePath + '/n_' + str(n_i) + '/snr_' + str(snr)):\n",
    "            os.makedirs(savePath + '/n_' + str(n_i) + '/snr_' + str(snr))\n",
    "        for subject_id in subject_ids:\n",
    "            if not os.path.exists(\n",
    "                savePath\n",
    "                + '/n_'\n",
    "                + str(n_i)\n",
    "                + '/snr_'\n",
    "                + str(snr)\n",
    "                + '/S'\n",
    "                + str(subject_id)\n",
    "            ):\n",
    "                os.makedirs(\n",
    "                    savePath\n",
    "                    + '/n_'\n",
    "                    + str(n_i)\n",
    "                    + '/snr_'\n",
    "                    + str(snr)\n",
    "                    + '/S'\n",
    "                    + str(subject_id)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{savePath}/n_{n_i}')\n",
    "print(os.path.isdir(f'{savePath}/n_{n_i}'))\n",
    "print(os.listdir(f'{savePath}/n_{n_i}'))\n",
    "print(\n",
    "    os.path.isdir(\n",
    "        f'{savePath}/n_{n_i}/snr_{snr}/fixed_resampled140hz_S{subject_id}.pkl'\n",
    "    )\n",
    ")\n",
    "\n",
    "with open(f'{savePath}/n_{n_i}/poop.txt', 'w') as f:\n",
    "    f.write('poop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table = pd_old.DataFrame(columns=['SNR', 'Accuracy', 'F1-Score', 'dataset'])\n",
    "results_table.loc[str('SVM')] = pd_old.Series(\n",
    "    {'SNR': 1, 'Accuracy': 5, 'F1 Score': 2, 'dataset': 'WESAD'}\n",
    ")\n",
    "results_table.loc[str('RF')] = pd_old.Series(\n",
    "    {'SNR': 1, 'Accuracy': 5, 'F1 Score': 2, 'dataset': 'WESAD'}\n",
    ")\n",
    "'''\n",
    "fb_model_list = ['SVM', 'RF']\n",
    "for model in fb_model_list:\n",
    "    for i in range(len(snrs)):\n",
    "        results_table.loc[str(model) + str(snrs[i])] = pd.Series({'SNR':snrs[i], 'Accuracy':svm_accuracy[i], 'F1 Score':2, 'dataset':'WESAD'})\n",
    "'''\n",
    "display(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "ecg_biosppy = ecg\n",
    "ecg = None\n",
    "fs_ecg = 700\n",
    "fs_ppg = 64\n",
    "subject_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = SubjectData(main_path=loadPath, subject_number=subject_id)\n",
    "data_dict = subject.get_wrist_and_chest_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.time()\n",
    "BS_signal_analysis3, pack3, ecg_out3 = analyze_ecg(ecg, fs_ecg)\n",
    "print('analyze_ecg execution time is ', now - time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing for PPG\n",
    "\n",
    "now = datetime.now()\n",
    "pack, ppg, RR, time_dict = freq_ratio(ppg, fs_ppg, method='welch', factor=1)\n",
    "print('freq_ratio execution time is ', now - time.time())\n",
    "\n",
    "now = datetime.now()\n",
    "pack, ppg, time_dict = freq_ratio_hybrid(ppg, fs_ppg, method='welch', factor=1)\n",
    "print('freq_ratio_hybrid execution time is ', now - time.time())\n",
    "\n",
    "now = datetime.now()\n",
    "BS_signal_analysis, pack, ppg_out = analyze_ecg(ppg, fs_ppg)\n",
    "print('analyze_ecg execution time is ', now - time.time())\n",
    "\n",
    "now = datetime.now()\n",
    "wd, m = hp.process(ppg, fs_ppg)\n",
    "print('hp.process execution time is ', now - time.time())\n",
    "\n",
    "now = datetime.now()\n",
    "pack, ppg, RR = freq_ratio_fast(ppg, fs_ppg, method='welch', factor=1)\n",
    "print('freq_ratio_fast execution time is ', now - time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_noiZ_files(subject_ids)\n",
    "# took 19m 30s to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging\n",
    "\n",
    "now = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "def process_subject_file(snr, n_i, s):\n",
    "    file_path = f'{savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/S{s}_feats.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path, index_col=0)\n",
    "        df['subject'] = s\n",
    "        return df\n",
    "    return None\n",
    "\n",
    "\n",
    "def combine_noiZ_files(subjects):\n",
    "    now = datetime.now().strftime('%Y-%m-%d')\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO, filename=now + '-combine.log', filemode='w', force=True\n",
    "    )\n",
    "\n",
    "    for snr in snrs:\n",
    "        for n_i in range(n_samples):\n",
    "            # Parallelize file reading\n",
    "            with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "                futures = [\n",
    "                    executor.submit(process_subject_file, snr, n_i, s) for s in subjects\n",
    "                ]\n",
    "                df_list = [\n",
    "                    future.result() for future in futures if future.result() is not None\n",
    "                ]\n",
    "\n",
    "            if df_list:\n",
    "                df = pd.concat(df_list)\n",
    "                df['label'] = df[['0', '1', '2']].idxmax(axis=1)\n",
    "                df.drop(['0', '1', '2'], axis=1, inplace=True)\n",
    "                df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                df.to_csv(\n",
    "                    f'{savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/{now}_feats_filt.csv'\n",
    "                )\n",
    "                logging.info('-' * 20)\n",
    "                logging.info(\n",
    "                    f'Saved file to: {savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/{now}_feats_filt.csv'\n",
    "                )\n",
    "\n",
    "                counts = df['label'].value_counts()\n",
    "                logging.info('Number of samples per class:')\n",
    "                logging.info(\n",
    "                    'baseline: {0[1]}; stress: {1[1]}; amusement: {2[1]} '.format(\n",
    "                        *list(zip(counts.index, counts.values))\n",
    "                    )\n",
    "                )\n",
    "    logging.info('all done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_i = 5\n",
    "s = 2\n",
    "snr = 0.6\n",
    "df = pd_old.read_csv(\n",
    "    f'{savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/S{subject_id}_feats.csv',\n",
    "    index_col=0,\n",
    ")\n",
    "df['subject'] = s\n",
    "# df_list.append(df)\n",
    "# f = pd_old.concat(df_list)\n",
    "df['label'] = (df['0'].astype(str) + df['1'].astype(str) + df['2'].astype(str)).apply(\n",
    "    lambda x: x.index('1')\n",
    ")\n",
    "df.drop(['0', '1', '2'], axis=1, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "counts = df['label'].value_counts()\n",
    "print('Number of samples per class:')\n",
    "print(\n",
    "    'baseline: {0[1]}; stress: {1[1]}; amusement: {2[1]} '.format(\n",
    "        *list(zip(counts.index, counts.values))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_n_reduce(path):\n",
    "    # print(os.listdir(path))\n",
    "    df = pd_old.read_csv(path, index_col=0)\n",
    "    print('len of df ', len(df))\n",
    "    pd_old.set_option('display.max_columns', None)\n",
    "    # We want to drop columns in df that are not in RADWear to match modalities.\n",
    "    # drop _c columns\n",
    "    columns_list = df.columns.tolist()\n",
    "    drop_list = []\n",
    "    # df.drop(columns=['Resp_C'])\n",
    "    for column in columns_list:\n",
    "        if (\n",
    "            'EMG' in column\n",
    "            or 'EDA_C' in column\n",
    "            or 'Temp_C' in column\n",
    "            or 'TEMP_C' in column\n",
    "            or 'SCR_C' in column\n",
    "            or 'SCL_C' in column\n",
    "        ):\n",
    "            drop_list.append(column)\n",
    "\n",
    "    reduced_df = df.drop(columns=drop_list)\n",
    "    df = reduced_df\n",
    "    print('len of reduced df ', len(df))\n",
    "    return df\n",
    "\n",
    "\n",
    "def gn_wesad_path(n_i, snr):\n",
    "    loadPath = '../data/GN-WESAD'\n",
    "    return (\n",
    "        f'{loadPath}/n_{n_i}/snr_{snr}{subject_feature_path}/{gn_wesad_day}_feats2.csv'\n",
    "    )\n",
    "\n",
    "\n",
    "gn_wesad_day = '2023-11-13'\n",
    "matrix = np.zeros((len(snrs), n_samples))\n",
    "\n",
    "for n_i in range(n_samples):\n",
    "    for i, snr in enumerate(snrs):\n",
    "        print(f'for {n_i} and {snr} number {i}: ')\n",
    "        file_path = gn_wesad_path(n_i, snr)\n",
    "        df = read_n_reduce(file_path)\n",
    "        matrix[i][n_i] = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'data/GN-WESAD/n_0/snr_0.0001/subject_feats/2023-11-12_feats_filt.csv'\n",
    "'data/GN-WESAD/n_0/snr_0.001/subject_feats/2023-11-12_feats_filt.csv'\n",
    "loadPath = '../data/GN-WESAD'\n",
    "# display(os.listdir(f'{loadPath}/n_{n_i}/snr_{snr}{subject_feature_path}'))\n",
    "snr0001 = pd_old.read_csv(\n",
    "    '../data/GN-WESAD/n_0/snr_0.0001/subject_feats/2023-11-13_feats2.csv', index_col=0\n",
    ")\n",
    "snr001 = pd_old.read_csv(\n",
    "    '../data/GN-WESAD/n_0/snr_0.001/subject_feats/2023-11-13_feats2.csv', index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'SNR': [0.6] * 10,\n",
    "        'Accuracy': [\n",
    "            0.940639,\n",
    "            0.968134,\n",
    "            0.964939,\n",
    "            0.940909,\n",
    "            0.937785,\n",
    "            0.923780,\n",
    "            0.942337,\n",
    "            0.960486,\n",
    "            0.952816,\n",
    "            0.925645,\n",
    "        ],\n",
    "        'F1 Score': [\n",
    "            0.940639,\n",
    "            0.968134,\n",
    "            0.964939,\n",
    "            0.940909,\n",
    "            0.937785,\n",
    "            0.923780,\n",
    "            0.942337,\n",
    "            0.960486,\n",
    "            0.952816,\n",
    "            0.925645,\n",
    "        ],\n",
    "        'dataset': ['GN-WESAD'] * 10,\n",
    "        'n_i': list(range(10)),\n",
    "        'n': [10] * 10,\n",
    "        'noise gen function': ['Gaussian Noise'] * 10,\n",
    "        'Precision': [\n",
    "            0.940639,\n",
    "            0.968134,\n",
    "            0.964939,\n",
    "            0.940909,\n",
    "            0.937785,\n",
    "            0.923780,\n",
    "            0.942337,\n",
    "            0.960486,\n",
    "            0.952816,\n",
    "            0.925645,\n",
    "        ],\n",
    "        'Recall': [\n",
    "            0.940639,\n",
    "            0.968134,\n",
    "            0.964939,\n",
    "            0.940909,\n",
    "            0.937785,\n",
    "            0.923780,\n",
    "            0.942337,\n",
    "            0.960486,\n",
    "            0.952816,\n",
    "            0.925645,\n",
    "        ],\n",
    "        'Model': ['DT'] * 10,\n",
    "    }\n",
    ")\n",
    "series = pd.Series(\n",
    "    {\n",
    "        'SNR': 0.600000,\n",
    "        'Accuracy': 0.945747,\n",
    "        'F1 Score': 0.945747,\n",
    "        'n_i': 4.500000,\n",
    "        'n': 10.000000,\n",
    "        'Precision': 0.945747,\n",
    "        'Recall': 0.945747,\n",
    "    },\n",
    "    name='SNR 0.6 Model DT mean',\n",
    ")\n",
    "\n",
    "print(set(df.columns))\n",
    "print(set(series.index))\n",
    "missing_columns = set(df.columns) - set(series.index)\n",
    "print(missing_columns)\n",
    "for col in missing_columns:\n",
    "    # You can assign a specific value or use a value from the DataFrame\n",
    "    # Here, I'm using the first row's value as an example\n",
    "    # print(col)\n",
    "    # print(df[col].iloc[0])\n",
    "\n",
    "    series[col] = df[col].iloc[0]\n",
    "    # print(series[col])\n",
    "\n",
    "# print(series)\n",
    "\n",
    "series_df2 = series.to_frame().T\n",
    "display(series_df2)\n",
    "df_combined2 = pd.concat([df, series_df2])\n",
    "display(df_combined2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabulate and plot\n",
    "\n",
    "with open('../data/GN-WESAD/cm_cr_dict.pickle', 'rb') as handle:\n",
    "    GN_cm_cr_dict = pickle.load(handle)\n",
    "with open('../data/WESAD/cm_cr_dict.pickle', 'rb') as handle:\n",
    "    WESAD_cm_cr_dict = pickle.load(handle)\n",
    "wesad_acc = pd.read_csv(\n",
    "    '../data/WESAD/wesad_models_results-win60stride1_wcm_wcr.csv', index_col=0\n",
    ")\n",
    "display(wesad_acc)\n",
    "# combined_results = pd.concat([WESAD_model_results, GN_model_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/GN-WESAD/cm_cr_dict.pickle', 'rb') as handle:\n",
    "    GN_cm_cr_dict = pickle.load(handle)\n",
    "tgt_file = '../data/GN-WESAD/GN_wesad_models_results_wbinaryf1.csv'\n",
    "gn_wesad_acc = pd.read_csv(tgt_file, index_col=0)\n",
    "# gn_wesad_acc['Binary F1'] = None\n",
    "print(gn_wesad_acc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/GN-WESAD/cm_cr_dict.pickle', 'rb') as handle:\n",
    "    GN_cm_cr_dict = pickle.load(handle)\n",
    "tgt_file = '../data/GN-WESAD/GN_wesad_models_results_wcm_wcr.csv'\n",
    "gn_wesad_acc = pd.read_csv(tgt_file, index_col=0)\n",
    "gn_wesad_acc['Binary F1'] = None\n",
    "\n",
    "for i, classification_report in enumerate(GN_cm_cr_dict['cr']):\n",
    "    cr = classification_report['Classification Report']\n",
    "    print(classification_report['id'][2], fb_model_list[i % 6])\n",
    "    # print(cr)\n",
    "    # print(i//5)\n",
    "    binary_f1_score = calculate_binary_metrics(cr)\n",
    "    # print(classification_report['id'])\n",
    "    if binary_f1_score is not None:\n",
    "        # print(\"Binary F1 Score for \", fb_model_list[i], \" :\\t\\t\", binary_f1_score)\n",
    "        insta_acc = wesad_acc['Accuracy'][i % 6]\n",
    "        insta_f1 = wesad_acc['F1 Score'][i % 6]\n",
    "        secret_df = pd.concat(\n",
    "            [\n",
    "                secret_df,\n",
    "                pd.Series(\n",
    "                    {\n",
    "                        'Model': fb_model_list[i % 6],\n",
    "                        'Binary F1 Score': binary_f1_score,\n",
    "                        'SNR': classification_report['id'][0],\n",
    "                        'n': classification_report['id'][1],\n",
    "                        'Model': classification_report['id'][2],\n",
    "                    }\n",
    "                )\n",
    "                .to_frame()\n",
    "                .T,\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        # print(f'my calc acc {insta_acc}, calc f1 {insta_f1}')\n",
    "        # display(wesad_acc_test[wesad_acc_test['Model'] == fb_model_list[i]])#['binary f1'] = binary_f1_score\n",
    "        # wesad_acc_test[wesad_acc_test['Model'] == fb_model_list[i]]['binary f1'] = binary_f1_score\n",
    "        # wesad_acc_test[wesad_acc_test['Model'] == fb_model_list[i]]['binary acc'] = insta_acc\n",
    "        # print(fb_model_list[i])\n",
    "        gn_wesad_acc.loc[\n",
    "            gn_wesad_acc['Model'] == fb_model_list[i % 6], 'Binary f1'\n",
    "        ] = binary_f1_score\n",
    "        # print(gn_wesad_acc.loc[gn_wesad_acc['Model'] == fb_model_list[i], 'binary f1'])\n",
    "\n",
    "    else:\n",
    "        print(\"Could not extract metrics from the report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "wesad_acc_test = wesad_acc.copy()\n",
    "wesad_acc_test['Binary F1'] = None\n",
    "\n",
    "\n",
    "def extract_metrics(report):\n",
    "    # Regular expression to find numeric values\n",
    "    regex = r\"\\s+1\\s+([\\d\\.]+)\\s+([\\d\\.]+)\\s+([\\d\\.]+)\"\n",
    "\n",
    "    # Search for the pattern\n",
    "    match = re.search(regex, report)\n",
    "    # print(match)\n",
    "    if match:\n",
    "        precision = float(match.group(1))\n",
    "        recall = float(match.group(2))\n",
    "        f1_score = float(match.group(3))\n",
    "        return precision, recall, f1_score\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def calculate_binary_metrics(report):\n",
    "    precision, recall, f1_score = extract_metrics(report)\n",
    "\n",
    "    if precision is not None and recall is not None:\n",
    "        # Calculate binary F1 score for class 1\n",
    "        binary_f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        return binary_f1_score\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# classification_report =\n",
    "# Extract and calculate binary F1 score\n",
    "fb_model_counter = fb_model_list\n",
    "\n",
    "\n",
    "secret_df = pd.DataFrame()\n",
    "\n",
    "for i, classification_report in enumerate(WESAD_cm_cr_dict['cr']):\n",
    "    cr = classification_report['Classification Report']\n",
    "    binary_f1_score = calculate_binary_metrics(cr)\n",
    "    # print(classification_report['id'])\n",
    "    if binary_f1_score is not None:\n",
    "        print(\"Binary F1 Score for \", fb_model_list[i], \" :\\t\\t\", binary_f1_score)\n",
    "        insta_acc = wesad_acc['Accuracy'][i]\n",
    "        insta_f1 = wesad_acc['F1 Score'][i]\n",
    "        secret_df = pd.concat(\n",
    "            [\n",
    "                secret_df,\n",
    "                pd.Series(\n",
    "                    {\n",
    "                        'Model': fb_model_list[i],\n",
    "                        'Binary F1 Score': binary_f1_score,\n",
    "                        'SNR': classification_report['id'][0],\n",
    "                        'n': classification_report['id'][1],\n",
    "                        'Model': classification_report['id'][2],\n",
    "                    }\n",
    "                )\n",
    "                .to_frame()\n",
    "                .T,\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        # print(f'my calc acc {insta_acc}, calc f1 {insta_f1}')\n",
    "        # display(wesad_acc_test[wesad_acc_test['Model'] == fb_model_list[i]])#['binary f1'] = binary_f1_score\n",
    "        # wesad_acc_test[wesad_acc_test['Model'] == fb_model_list[i]]['binary f1'] = binary_f1_score\n",
    "        # wesad_acc_test[wesad_acc_test['Model'] == fb_model_list[i]]['binary acc'] = insta_acc\n",
    "        # print(fb_model_list[i])\n",
    "        wesad_acc_test.loc[\n",
    "            wesad_acc_test['Model'] == fb_model_list[i], 'binary f1'\n",
    "        ] = binary_f1_score\n",
    "        print(\n",
    "            wesad_acc_test.loc[wesad_acc_test['Model'] == fb_model_list[i], 'binary f1']\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(\"Could not extract metrics from the report.\")\n",
    "display(secret_df)\n",
    "display(wesad_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([wesad_acc, secret_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_n_reduce(path):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    # We want to drop columns in df that are not in RADWear to match modalities.\n",
    "    # drop _c columns\n",
    "    columns_list = df.columns.tolist()\n",
    "    drop_list = []\n",
    "    # df.drop(columns=['Resp_C'])\n",
    "    for column in columns_list:\n",
    "        if (\n",
    "            'EMG' in column\n",
    "            or 'EDA_C' in column\n",
    "            or 'Temp_C' in column\n",
    "            or 'TEMP_C' in column\n",
    "            or 'SCR_C' in column\n",
    "            or 'SCL_C' in column\n",
    "        ):\n",
    "            drop_list.append(column)\n",
    "\n",
    "    reduced_df = df.drop(columns=drop_list)\n",
    "    df = reduced_df\n",
    "    return df\n",
    "\n",
    "\n",
    "print(os.listdir('../data/WESAD'))\n",
    "df = read_n_reduce('../data/WESAD//subject_feats/oct5_feats4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# display(the_splits[0])\n",
    "X_train, X_test, y_train, y_test = the_splits\n",
    "clf = SVC(kernel='linear', C=1, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_out = clf.predict(X_test)\n",
    "\n",
    "svm_accuracy = accuracy_score(y_test, y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for snr in snrs:\n",
    "    for n_i in range(n_samples):\n",
    "        tgt = f'../data/GN-WESAD/n_{n_i}/snr_{snr}{subject_feature_path}/{gn_wesad_day}_feats2.csv'\n",
    "        print(f'df {snr} n {n_i} shape is {(pd.read_csv(tgt, index_col=0)).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wesad loaded in  225.43 s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "subject_id = 2\n",
    "snr = 0.01\n",
    "n_i = 0\n",
    "\n",
    "\n",
    "wesad_path = '/mnt/d/Users/alkurdi/data/WESAD'\n",
    "#freshwesad_path = '/mnt/d/Users/alkurdi/data/freshWESAD'\n",
    "downloaddwesad_path = '/mnt/c/Users/alkurdi/Desktop/Vansh/data/WESAD'\n",
    "gn_path = '/mnt/d/Users/alkurdi/data/GN-WESAD'\n",
    "\n",
    "sesh_path = '/n_' + str(n_i) + '/snr_' + str(snr) + '/S' + str(subject_id)\n",
    "load_gn_path = gn_path + sesh_path + '/S' + str(subject_id) + '.pkl'\n",
    "#load_dw_path = (\n",
    "#    downloaddwesad_path + '/S' + str(subject_id) + '/S' + str(subject_id) + '.pkl'\n",
    "#)\n",
    "\n",
    "load_ws_path = wesad_path + '/S' + str(subject_id) + '/S' + str(subject_id) + '.pkl'\n",
    "\n",
    "# ws_df = pd.read_pickle(load_ws_path)\n",
    "\n",
    "# with open( load_ws_path, 'rb') as dest:\n",
    "#    ws_df = pickle.load(dest)\n",
    "\n",
    "now = time()\n",
    "'''\n",
    "with open(load_dw_path, 'rb') as file:\n",
    "    dw_df = pickle.load(file, encoding='latin1')\n",
    "print(\n",
    "    'c:\\ downloads wesad loaded w pickle.load in ', round(time() - now, 3), 's'\n",
    ")  # c:\\ downloads wesad loaded w pickle.load in  17.112 s\n",
    "'''\n",
    "'''\n",
    "now = time()\n",
    "with open(load_gn_path, 'rb') as file:\n",
    "    gn_df = pickle.load(file, encoding='latin1')\n",
    "print('gnwesad loaded in ', round(time() - now, 3), 's')\n",
    "\n",
    "\n",
    "now = time()\n",
    "#with open(load_freshws_path, 'rb') as file:\n",
    "#            freshws_df = pickle.load(file, encoding='latin1')\n",
    "print('d:\\ freshwesad loaded in ', round(time()-now,3),'s')  #d:\\ freshwesad loaded in  191.335 s\n",
    "\n",
    "now = time()\n",
    "dw_df = pd.read_pickle(load_dw_path)\n",
    "print('c:\\ downloads wesad loaded w pd.read_pickle in ', round(time()-now,3),'s') #c:\\ downloads wesad loaded w pd.read_pickle in  24.78 s\n",
    "'''\n",
    "\n",
    "#this is the one that fails\n",
    "#load_ws_path = wesad_path + '/S'+str(subject_id) + '/S'+str(subject_id)+'.pkl'\n",
    "now = time()\n",
    "with open(load_ws_path, 'rb') as file:\n",
    "            ws_df = pickle.load(file, encoding='latin1')\n",
    "print('wesad loaded in ', round(time()-now,3),'s')\n",
    "\n",
    "# fresh_df = pd.read_pickle()\n",
    "# wesad_path = '/mnt/c/Users/alkurdi/Desktop/Vansh/data/WESAD'\n",
    "# msg = f'starting  n_i: {n_i}; snr: {snr}, id: {subject_id}. iteration'\n",
    "# sesh_path = '/n_'+str(n_i)+'/snr_'+str(snr)+'/S'+str(subject_id)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ws.keys():  dict_keys(['signal', 'label', 'subject'])\n",
      "signal keys: dict_keys(['chest', 'wrist'])\n",
      "chest keys: dict_keys(['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'])\n",
      "wrist keys: dict_keys(['ACC', 'BVP', 'EDA', 'TEMP'])\n"
     ]
    }
   ],
   "source": [
    "print('ws.keys(): ',ws_df.keys())\n",
    "print(f'signal keys: {ws_df[\"signal\"].keys()}')\n",
    "print(f'chest keys: {ws_df[\"signal\"][\"chest\"].keys()}')\n",
    "print(f'wrist keys: {ws_df[\"signal\"][\"wrist\"].keys()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "\n",
    "print((ws_df['label']))\n",
    "numpy.array(ws_df['label'])\n",
    "print(type(ws_df[\"signal\"][\"wrist\"]['ACC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time()\n",
    "with open(\n",
    "    '/mnt/c/Users/alkurdi/Downloads/WESAD/GN-WESAD/n_0/snr_0.6/S17/fixed_resampled140hz_S17.pkl',\n",
    "    'rb',\n",
    ") as file:\n",
    "    resampled_gn = pickle.load(file, encoding='latin1')\n",
    "print('resampled_gn loaded in ', round(time() - now, 3), 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def my_counter(df, name=None):\n",
    "    i = 0\n",
    "    long_list = []\n",
    "    for i_first_layer in df.keys():\n",
    "        # print(i_first_layer, dw_df[i_first_layer])\n",
    "        if i_first_layer == 'label':\n",
    "            long_list = long_list + [*df[i_first_layer]]\n",
    "            i += len(df[i_first_layer])\n",
    "            print(f'{name}: length of {i_first_layer} is {len(df[i_first_layer]):,.0f}')\n",
    "        elif i_first_layer == 'signal':\n",
    "            for i_second_layer in df[i_first_layer].keys():\n",
    "                # print('part', i_second_layer)#, dw_df[i_first_layer][i_second_layer])\n",
    "\n",
    "                for i_third_layer in df[i_first_layer][i_second_layer].keys():\n",
    "                    sig_shape = np.shape(\n",
    "                        df[i_first_layer][i_second_layer][i_third_layer]\n",
    "                    )\n",
    "                    # print('part', i_second_layer, 'signal', i_third_layer, sig_shape)\n",
    "                    i += np.prod(sig_shape)\n",
    "                    long_list = long_list + [\n",
    "                        *df[i_first_layer][i_second_layer][i_third_layer].flatten()\n",
    "                    ]\n",
    "                    print(\n",
    "                        f'{name}: length of {i_third_layer} is {len(df[i_first_layer][i_second_layer][i_third_layer]):,.0f}'\n",
    "                    )\n",
    "        elif i_first_layer == 'subject':\n",
    "            pass\n",
    "        else:\n",
    "            long_list = long_list + [*df[i_first_layer].flatten()]\n",
    "            i += np.prod(np.shape(df[i_first_layer]))\n",
    "            print(f'{name}: length of {i_first_layer} is {len(df[i_first_layer]):,.0f}')\n",
    "    print('_' * 5)\n",
    "    print(f'total length of {name} df is {len(long_list):,.0f}')\n",
    "    print('_' * 25)\n",
    "\n",
    "\n",
    "my_counter(dw_df, name='dw_df')\n",
    "my_counter(gn_df, name='gs_df')\n",
    "my_counter(resampled_gn, name='resampled_gn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(os.getpid(), file=sys.stderr)\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import requests\n",
    "\n",
    "from subprocess import PIPE, Popen\n",
    "\n",
    "\n",
    "def get_cmd(pid):\n",
    "    with Popen(f\"ps -q {pid} -o comm=\", shell=True, stdout=PIPE) as p:\n",
    "        return p.communicate()[0]\n",
    "\n",
    "\n",
    "get_cmd(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_list = list(dw_df['signal']['chest'].items()) + list(\n",
    "    dw_df['signal']['wrist'].items()\n",
    ")\n",
    "a, b = zip(*long_list)\n",
    "tot_len = 0\n",
    "for i in list(b):\n",
    "    tot_len += len(i)\n",
    "print(f'total length wesad {tot_len:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/c/Users/alkurdi/Downloads/WESAD/GN-WESAD/n_0/snr_0.0001/S2'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 0, 0\n",
    "a, b = zip(*list(gn_df.items()))\n",
    "tot_len = 0\n",
    "for i in list(b):\n",
    "    tot_len += len(i)\n",
    "print(f'total length gn wesad {tot_len:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wesad_path = '/mnt/c/Users/alkurdi/data/WESAD'\n",
    "fresh_wesad_path = '/mnt/c/Users/alkurdi/Downloads/WESAD/WESAD'\n",
    "\n",
    "# start_time = time()\n",
    "id = 2\n",
    "sesh_path = fresh_wesad_path + '/S' + str(id) + '/S' + str(id) + '.pkl'\n",
    "\n",
    "ws_df = pd.read_pickle(sesh_path)\n",
    "# with open( sesh_path, 'rb') as dest:\n",
    "#        ws2_df = pickle.load(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_resampled_df = pd.read_pickle(\n",
    "    '/mnt/d/Users/alkurdi/data/GN-WESAD/n_0/snr_0.01/S17/fixed_resampled170hz64_S17.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('for resampled dataset: ')\n",
    "for key in fixed_resampled_df.keys():\n",
    "    print(\n",
    "        f'length of signal {key}: ', len(fixed_resampled_df['signal']['chest']['ECG'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('keys', ws_df.keys())\n",
    "print('keys', ws_df['signal'].keys())\n",
    "print('length of signal', len(ws_df['signal']['chest']['ECG']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fixed_resampled_df['signal']['chest']['ECG']) / len(ws_df['signal']['chest']['ECG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import signal\n",
    "from time import time\n",
    "import concurrent.futures\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import logging\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "snrs = [ 0.01,0.1,0.6 0.05,  0.3,0.1, 0.15, 0.2,0.0001, 0.001, 0.4, 0.5, 0.6] # this is what we ran #0.00001,\n",
    "n_samples = 0 #10\n",
    "n_i = n_samples\n",
    "snr1 = 0.01\n",
    "snr2 = 0.6\n",
    "subject_id = 17\n",
    "\n",
    "sesh_id =[n_i,snr1,subject_id]\n",
    "rt_pth = '/mnt/d/Users/alkurdi/data/GN-WESAD'\n",
    "start_time = time()\n",
    "onedrive = '/mnt/d/Users/alkurdi/OneDrive - University of Illinois - Urbana/data/GN-WESAD'\n",
    "\n",
    "#print(os.path.isfile(rt_pth + '/n_'+str(0)+'/snr_'+str(snr1)+ '/S'+str(17)+'/S'+str(17)+'.pkl'))\n",
    "sesh_path = rt_pth + '/n_'+str(0)+'/snr_'+str(0.0001)+ '/S'+str(2)+'/S'+str(2)+'.pkl'\n",
    "#drive_path = onedrive +  '/n_'+str(0)+'/snr_'+str(snr1)+ '/S'+str(subject_id)+'/S'+str(subject_id)+'.pkl'\n",
    "with open( sesh_path, 'rb') as dest:\n",
    "        ws1_df = pickle.load(dest) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_pth = '/mnt/d/Users/alkurdi/data/GN-WESAD'\n",
    "# start_time = time()\n",
    "id = 4\n",
    "sesh_path = (\n",
    "    rt_pth\n",
    "    + '/n_'\n",
    "    + str(1)\n",
    "    + '/snr_'\n",
    "    + str(0.001)\n",
    "    + '/S'\n",
    "    + str(id)\n",
    "    + '/S'\n",
    "    + str(id)\n",
    "    + '.pkl'\n",
    ")\n",
    "# drive_path = onedrive +  '/n_'+str(0)+'/snr_'+str(snr1)+ '/S'+str(subject_id)+'/S'+str(subject_id)+'.pkl'\n",
    "\n",
    "with open(sesh_path, 'rb') as dest:\n",
    "    ws2_df = pickle.load(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('for resampled dataset: ')\n",
    "for key in ws2_df.keys():\n",
    "    print('key', key)\n",
    "    # print(f'length of chest ignal {key}: ', len(ws2_df['signal']['chest']['ECG']))\n",
    "    # print(f'length of chest ignal {key}: ', len(ws2_df['signal']['chest']['ECG']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "# snrs = [ 0.01,0.1,0.6 0.05,  0.3,0.1, 0.15, 0.2,0.0001, 0.001, 0.4, 0.5, 0.6] # this is what we ran #0.00001,\n",
    "snrs = [0.01, 0.05, 0.3]  # ,0.1, 0.15, 0.2,0.0001, 0.001, 0.4, 0.5, 0.6]\n",
    "n_i = [0, 1, 3, 4]  # next is [5, 6, 7] [8, 9, 10]\n",
    "\n",
    "\n",
    "from_path = '/mnt/c/Users/alkurdi/Downloads/WESAD/GN-WESAD'\n",
    "to_path = '/mnt/d/Users/alkurdi/data/GN-WESAD'\n",
    "\n",
    "\n",
    "for n in n_i:\n",
    "    for snr in snrs:\n",
    "        for s in subject_ids:\n",
    "            sesh_path = '/n_' + str(n_i) + '/snr_' + str(snr) + '/S' + str(subject_id)\n",
    "\n",
    "            xact_from_path = from_path + sesh_path\n",
    "            xact_to_path = to_path + sesh_path\n",
    "\n",
    "            os.system(f'cp -r {from_path} {to_path}')\n",
    "            print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for 5 seconds\n",
    "from time import sleep\n",
    "\n",
    "from_path = '/mnt/c/Users/alkurdi/Downloads/WESAD'\n",
    "poop = 'poop'\n",
    "\n",
    "with open(from_path + '/poop.txt', 'w') as f:\n",
    "    f.write(poop)\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "# os.system(f'{from_path}/poop>poop.txt')\n",
    "\n",
    "to_path = '/mnt/d/Users/alkurdi/data/'\n",
    "\n",
    "os.system(f'mv {from_path}/poop.txt {to_path}/poop.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RADWear Calibration fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'modified by abdul alkurdi; 10/05/2023'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# import cudf\n",
    "import pickle, sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.signal import correlate\n",
    "\n",
    "# import cupy as cp\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal, stats\n",
    "\n",
    "# import peakutils, wfdb, pywt\n",
    "import csv\n",
    "import os, statistics\n",
    "from datetime import datetime\n",
    "\n",
    "# import heartpy as hp\n",
    "import json\n",
    "\n",
    "# import neurokit2 as nk\n",
    "\n",
    "# add path to sys\n",
    "sys.path.append('../')\n",
    "from syncfcns import *\n",
    "from process_redcap import process_redcap\n",
    "calib_dict = {'meditation': 1, 'cpt': 2, 'baseline': 0}\n",
    "rot_anx_dict = {'calibration': 0, 'LA': 1, 'HA': 2}\n",
    "fs_hx = {'ECG': 256, 'ACC': 64, 'BR': 1, 'RESP': 128, 'label': 256} # for RADWear, Wear\n",
    "fs_e4 = {'ACC': 32, 'BVP': 64, 'EDA': 4, 'TEMP': 4} # for RADWear, Wear\n",
    "\n",
    "radwear_path = '/mnt/c/Users/alkurdi/Desktop/Vansh/data/RADWear/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 16\n",
    "p_path = radwear_path + 'Participant ' + str(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(radwear_path + 'all_p_metadata.json', 'rb') as f:\n",
    "    all_p_metadata = json.load(f)\n",
    "\n",
    "incomplete = [16]\n",
    "\n",
    "\n",
    "for p in incomplete:\n",
    "    p_path = radwear_path + 'Participant ' + str(p)\n",
    "    p_df = pd.DataFrame()\n",
    "\n",
    "    # check if file exist\n",
    "    a = (\n",
    "        'available.'\n",
    "        if os.path.isfile(p_path + '/p_' + str(p) + '.pkl')\n",
    "        else ' not available.'\n",
    "    )\n",
    "    print('pickle file for participant ' + str(p) + ' is ' + a)\n",
    "\n",
    "    # all_p[p] = p_data ## this takes too much memory so i will just load each p when needed\n",
    "    if not (os.path.isfile(radwear_path + 'p_' + str(p) + '.pkl')) or True:\n",
    "        with open(p_path + '/p_' + str(p) + '.pkl', 'rb') as f:\n",
    "            p_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redcap_path = radwear_path + 'REDCap responses/'\n",
    "with open(radwear_path + 'all_p_metadata.json', 'rb') as f:\n",
    "    all_p_metadata = json.load(f)\n",
    "# load all participant redcap data\n",
    "redcap_calib_dict = pd.read_pickle(\n",
    "    radwear_path + '/REDCap responses/redcap_calib_dict.pkl'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "e4sn = all_p_metadata[str(p)]['e4sn']\n",
    "calibration_files = all_p_metadata[str(p)]['calibration']\n",
    "p_calib = {}\n",
    "\n",
    "# load calibration data\n",
    "e4_num = all_p_metadata[str(p)]['e4sn'] + '_' + all_p_metadata[str(p)]['calibration'][0]\n",
    "hx_num = str(all_p_metadata[str(p)]['calibration'][1])\n",
    "p_calib[p] = read_sync_return(p_path, e4_num, hx_num)\n",
    "p_calib[p]['rot_label'] = rot_anx_dict['calibration'] * np.ones(len(p_calib[p]['ECG'])) # add label to designate calibration segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in p_calib[p]:\n",
    "    print(key,(p_calib[p][key]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radwear_path = '/mnt/c/Users/alkurdi/Desktop/Vansh/data/RADWear/'\n",
    "redcap_path = radwear_path + 'REDCap responses/'\n",
    "print(os.listdir(redcap_path))\n",
    "#redcap_df_2nd.pkl\n",
    "with open(redcap_path + 'redcap_dict_1st.pkl', 'rb') as f:\n",
    "    redcap_dict_1st = pickle.load(f)\n",
    "with open(redcap_path + 'redcap_df_2nd.pkl', 'rb') as f:\n",
    "    redcap_df_2nd = pickle.load(f)\n",
    "#redcap_dict_1st.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(redcap_dict_1st[16])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redcap_df_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "print('hi')\n",
    "import os\n",
    "import csv\n",
    "os.listdir()\n",
    "\n",
    "with open('poop.txt', 'rb') as f:\n",
    "    poop = csv.reader(f)\n",
    "    for i in poop:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/d/Users/alkurdi/data/WESAD/cm_cr_dict.pickle', 'rb') as handle:\n",
    "    WESAD_cm_cr_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 6, 7}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/mnt/d/Users/alkurdi/data/WESAD/S2/S2.pkl', 'rb') as f:\n",
    "    s2 = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "set(s2['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.sys.path.append('/mnt/d/Users/alkurdi/anxietyE2E/')\n",
    "#print(os.listdir('/mnt/d/Users/alkurdi/data/E2Epreprocessed/WESAD'))\n",
    "with open('/mnt/d/Users/alkurdi/data/E2Epreprocessed/WESAD/y_2.pkl', 'rb') as f:\n",
    "    y2 = pickle.load(f)\n",
    "with open('/mnt/d/Users/alkurdi/data/E2Epreprocessed/WESAD/x_2_5.pkl', 'rb') as f:\n",
    "    x_2_5 = pickle.load(f)\n",
    "with open('/mnt/d/Users/alkurdi/data/E2Epreprocessed/WESAD/x_2_4.pkl', 'rb') as f:\n",
    "    x_2_4 = pickle.load(f)\n",
    "with open('/mnt/d/Users/alkurdi/data/E2Epreprocessed/WESAD/x_2_3.pkl', 'rb') as f:\n",
    "    x_2_3 = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_2_3.data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1bf4ddc400>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(s2['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1484700"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s2['label'][(s2['label']==2) | (s2['label']==3) | (s2['label']==1) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      " [[101   3   0]\n",
      " [  2 387   0]\n",
      " [  0   0 178]]\n",
      "confusion matrix\n",
      " [[ 46  56   2]\n",
      " [  0 388   1]\n",
      " [  0   1 177]]\n",
      "confusion matrix\n",
      " [[ 84  17   3]\n",
      " [ 21 366   2]\n",
      " [  2   0 176]]\n",
      "confusion matrix\n",
      " [[ 88  12   4]\n",
      " [ 13 373   3]\n",
      " [  1   7 170]]\n",
      "confusion matrix\n",
      " [[ 38  66   0]\n",
      " [ 49 340   0]\n",
      " [  0  52 126]]\n",
      "confusion matrix\n",
      " [[ 91  13   0]\n",
      " [ 18 370   1]\n",
      " [  0   1 177]]\n"
     ]
    }
   ],
   "source": [
    "#%pprint\n",
    "#from pprint import pprint as print\n",
    "\n",
    "#print(WESAD_cm_cr_dict['cr'])\n",
    "\n",
    "import json\n",
    "#ling = json.dumps(,sort_keys=True)\n",
    "\n",
    "for i in WESAD_cm_cr_dict[\"cm\"]:\n",
    "    print('confusion matrix\\n',i['Confusion Matrix'])\n",
    "    #print(WESAD_cm_cr_dict[\"cr\"][i],sep='\\n' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 46, 388, 177])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(WESAD_cm_cr_dict[\"cm\"][1]['Confusion Matrix'])  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fb_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
