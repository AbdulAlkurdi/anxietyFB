{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fb testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pickle\n",
    "import dask as pd\n",
    "import pandas as pd_old\n",
    "import warnings\n",
    "import utils\n",
    "import heartpy as hp\n",
    "from ECG_feature_extractor_1001 import *\n",
    "# import time \n",
    "import time\n",
    "from datetime import datetime\n",
    "from biosppy.signals import ecg\n",
    "from feature_extraction import SubjectData, compute_features, get_samples, combine_files\n",
    "\n",
    "# To ignore all warnings:\n",
    "warnings.filterwarnings(\"ignore\", module=\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_IN_SECONDS = 60\n",
    "stride = 1\n",
    "label_dict = {'baseline': 1, 'stress': 2, 'amusement': 0}\n",
    "int_to_label = {1: 'baseline', 2: 'stress', 0: 'amusement'}\n",
    "feat_names = None\n",
    "loadPath = '../data/WESAD'\n",
    "savePath = '../data/GN-WESAD'\n",
    "subject_feature_path = '/subject_feats'\n",
    "\n",
    "n_samples = 10\n",
    "subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "snrs = [0.0001, 0.001, 0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6]  # 0.00001,\n",
    "fb_model_list = ['DT', 'RF', 'LDA', 'KNN', 'AdaBoost', 'SVM']\n",
    "\n",
    "if not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "if not os.path.exists(savePath + subject_feature_path):\n",
    "    os.makedirs(savePath + subject_feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'onedrive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/alkurdi/Desktop/Vansh/fb_code/fb_testing.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/alkurdi/Desktop/Vansh/fb_code/fb_testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcompleted snrs :\u001b[39m\u001b[39m{\u001b[39;00mcompleted_snrs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/alkurdi/Desktop/Vansh/fb_code/fb_testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mincomplete snrs :\u001b[39m\u001b[39m{\u001b[39;00mbad_snrs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/alkurdi/Desktop/Vansh/fb_code/fb_testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m get_processing_status(snrs, subject_ids, onedrive, n_samples\u001b[39m=\u001b[39mn_samples)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'onedrive' is not defined"
     ]
    }
   ],
   "source": [
    "def get_processing_status(snrs, subject_ids, onedrive, n_samples=10):\n",
    "    # bads are the ones that do not have the gaussian-modified data.\n",
    "    bads = []\n",
    "    bad_snrs = []\n",
    "    bad_subjects = []\n",
    "    bad_ns = []\n",
    "    completed_snrs = []\n",
    "    for n_i in range(n_samples):\n",
    "        for snr in snrs:\n",
    "            for subject_id in subject_ids:\n",
    "                # print(snr)\n",
    "\n",
    "                # print(f'{onedrive}/n_{n_i}/snr_{snr}/S{subject_id}/{a}')\n",
    "                try:\n",
    "                    a = os.listdir(f'{onedrive}/n_{n_i}/snr_{str(snr)}/S{subject_id}')\n",
    "                    a[0]\n",
    "                    completed_snrs.append(snr)\n",
    "                except:\n",
    "                    bads.append(f'n_{n_i}/snr_{snr}/S{subject_id}')\n",
    "                    bad_snrs.append(snr)\n",
    "                    bad_subjects.append(subject_id)\n",
    "                    bad_ns.append(n_i)\n",
    "\n",
    "    bad_snrs = sorted(set(bad_snrs))\n",
    "    bad_subjects = sorted(set(bad_subjects))\n",
    "    bad_ns = sorted(set(bad_ns))\n",
    "    completed_snrs = sorted(set(completed_snrs))\n",
    "    # printing after checking\n",
    "    print(f'completed snrs :{completed_snrs}')\n",
    "    print(f'incomplete snrs :{bad_snrs}')\n",
    "\n",
    "\n",
    "get_processing_status(snrs, subject_ids, onedrive, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "\n",
    "for each_dataset in dataset_list:\n",
    "    for snr in snrs:\n",
    "        for model in fb_model_list:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "savePath = 'C:/Users/alkurdi/Downloads/WESAD/GN-WESAD'\n",
    "n_samples = [9]\n",
    "subject_ids = [2]\n",
    "snrs = [0.01]\n",
    "for n_i in n_samples:\n",
    "    if not os.path.exists(savePath + '/n_' + str(n_i)):\n",
    "        os.makedirs(savePath + '/n_' + str(n_i))\n",
    "    for snr in snrs:\n",
    "        if not os.path.exists(savePath + '/n_' + str(n_i) + '/snr_' + str(snr)):\n",
    "            os.makedirs(savePath + '/n_' + str(n_i) + '/snr_' + str(snr))\n",
    "        for subject_id in subject_ids:\n",
    "            if not os.path.exists(\n",
    "                savePath\n",
    "                + '/n_'\n",
    "                + str(n_i)\n",
    "                + '/snr_'\n",
    "                + str(snr)\n",
    "                + '/S'\n",
    "                + str(subject_id)\n",
    "            ):\n",
    "                os.makedirs(\n",
    "                    savePath\n",
    "                    + '/n_'\n",
    "                    + str(n_i)\n",
    "                    + '/snr_'\n",
    "                    + str(snr)\n",
    "                    + '/S'\n",
    "                    + str(subject_id)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{savePath}/n_{n_i}')\n",
    "print(os.path.isdir(f'{savePath}/n_{n_i}'))\n",
    "print(os.listdir(f'{savePath}/n_{n_i}'))\n",
    "print(\n",
    "    os.path.isdir(\n",
    "        f'{savePath}/n_{n_i}/snr_{snr}/fixed_resampled140hz_S{subject_id}.pkl'\n",
    "    )\n",
    ")\n",
    "\n",
    "with open(f'{savePath}/n_{n_i}/poop.txt', 'w') as f:\n",
    "    f.write('poop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table = pd_old.DataFrame(columns=['SNR', 'Accuracy', 'F1-Score', 'dataset'])\n",
    "results_table.loc[str('SVM')] = pd_old.Series(\n",
    "    {'SNR': 1, 'Accuracy': 5, 'F1 Score': 2, 'dataset': 'WESAD'}\n",
    ")\n",
    "results_table.loc[str('RF')] = pd_old.Series(\n",
    "    {'SNR': 1, 'Accuracy': 5, 'F1 Score': 2, 'dataset': 'WESAD'}\n",
    ")\n",
    "'''\n",
    "fb_model_list = ['SVM', 'RF']\n",
    "for model in fb_model_list:\n",
    "    for i in range(len(snrs)):\n",
    "        results_table.loc[str(model) + str(snrs[i])] = pd.Series({'SNR':snrs[i], 'Accuracy':svm_accuracy[i], 'F1 Score':2, 'dataset':'WESAD'})\n",
    "'''\n",
    "display(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "ecg_biosppy = ecg\n",
    "ecg = None\n",
    "fs_ecg = 700\n",
    "fs_ppg = 64\n",
    "subject_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = SubjectData(main_path=loadPath, subject_number=subject_id)\n",
    "data_dict = subject.get_wrist_and_chest_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.time()\n",
    "BS_signal_analysis3, pack3, ecg_out3 = analyze_ecg(ecg, fs_ecg)\n",
    "print('analyze_ecg execution time is ', now - time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing for PPG\n",
    "\n",
    "now = datetime.now()\n",
    "pack, ppg, RR, time_dict = freq_ratio(ppg, fs_ppg, method='welch', factor=1)\n",
    "print('freq_ratio execution time is ', now - time.time())\n",
    "\n",
    "now = datetime.now()\n",
    "pack, ppg, time_dict = freq_ratio_hybrid(ppg, fs_ppg, method='welch', factor=1)\n",
    "print('freq_ratio_hybrid execution time is ', now - time.time())\n",
    "\n",
    "now = datetime.now()\n",
    "BS_signal_analysis, pack, ppg_out = analyze_ecg(ppg, fs_ppg)\n",
    "print('analyze_ecg execution time is ', now - time.time())\n",
    "\n",
    "now = datetime.now()\n",
    "wd, m = hp.process(ppg, fs_ppg)\n",
    "print('hp.process execution time is ', now - time.time())\n",
    "\n",
    "now = datetime.now()\n",
    "pack, ppg, RR = freq_ratio_fast(ppg, fs_ppg, method='welch', factor=1)\n",
    "print('freq_ratio_fast execution time is ', now - time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_noiZ_files(subject_ids)\n",
    "# took 19m 30s to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging\n",
    "\n",
    "now = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "def process_subject_file(snr, n_i, s):\n",
    "    file_path = f'{savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/S{s}_feats.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path, index_col=0)\n",
    "        df['subject'] = s\n",
    "        return df\n",
    "    return None\n",
    "\n",
    "\n",
    "def combine_noiZ_files(subjects):\n",
    "    now = datetime.now().strftime('%Y-%m-%d')\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO, filename=now + '-combine.log', filemode='w', force=True\n",
    "    )\n",
    "\n",
    "    for snr in snrs:\n",
    "        for n_i in range(n_samples):\n",
    "            # Parallelize file reading\n",
    "            with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "                futures = [\n",
    "                    executor.submit(process_subject_file, snr, n_i, s) for s in subjects\n",
    "                ]\n",
    "                df_list = [\n",
    "                    future.result() for future in futures if future.result() is not None\n",
    "                ]\n",
    "\n",
    "            if df_list:\n",
    "                df = pd.concat(df_list)\n",
    "                df['label'] = df[['0', '1', '2']].idxmax(axis=1)\n",
    "                df.drop(['0', '1', '2'], axis=1, inplace=True)\n",
    "                df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                df.to_csv(\n",
    "                    f'{savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/{now}_feats_filt.csv'\n",
    "                )\n",
    "                logging.info('-' * 20)\n",
    "                logging.info(\n",
    "                    f'Saved file to: {savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/{now}_feats_filt.csv'\n",
    "                )\n",
    "\n",
    "                counts = df['label'].value_counts()\n",
    "                logging.info('Number of samples per class:')\n",
    "                logging.info(\n",
    "                    'baseline: {0[1]}; stress: {1[1]}; amusement: {2[1]} '.format(\n",
    "                        *list(zip(counts.index, counts.values))\n",
    "                    )\n",
    "                )\n",
    "    logging.info('all done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_i = 5\n",
    "s = 2\n",
    "snr = 0.6\n",
    "df = pd_old.read_csv(\n",
    "    f'{savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/S{subject_id}_feats.csv',\n",
    "    index_col=0,\n",
    ")\n",
    "df['subject'] = s\n",
    "# df_list.append(df)\n",
    "# f = pd_old.concat(df_list)\n",
    "df['label'] = (df['0'].astype(str) + df['1'].astype(str) + df['2'].astype(str)).apply(\n",
    "    lambda x: x.index('1')\n",
    ")\n",
    "df.drop(['0', '1', '2'], axis=1, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "counts = df['label'].value_counts()\n",
    "print('Number of samples per class:')\n",
    "print(\n",
    "    'baseline: {0[1]}; stress: {1[1]}; amusement: {2[1]} '.format(\n",
    "        *list(zip(counts.index, counts.values))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_n_reduce(path):\n",
    "    # print(os.listdir(path))\n",
    "    df = pd_old.read_csv(path, index_col=0)\n",
    "    print('len of df ', len(df))\n",
    "    pd_old.set_option('display.max_columns', None)\n",
    "    # We want to drop columns in df that are not in RADWear to match modalities.\n",
    "    # drop _c columns\n",
    "    columns_list = df.columns.tolist()\n",
    "    drop_list = []\n",
    "    # df.drop(columns=['Resp_C'])\n",
    "    for column in columns_list:\n",
    "        if (\n",
    "            'EMG' in column\n",
    "            or 'EDA_C' in column\n",
    "            or 'Temp_C' in column\n",
    "            or 'TEMP_C' in column\n",
    "            or 'SCR_C' in column\n",
    "            or 'SCL_C' in column\n",
    "        ):\n",
    "            drop_list.append(column)\n",
    "\n",
    "    reduced_df = df.drop(columns=drop_list)\n",
    "    df = reduced_df\n",
    "    print('len of reduced df ', len(df))\n",
    "    return df\n",
    "\n",
    "\n",
    "def gn_wesad_path(n_i, snr):\n",
    "    loadPath = '../data/GN-WESAD'\n",
    "    return (\n",
    "        f'{loadPath}/n_{n_i}/snr_{snr}{subject_feature_path}/{gn_wesad_day}_feats2.csv'\n",
    "    )\n",
    "\n",
    "\n",
    "gn_wesad_day = '2023-11-13'\n",
    "matrix = np.zeros((len(snrs), n_samples))\n",
    "\n",
    "for n_i in range(n_samples):\n",
    "    for i, snr in enumerate(snrs):\n",
    "        print(f'for {n_i} and {snr} number {i}: ')\n",
    "        file_path = gn_wesad_path(n_i, snr)\n",
    "        df = read_n_reduce(file_path)\n",
    "        matrix[i][n_i] = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'data/GN-WESAD/n_0/snr_0.0001/subject_feats/2023-11-12_feats_filt.csv'\n",
    "'data/GN-WESAD/n_0/snr_0.001/subject_feats/2023-11-12_feats_filt.csv'\n",
    "loadPath = '../data/GN-WESAD'\n",
    "# display(os.listdir(f'{loadPath}/n_{n_i}/snr_{snr}{subject_feature_path}'))\n",
    "snr0001 = pd_old.read_csv(\n",
    "    '../data/GN-WESAD/n_0/snr_0.0001/subject_feats/2023-11-13_feats2.csv', index_col=0\n",
    ")\n",
    "snr001 = pd_old.read_csv(\n",
    "    '../data/GN-WESAD/n_0/snr_0.001/subject_feats/2023-11-13_feats2.csv', index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'SNR': [0.6] * 10,\n",
    "        'Accuracy': [\n",
    "            0.940639,\n",
    "            0.968134,\n",
    "            0.964939,\n",
    "            0.940909,\n",
    "            0.937785,\n",
    "            0.923780,\n",
    "            0.942337,\n",
    "            0.960486,\n",
    "            0.952816,\n",
    "            0.925645,\n",
    "        ],\n",
    "        'F1 Score': [\n",
    "            0.940639,\n",
    "            0.968134,\n",
    "            0.964939,\n",
    "            0.940909,\n",
    "            0.937785,\n",
    "            0.923780,\n",
    "            0.942337,\n",
    "            0.960486,\n",
    "            0.952816,\n",
    "            0.925645,\n",
    "        ],\n",
    "        'dataset': ['GN-WESAD'] * 10,\n",
    "        'n_i': list(range(10)),\n",
    "        'n': [10] * 10,\n",
    "        'noise gen function': ['Gaussian Noise'] * 10,\n",
    "        'Precision': [\n",
    "            0.940639,\n",
    "            0.968134,\n",
    "            0.964939,\n",
    "            0.940909,\n",
    "            0.937785,\n",
    "            0.923780,\n",
    "            0.942337,\n",
    "            0.960486,\n",
    "            0.952816,\n",
    "            0.925645,\n",
    "        ],\n",
    "        'Recall': [\n",
    "            0.940639,\n",
    "            0.968134,\n",
    "            0.964939,\n",
    "            0.940909,\n",
    "            0.937785,\n",
    "            0.923780,\n",
    "            0.942337,\n",
    "            0.960486,\n",
    "            0.952816,\n",
    "            0.925645,\n",
    "        ],\n",
    "        'Model': ['DT'] * 10,\n",
    "    }\n",
    ")\n",
    "series = pd.Series(\n",
    "    {\n",
    "        'SNR': 0.600000,\n",
    "        'Accuracy': 0.945747,\n",
    "        'F1 Score': 0.945747,\n",
    "        'n_i': 4.500000,\n",
    "        'n': 10.000000,\n",
    "        'Precision': 0.945747,\n",
    "        'Recall': 0.945747,\n",
    "    },\n",
    "    name='SNR 0.6 Model DT mean',\n",
    ")\n",
    "\n",
    "print(set(df.columns))\n",
    "print(set(series.index))\n",
    "missing_columns = set(df.columns) - set(series.index)\n",
    "print(missing_columns)\n",
    "for col in missing_columns:\n",
    "    # You can assign a specific value or use a value from the DataFrame\n",
    "    # Here, I'm using the first row's value as an example\n",
    "    # print(col)\n",
    "    # print(df[col].iloc[0])\n",
    "\n",
    "    series[col] = df[col].iloc[0]\n",
    "    # print(series[col])\n",
    "\n",
    "# print(series)\n",
    "\n",
    "series_df2 = series.to_frame().T\n",
    "display(series_df2)\n",
    "df_combined2 = pd.concat([df, series_df2])\n",
    "display(df_combined2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabulate and plot\n",
    "\n",
    "with open('../data/GN-WESAD/cm_cr_dict.pickle', 'rb') as handle:\n",
    "    GN_cm_cr_dict = pickle.load(handle)\n",
    "with open('../data/WESAD/cm_cr_dict.pickle', 'rb') as handle:\n",
    "    WESAD_cm_cr_dict = pickle.load(handle)\n",
    "wesad_acc = pd.read_csv(\n",
    "    '../data/WESAD/wesad_models_results-win60stride1_wcm_wcr.csv', index_col=0\n",
    ")\n",
    "display(wesad_acc)\n",
    "# combined_results = pd.concat([WESAD_model_results, GN_model_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/GN-WESAD/cm_cr_dict.pickle', 'rb') as handle:\n",
    "    GN_cm_cr_dict = pickle.load(handle)\n",
    "tgt_file = '../data/GN-WESAD/GN_wesad_models_results_wbinaryf1.csv'\n",
    "gn_wesad_acc = pd.read_csv(tgt_file, index_col=0)\n",
    "# gn_wesad_acc['Binary F1'] = None\n",
    "print(gn_wesad_acc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/GN-WESAD/cm_cr_dict.pickle', 'rb') as handle:\n",
    "    GN_cm_cr_dict = pickle.load(handle)\n",
    "tgt_file = '../data/GN-WESAD/GN_wesad_models_results_wcm_wcr.csv'\n",
    "gn_wesad_acc = pd.read_csv(tgt_file, index_col=0)\n",
    "gn_wesad_acc['Binary F1'] = None\n",
    "\n",
    "for i, classification_report in enumerate(GN_cm_cr_dict['cr']):\n",
    "    cr = classification_report['Classification Report']\n",
    "    print(classification_report['id'][2], fb_model_list[i % 6])\n",
    "    # print(cr)\n",
    "    # print(i//5)\n",
    "    binary_f1_score = calculate_binary_metrics(cr)\n",
    "    # print(classification_report['id'])\n",
    "    if binary_f1_score is not None:\n",
    "        # print(\"Binary F1 Score for \", fb_model_list[i], \" :\\t\\t\", binary_f1_score)\n",
    "        insta_acc = wesad_acc['Accuracy'][i % 6]\n",
    "        insta_f1 = wesad_acc['F1 Score'][i % 6]\n",
    "        secret_df = pd.concat(\n",
    "            [\n",
    "                secret_df,\n",
    "                pd.Series(\n",
    "                    {\n",
    "                        'Model': fb_model_list[i % 6],\n",
    "                        'Binary F1 Score': binary_f1_score,\n",
    "                        'SNR': classification_report['id'][0],\n",
    "                        'n': classification_report['id'][1],\n",
    "                        'Model': classification_report['id'][2],\n",
    "                    }\n",
    "                )\n",
    "                .to_frame()\n",
    "                .T,\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        # print(f'my calc acc {insta_acc}, calc f1 {insta_f1}')\n",
    "        # display(wesad_acc_test[wesad_acc_test['Model'] == fb_model_list[i]])#['binary f1'] = binary_f1_score\n",
    "        # wesad_acc_test[wesad_acc_test['Model'] == fb_model_list[i]]['binary f1'] = binary_f1_score\n",
    "        # wesad_acc_test[wesad_acc_test['Model'] == fb_model_list[i]]['binary acc'] = insta_acc\n",
    "        # print(fb_model_list[i])\n",
    "        gn_wesad_acc.loc[\n",
    "            gn_wesad_acc['Model'] == fb_model_list[i % 6], 'Binary f1'\n",
    "        ] = binary_f1_score\n",
    "        # print(gn_wesad_acc.loc[gn_wesad_acc['Model'] == fb_model_list[i], 'binary f1'])\n",
    "\n",
    "    else:\n",
    "        print(\"Could not extract metrics from the report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "wesad_acc_test = wesad_acc.copy()\n",
    "wesad_acc_test['Binary F1'] = None\n",
    "\n",
    "\n",
    "def extract_metrics(report):\n",
    "    # Regular expression to find numeric values\n",
    "    regex = r\"\\s+1\\s+([\\d\\.]+)\\s+([\\d\\.]+)\\s+([\\d\\.]+)\"\n",
    "\n",
    "    # Search for the pattern\n",
    "    match = re.search(regex, report)\n",
    "    # print(match)\n",
    "    if match:\n",
    "        precision = float(match.group(1))\n",
    "        recall = float(match.group(2))\n",
    "        f1_score = float(match.group(3))\n",
    "        return precision, recall, f1_score\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def calculate_binary_metrics(report):\n",
    "    precision, recall, f1_score = extract_metrics(report)\n",
    "\n",
    "    if precision is not None and recall is not None:\n",
    "        # Calculate binary F1 score for class 1\n",
    "        binary_f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        return binary_f1_score\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# classification_report =\n",
    "# Extract and calculate binary F1 score\n",
    "fb_model_counter = fb_model_list\n",
    "\n",
    "\n",
    "secret_df = pd.DataFrame()\n",
    "\n",
    "for i, classification_report in enumerate(WESAD_cm_cr_dict['cr']):\n",
    "    cr = classification_report['Classification Report']\n",
    "    binary_f1_score = calculate_binary_metrics(cr)\n",
    "    # print(classification_report['id'])\n",
    "    if binary_f1_score is not None:\n",
    "        print(\"Binary F1 Score for \", fb_model_list[i], \" :\\t\\t\", binary_f1_score)\n",
    "        insta_acc = wesad_acc['Accuracy'][i]\n",
    "        insta_f1 = wesad_acc['F1 Score'][i]\n",
    "        secret_df = pd.concat(\n",
    "            [\n",
    "                secret_df,\n",
    "                pd.Series(\n",
    "                    {\n",
    "                        'Model': fb_model_list[i],\n",
    "                        'Binary F1 Score': binary_f1_score,\n",
    "                        'SNR': classification_report['id'][0],\n",
    "                        'n': classification_report['id'][1],\n",
    "                        'Model': classification_report['id'][2],\n",
    "                    }\n",
    "                )\n",
    "                .to_frame()\n",
    "                .T,\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        # print(f'my calc acc {insta_acc}, calc f1 {insta_f1}')\n",
    "        # display(wesad_acc_test[wesad_acc_test['Model'] == fb_model_list[i]])#['binary f1'] = binary_f1_score\n",
    "        # wesad_acc_test[wesad_acc_test['Model'] == fb_model_list[i]]['binary f1'] = binary_f1_score\n",
    "        # wesad_acc_test[wesad_acc_test['Model'] == fb_model_list[i]]['binary acc'] = insta_acc\n",
    "        # print(fb_model_list[i])\n",
    "        wesad_acc_test.loc[\n",
    "            wesad_acc_test['Model'] == fb_model_list[i], 'binary f1'\n",
    "        ] = binary_f1_score\n",
    "        print(\n",
    "            wesad_acc_test.loc[wesad_acc_test['Model'] == fb_model_list[i], 'binary f1']\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(\"Could not extract metrics from the report.\")\n",
    "display(secret_df)\n",
    "display(wesad_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([wesad_acc, secret_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_n_reduce(path):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    # We want to drop columns in df that are not in RADWear to match modalities.\n",
    "    # drop _c columns\n",
    "    columns_list = df.columns.tolist()\n",
    "    drop_list = []\n",
    "    # df.drop(columns=['Resp_C'])\n",
    "    for column in columns_list:\n",
    "        if (\n",
    "            'EMG' in column\n",
    "            or 'EDA_C' in column\n",
    "            or 'Temp_C' in column\n",
    "            or 'TEMP_C' in column\n",
    "            or 'SCR_C' in column\n",
    "            or 'SCL_C' in column\n",
    "        ):\n",
    "            drop_list.append(column)\n",
    "\n",
    "    reduced_df = df.drop(columns=drop_list)\n",
    "    df = reduced_df\n",
    "    return df\n",
    "\n",
    "\n",
    "print(os.listdir('../data/WESAD'))\n",
    "df = read_n_reduce('../data/WESAD//subject_feats/oct5_feats4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# display(the_splits[0])\n",
    "X_train, X_test, y_train, y_test = the_splits\n",
    "clf = SVC(kernel='linear', C=1, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_out = clf.predict(X_test)\n",
    "\n",
    "svm_accuracy = accuracy_score(y_test, y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for snr in snrs:\n",
    "    for n_i in range(n_samples):\n",
    "        tgt = f'../data/GN-WESAD/n_{n_i}/snr_{snr}{subject_feature_path}/{gn_wesad_day}_feats2.csv'\n",
    "        print(f'df {snr} n {n_i} shape is {(pd.read_csv(tgt, index_col=0)).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "subject_id = 2\n",
    "snr = 0.01\n",
    "n_i = 0\n",
    "\n",
    "\n",
    "wesad_path = '/mnt/d/Users/alkurdi/data/WESAD'\n",
    "freshwesad_path = '/mnt/d/Users/alkurdi/data/freshWESAD'\n",
    "downloaddwesad_path = '/mnt/c/Users/alkurdi/Desktop/Vansh/data'\n",
    "gn_path = '/mnt/d/Users/alkurdi/data/GN-WESAD'\n",
    "\n",
    "sesh_path = '/n_' + str(n_i) + '/snr_' + str(snr) + '/S' + str(subject_id)\n",
    "load_gn_path = gn_path + sesh_path + '/S' + str(subject_id) + '.pkl'\n",
    "load_dw_path = (\n",
    "    downloaddwesad_path + '/S' + str(subject_id) + '/S' + str(subject_id) + '.pkl'\n",
    ")\n",
    "load_ws_path = wesad_path + '/S' + str(subject_id) + '/S' + str(subject_id) + '.pkl'\n",
    "load_freshws_path = (\n",
    "    freshwesad_path + '/S' + str(subject_id) + '/S' + str(subject_id) + '.pkl'\n",
    ")\n",
    "\n",
    "# ws_df = pd.read_pickle(load_ws_path)\n",
    "\n",
    "# with open( load_ws_path, 'rb') as dest:\n",
    "#    ws_df = pickle.load(dest)\n",
    "\n",
    "now = time()\n",
    "with open(load_dw_path, 'rb') as file:\n",
    "    dw_df = pickle.load(file, encoding='latin1')\n",
    "print(\n",
    "    'c:\\ downloads wesad loaded w pickle.load in ', round(time() - now, 3), 's'\n",
    ")  # c:\\ downloads wesad loaded w pickle.load in  17.112 s\n",
    "\n",
    "\n",
    "now = time()\n",
    "with open(load_gn_path, 'rb') as file:\n",
    "    gn_df = pickle.load(file, encoding='latin1')\n",
    "print('gnwesad loaded in ', round(time() - now, 3), 's')\n",
    "\n",
    "'''\n",
    "now = time()\n",
    "with open(load_freshws_path, 'rb') as file:\n",
    "            freshws_df = pickle.load(file, encoding='latin1')\n",
    "print('d:\\ freshwesad loaded in ', round(time()-now,3),'s')  #d:\\ freshwesad loaded in  191.335 s\n",
    "\n",
    "now = time()\n",
    "dw_df = pd.read_pickle(load_dw_path)\n",
    "print('c:\\ downloads wesad loaded w pd.read_pickle in ', round(time()-now,3),'s') #c:\\ downloads wesad loaded w pd.read_pickle in  24.78 s\n",
    "\n",
    "\n",
    "#this is the one that fails\n",
    "load_ws_path = wesad_path + '/S'+str(subject_id) + '/S'+str(subject_id)+'.pkl'\n",
    "now = time()\n",
    "with open(load_ws_path, 'rb') as file:\n",
    "            ws_df = pickle.load(file, encoding='latin1')\n",
    "print('wesad loaded in ', round(time()-now,3),'s')\n",
    "'''\n",
    "# fresh_df = pd.read_pickle()\n",
    "# wesad_path = '/mnt/c/Users/alkurdi/Desktop/Vansh/data/WESAD'\n",
    "# msg = f'starting  n_i: {n_i}; snr: {snr}, id: {subject_id}. iteration'\n",
    "# sesh_path = '/n_'+str(n_i)+'/snr_'+str(snr)+'/S'+str(subject_id)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time()\n",
    "with open(\n",
    "    '/mnt/c/Users/alkurdi/Downloads/WESAD/GN-WESAD/n_0/snr_0.6/S17/fixed_resampled140hz_S17.pkl',\n",
    "    'rb',\n",
    ") as file:\n",
    "    resampled_gn = pickle.load(file, encoding='latin1')\n",
    "print('resampled_gn loaded in ', round(time() - now, 3), 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def my_counter(df, name=None):\n",
    "    i = 0\n",
    "    long_list = []\n",
    "    for i_first_layer in df.keys():\n",
    "        # print(i_first_layer, dw_df[i_first_layer])\n",
    "        if i_first_layer == 'label':\n",
    "            long_list = long_list + [*df[i_first_layer]]\n",
    "            i += len(df[i_first_layer])\n",
    "            print(f'{name}: length of {i_first_layer} is {len(df[i_first_layer]):,.0f}')\n",
    "        elif i_first_layer == 'signal':\n",
    "            for i_second_layer in df[i_first_layer].keys():\n",
    "                # print('part', i_second_layer)#, dw_df[i_first_layer][i_second_layer])\n",
    "\n",
    "                for i_third_layer in df[i_first_layer][i_second_layer].keys():\n",
    "                    sig_shape = np.shape(\n",
    "                        df[i_first_layer][i_second_layer][i_third_layer]\n",
    "                    )\n",
    "                    # print('part', i_second_layer, 'signal', i_third_layer, sig_shape)\n",
    "                    i += np.prod(sig_shape)\n",
    "                    long_list = long_list + [\n",
    "                        *df[i_first_layer][i_second_layer][i_third_layer].flatten()\n",
    "                    ]\n",
    "                    print(\n",
    "                        f'{name}: length of {i_third_layer} is {len(df[i_first_layer][i_second_layer][i_third_layer]):,.0f}'\n",
    "                    )\n",
    "        elif i_first_layer == 'subject':\n",
    "            pass\n",
    "        else:\n",
    "            long_list = long_list + [*df[i_first_layer].flatten()]\n",
    "            i += np.prod(np.shape(df[i_first_layer]))\n",
    "            print(f'{name}: length of {i_first_layer} is {len(df[i_first_layer]):,.0f}')\n",
    "    print('_' * 5)\n",
    "    print(f'total length of {name} df is {len(long_list):,.0f}')\n",
    "    print('_' * 25)\n",
    "\n",
    "\n",
    "my_counter(dw_df, name='dw_df')\n",
    "my_counter(gn_df, name='gs_df')\n",
    "my_counter(resampled_gn, name='resampled_gn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(os.getpid(), file=sys.stderr)\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import requests\n",
    "\n",
    "from subprocess import PIPE, Popen\n",
    "\n",
    "\n",
    "def get_cmd(pid):\n",
    "    with Popen(f\"ps -q {pid} -o comm=\", shell=True, stdout=PIPE) as p:\n",
    "        return p.communicate()[0]\n",
    "\n",
    "\n",
    "get_cmd(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_list = list(dw_df['signal']['chest'].items()) + list(\n",
    "    dw_df['signal']['wrist'].items()\n",
    ")\n",
    "a, b = zip(*long_list)\n",
    "tot_len = 0\n",
    "for i in list(b):\n",
    "    tot_len += len(i)\n",
    "print(f'total length wesad {tot_len:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/c/Users/alkurdi/Downloads/WESAD/GN-WESAD/n_0/snr_0.0001/S2'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 0, 0\n",
    "a, b = zip(*list(gn_df.items()))\n",
    "tot_len = 0\n",
    "for i in list(b):\n",
    "    tot_len += len(i)\n",
    "print(f'total length gn wesad {tot_len:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wesad_path = '/mnt/c/Users/alkurdi/data/WESAD'\n",
    "fresh_wesad_path = '/mnt/c/Users/alkurdi/Downloads/WESAD/WESAD'\n",
    "\n",
    "# start_time = time()\n",
    "id = 2\n",
    "sesh_path = fresh_wesad_path + '/S' + str(id) + '/S' + str(id) + '.pkl'\n",
    "\n",
    "ws_df = pd.read_pickle(sesh_path)\n",
    "# with open( sesh_path, 'rb') as dest:\n",
    "#        ws2_df = pickle.load(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_resampled_df = pd.read_pickle(\n",
    "    '/mnt/d/Users/alkurdi/data/GN-WESAD/n_0/snr_0.01/S17/fixed_resampled170hz64_S17.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('for resampled dataset: ')\n",
    "for key in fixed_resampled_df.keys():\n",
    "    print(\n",
    "        f'length of signal {key}: ', len(fixed_resampled_df['signal']['chest']['ECG'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('keys', ws_df.keys())\n",
    "print('keys', ws_df['signal'].keys())\n",
    "print('length of signal', len(ws_df['signal']['chest']['ECG']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fixed_resampled_df['signal']['chest']['ECG']) / len(ws_df['signal']['chest']['ECG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import signal\n",
    "from time import time\n",
    "import concurrent.futures\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import logging\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "snrs = [ 0.01,0.1,0.6 0.05,  0.3,0.1, 0.15, 0.2,0.0001, 0.001, 0.4, 0.5, 0.6] # this is what we ran #0.00001,\n",
    "n_samples = 0 #10\n",
    "n_i = n_samples\n",
    "snr1 = 0.01\n",
    "snr2 = 0.6\n",
    "subject_id = 17\n",
    "\n",
    "sesh_id =[n_i,snr1,subject_id]\n",
    "rt_pth = '/mnt/d/Users/alkurdi/data/GN-WESAD'\n",
    "start_time = time()\n",
    "onedrive = '/mnt/d/Users/alkurdi/OneDrive - University of Illinois - Urbana/data/GN-WESAD'\n",
    "\n",
    "#print(os.path.isfile(rt_pth + '/n_'+str(0)+'/snr_'+str(snr1)+ '/S'+str(17)+'/S'+str(17)+'.pkl'))\n",
    "sesh_path = rt_pth + '/n_'+str(0)+'/snr_'+str(0.0001)+ '/S'+str(2)+'/S'+str(2)+'.pkl'\n",
    "#drive_path = onedrive +  '/n_'+str(0)+'/snr_'+str(snr1)+ '/S'+str(subject_id)+'/S'+str(subject_id)+'.pkl'\n",
    "with open( sesh_path, 'rb') as dest:\n",
    "        ws1_df = pickle.load(dest) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_pth = '/mnt/d/Users/alkurdi/data/GN-WESAD'\n",
    "# start_time = time()\n",
    "id = 4\n",
    "sesh_path = (\n",
    "    rt_pth\n",
    "    + '/n_'\n",
    "    + str(1)\n",
    "    + '/snr_'\n",
    "    + str(0.001)\n",
    "    + '/S'\n",
    "    + str(id)\n",
    "    + '/S'\n",
    "    + str(id)\n",
    "    + '.pkl'\n",
    ")\n",
    "# drive_path = onedrive +  '/n_'+str(0)+'/snr_'+str(snr1)+ '/S'+str(subject_id)+'/S'+str(subject_id)+'.pkl'\n",
    "\n",
    "with open(sesh_path, 'rb') as dest:\n",
    "    ws2_df = pickle.load(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('for resampled dataset: ')\n",
    "for key in ws2_df.keys():\n",
    "    print('key', key)\n",
    "    # print(f'length of chest ignal {key}: ', len(ws2_df['signal']['chest']['ECG']))\n",
    "    # print(f'length of chest ignal {key}: ', len(ws2_df['signal']['chest']['ECG']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "# snrs = [ 0.01,0.1,0.6 0.05,  0.3,0.1, 0.15, 0.2,0.0001, 0.001, 0.4, 0.5, 0.6] # this is what we ran #0.00001,\n",
    "snrs = [0.01, 0.05, 0.3]  # ,0.1, 0.15, 0.2,0.0001, 0.001, 0.4, 0.5, 0.6]\n",
    "n_i = [0, 1, 3, 4]  # next is [5, 6, 7] [8, 9, 10]\n",
    "\n",
    "\n",
    "from_path = '/mnt/c/Users/alkurdi/Downloads/WESAD/GN-WESAD'\n",
    "to_path = '/mnt/d/Users/alkurdi/data/GN-WESAD'\n",
    "\n",
    "\n",
    "for n in n_i:\n",
    "    for snr in snrs:\n",
    "        for s in subject_ids:\n",
    "            sesh_path = '/n_' + str(n_i) + '/snr_' + str(snr) + '/S' + str(subject_id)\n",
    "\n",
    "            xact_from_path = from_path + sesh_path\n",
    "            xact_to_path = to_path + sesh_path\n",
    "\n",
    "            os.system(f'cp -r {from_path} {to_path}')\n",
    "            print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for 5 seconds\n",
    "from time import sleep\n",
    "\n",
    "from_path = '/mnt/c/Users/alkurdi/Downloads/WESAD'\n",
    "poop = 'poop'\n",
    "\n",
    "with open(from_path + '/poop.txt', 'w') as f:\n",
    "    f.write(poop)\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "# os.system(f'{from_path}/poop>poop.txt')\n",
    "\n",
    "to_path = '/mnt/d/Users/alkurdi/data/'\n",
    "\n",
    "os.system(f'mv {from_path}/poop.txt {to_path}/poop.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RADWear Calibration fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'modified by abdul alkurdi; 10/05/2023'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# import cudf\n",
    "import pickle, sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.signal import correlate\n",
    "\n",
    "# import cupy as cp\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal, stats\n",
    "\n",
    "# import peakutils, wfdb, pywt\n",
    "import csv\n",
    "import os, statistics\n",
    "from datetime import datetime\n",
    "\n",
    "# import heartpy as hp\n",
    "import json\n",
    "\n",
    "# import neurokit2 as nk\n",
    "\n",
    "# add path to sys\n",
    "sys.path.append('../')\n",
    "from syncfcns import *\n",
    "from process_redcap import process_redcap\n",
    "calib_dict = {'meditation': 1, 'cpt': 2, 'baseline': 0}\n",
    "rot_anx_dict = {'calibration': 0, 'LA': 1, 'HA': 2}\n",
    "fs_hx = {'ECG': 256, 'ACC': 64, 'BR': 1, 'RESP': 128, 'label': 256} # for RADWear, Wear\n",
    "fs_e4 = {'ACC': 32, 'BVP': 64, 'EDA': 4, 'TEMP': 4} # for RADWear, Wear\n",
    "\n",
    "radwear_path = '/mnt/c/Users/alkurdi/Desktop/Vansh/data/RADWear/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 16\n",
    "p_path = radwear_path + 'Participant ' + str(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file for participant 16 is available.\n"
     ]
    }
   ],
   "source": [
    "with open(radwear_path + 'all_p_metadata.json', 'rb') as f:\n",
    "    all_p_metadata = json.load(f)\n",
    "\n",
    "incomplete = [16]\n",
    "\n",
    "\n",
    "for p in incomplete:\n",
    "    p_path = radwear_path + 'Participant ' + str(p)\n",
    "    p_df = pd.DataFrame()\n",
    "\n",
    "    # check if file exist\n",
    "    a = (\n",
    "        'available.'\n",
    "        if os.path.isfile(p_path + '/p_' + str(p) + '.pkl')\n",
    "        else ' not available.'\n",
    "    )\n",
    "    print('pickle file for participant ' + str(p) + ' is ' + a)\n",
    "\n",
    "    # all_p[p] = p_data ## this takes too much memory so i will just load each p when needed\n",
    "    if not (os.path.isfile(radwear_path + 'p_' + str(p) + '.pkl')) or True:\n",
    "        with open(p_path + '/p_' + str(p) + '.pkl', 'rb') as f:\n",
    "            p_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redcap_path = radwear_path + 'REDCap responses/'\n",
    "with open(radwear_path + 'all_p_metadata.json', 'rb') as f:\n",
    "    all_p_metadata = json.load(f)\n",
    "# load all participant redcap data\n",
    "redcap_calib_dict = pd.read_pickle(\n",
    "    radwear_path + '/REDCap responses/redcap_calib_dict.pkl'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "e4sn = all_p_metadata[str(p)]['e4sn']\n",
    "calibration_files = all_p_metadata[str(p)]['calibration']\n",
    "p_calib = {}\n",
    "\n",
    "# load calibration data\n",
    "e4_num = all_p_metadata[str(p)]['e4sn'] + '_' + all_p_metadata[str(p)]['calibration'][0]\n",
    "hx_num = str(all_p_metadata[str(p)]['calibration'][1])\n",
    "p_calib[p] = read_sync_return(p_path, e4_num, hx_num)\n",
    "p_calib[p]['rot_label'] = rot_anx_dict['calibration'] * np.ones(len(p_calib[p]['ECG'])) # add label to designate calibration segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG            Timestamp      ECG       Second\n",
      "0       1.690417e+09   6.0224     0.000000\n",
      "1       1.690417e+09   1.0880     0.003906\n",
      "2       1.690417e+09   0.0000     0.007812\n",
      "3       1.690417e+09   0.0000     0.011719\n",
      "4       1.690417e+09   0.0320     0.015625\n",
      "...              ...      ...          ...\n",
      "357554  1.690418e+09   9.6256  1396.695312\n",
      "357555  1.690418e+09   9.9008  1396.699219\n",
      "357556  1.690418e+09  10.1376  1396.703125\n",
      "357557  1.690418e+09  10.3232  1396.707031\n",
      "357558  1.690418e+09  10.3232  1396.710938\n",
      "\n",
      "[357559 rows x 3 columns]\n",
      "BVP            Timestamp     BVP   Second\n",
      "52279   1.690417e+09   31.21   816.86\n",
      "52280   1.690417e+09   29.25   816.88\n",
      "52281   1.690417e+09   24.82   816.89\n",
      "52282   1.690417e+09   17.68   816.91\n",
      "52283   1.690417e+09    7.45   816.92\n",
      "...              ...     ...      ...\n",
      "141675  1.690418e+09 -102.76  2213.67\n",
      "141676  1.690418e+09  -81.86  2213.69\n",
      "141677  1.690418e+09  -50.64  2213.70\n",
      "141678  1.690418e+09  -17.35  2213.72\n",
      "141679  1.690418e+09   11.02  2213.73\n",
      "\n",
      "[89401 rows x 3 columns]\n",
      "BR          Timestamp  breathing_rate  Second\n",
      "0     1.690417e+09            10.0     0.0\n",
      "1     1.690417e+09            10.0     1.0\n",
      "2     1.690417e+09            10.0     2.0\n",
      "3     1.690417e+09            10.0     3.0\n",
      "4     1.690417e+09            10.0     4.0\n",
      "...            ...             ...     ...\n",
      "1392  1.690418e+09            17.0  1392.0\n",
      "1393  1.690418e+09            17.0  1393.0\n",
      "1394  1.690418e+09            16.0  1394.0\n",
      "1395  1.690418e+09            16.0  1395.0\n",
      "1396  1.690418e+09            16.0  1396.0\n",
      "\n",
      "[1397 rows x 3 columns]\n",
      "RESP          RESP       Second     Timestamp\n",
      "0           0     0.000000  1.690417e+09\n",
      "1           0     0.007812  1.690417e+09\n",
      "2           0     0.015625  1.690417e+09\n",
      "3           0     0.023438  1.690417e+09\n",
      "4       18175     0.031250  1.690417e+09\n",
      "...       ...          ...           ...\n",
      "178775  23716  1396.679688  1.690418e+09\n",
      "178776  23716  1396.687500  1.690418e+09\n",
      "178777  23716  1396.695312  1.690418e+09\n",
      "178778  23716  1396.703125  1.690418e+09\n",
      "178779  23716  1396.710938  1.690418e+09\n",
      "\n",
      "[178780 rows x 3 columns]\n",
      "B_PH         Timestamp     time [s] breathing_phase  ins | exp      Second\n",
      "0    1.690417e+09     2.046875            insp    20841.0    0.000000\n",
      "1    1.690417e+09     2.718750             exp    20802.0    0.361554\n",
      "2    1.690417e+09     5.000000            insp    20910.0    0.723109\n",
      "3    1.690417e+09     5.289062             exp    20921.0    1.084663\n",
      "4    1.690417e+09     5.921875            insp    20934.0    1.446218\n",
      "..            ...          ...             ...        ...         ...\n",
      "514  1.690417e+09  1428.679688            insp    20808.0  185.838946\n",
      "515  1.690417e+09  1430.156250             exp    20900.0  186.200501\n",
      "516  1.690417e+09  1430.820312            insp    20783.0  186.562055\n",
      "517  1.690417e+09  1431.726562             exp    20851.0  186.923609\n",
      "518  1.690417e+09  1437.515625            insp    65530.0  187.285164\n",
      "\n",
      "[519 rows x 5 columns]\n",
      "TEMP          Timestamp   Temp   Second\n",
      "3268  1.690417e+09  34.53   817.00\n",
      "3269  1.690417e+09  34.53   817.25\n",
      "3270  1.690417e+09  34.53   817.50\n",
      "3271  1.690417e+09  34.53   817.75\n",
      "3272  1.690417e+09  34.57   818.00\n",
      "...            ...    ...      ...\n",
      "8850  1.690418e+09  34.83  2212.50\n",
      "8851  1.690418e+09  34.83  2212.75\n",
      "8852  1.690418e+09  34.83  2213.00\n",
      "8853  1.690418e+09  34.83  2213.25\n",
      "8854  1.690418e+09  34.83  2213.50\n",
      "\n",
      "[5587 rows x 3 columns]\n",
      "EDA          Timestamp       EDA   Second\n",
      "3268  1.690417e+09  1.889117   817.00\n",
      "3269  1.690417e+09  1.790455   817.25\n",
      "3270  1.690417e+09  1.798143   817.50\n",
      "3271  1.690417e+09  1.768672   817.75\n",
      "3272  1.690417e+09  1.764828   818.00\n",
      "...            ...       ...      ...\n",
      "8850  1.690418e+09  2.102017  2212.50\n",
      "8851  1.690418e+09  2.177616  2212.75\n",
      "8852  1.690418e+09  2.162240  2213.00\n",
      "8853  1.690418e+09  1.921350  2213.25\n",
      "8854  1.690418e+09  1.627925  2213.50\n",
      "\n",
      "[5587 rows x 3 columns]\n",
      "HR          Timestamp  Heart rate  Second\n",
      "817   1.690417e+09      109.00   817.0\n",
      "818   1.690417e+09      109.07   818.0\n",
      "819   1.690417e+09      109.22   819.0\n",
      "820   1.690417e+09      109.42   820.0\n",
      "821   1.690417e+09      109.58   821.0\n",
      "...            ...         ...     ...\n",
      "2199  1.690418e+09       95.28  2199.0\n",
      "2200  1.690418e+09       94.75  2200.0\n",
      "2201  1.690418e+09       94.27  2201.0\n",
      "2202  1.690418e+09       93.83  2202.0\n",
      "2203  1.690418e+09       93.32  2203.0\n",
      "\n",
      "[1387 rows x 3 columns]\n",
      "ACC_hx           Timestamp  Acceleration_X  Acceleration_Y  Acceleration_Z  \\\n",
      "26140  1.690417e+09           -61.0           -23.0            -6.0   \n",
      "26141  1.690417e+09           -64.0           -23.0            -6.0   \n",
      "26142  1.690417e+09           -62.0           -23.0            -7.0   \n",
      "26143  1.690417e+09           -61.0           -24.0            -6.0   \n",
      "26144  1.690417e+09           -61.0           -25.0            -6.0   \n",
      "...             ...             ...             ...             ...   \n",
      "70837  1.690418e+09            31.0            16.0            52.0   \n",
      "70838  1.690418e+09            29.0            17.0            52.0   \n",
      "70839  1.690418e+09            27.0            18.0            52.0   \n",
      "70840  1.690418e+09            27.0            17.0            51.0   \n",
      "70841  1.690418e+09            29.0            18.0            49.0   \n",
      "\n",
      "           Second  \n",
      "26140   816.87500  \n",
      "26141   816.90625  \n",
      "26142   816.93750  \n",
      "26143   816.96875  \n",
      "26144   817.00000  \n",
      "...           ...  \n",
      "70837  2213.65625  \n",
      "70838  2213.68750  \n",
      "70839  2213.71875  \n",
      "70840  2213.75000  \n",
      "70841  2213.78125  \n",
      "\n",
      "[44702 rows x 5 columns]\n",
      "ACC_e4           Timestamp  Acc_X       Second  Acc_Y  Acc_Z\n",
      "0      1.690417e+09  103.0     0.000000   29.0 -208.0\n",
      "1      1.690417e+09   99.0     0.015625   31.0 -210.0\n",
      "2      1.690417e+09   90.0     0.031250   30.0 -223.0\n",
      "3      1.690417e+09   86.0     0.046875   30.0 -226.0\n",
      "4      1.690417e+09   86.0     0.062500   40.0 -216.0\n",
      "...             ...    ...          ...    ...    ...\n",
      "89392  1.690418e+09 -232.0  1396.750000   58.0 -103.0\n",
      "89393  1.690418e+09 -231.0  1396.765625   59.0 -103.0\n",
      "89394  1.690418e+09 -233.0  1396.781250   58.0 -103.0\n",
      "89395  1.690418e+09 -232.0  1396.796875   61.0 -101.0\n",
      "89396  1.690418e+09 -233.0  1396.812500   57.0 -104.0\n",
      "\n",
      "[89397 rows x 5 columns]\n",
      "rot_label [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for key in p_calib[p]:\n",
    "    print(key,(p_calib[p][key]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all_dict.pkl', 'all_dict_archive10-10-2023.pkl', 'all_dict_archive10-8-2023.pkl', 'parsingSurvey.pdf', 'Participant_12_RADWearStudy.csv', 'Participant_14_RADWearStudy.csv', 'Participant_16_RADWearStudy.csv', 'Participant_17_RADWearStudy.csv', 'Participant_18_RADWearStudy.csv', 'Participant_20_RADWearStudy.csv', 'Participant_21_RADWearStudy.csv', 'Participant_4_RADWearStudy.csv', 'Participant_5_RADWearStudy.csv', 'Participant_7_RADWearStudy.csv', 'Participant_9_RADWearStudy.csv', 'readme.txt', 'redcap_calib_dict.pkl', 'redcap_df.pkl', 'redcap_df_2nd.pkl', 'redcap_dict.pkl', 'redcap_dict_1st.pkl']\n"
     ]
    }
   ],
   "source": [
    "radwear_path = '/mnt/c/Users/alkurdi/Desktop/Vansh/data/RADWear/'\n",
    "redcap_path = radwear_path + 'REDCap responses/'\n",
    "print(os.listdir(redcap_path))\n",
    "#redcap_df_2nd.pkl\n",
    "with open(redcap_path + 'redcap_dict_1st.pkl', 'rb') as f:\n",
    "    redcap_dict_1st = pickle.load(f)\n",
    "with open(redcap_path + 'redcap_df_2nd.pkl', 'rb') as f:\n",
    "    redcap_df_2nd = pickle.load(f)\n",
    "#redcap_dict_1st.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_info_dict': {'parq_you_timestamp': '2023-07-14 21:44:03',\n",
       "  'parq_1': '1',\n",
       "  'parq_2': '1',\n",
       "  'parq_3': '1',\n",
       "  'parq_4': '1',\n",
       "  'parq_5': '1',\n",
       "  'parq_6': '1',\n",
       "  'parq_7': '1',\n",
       "  'signed_name': 'signature_2023-07-14_2144.png',\n",
       "  'parq_you_complete': '2',\n",
       "  'hads_timestamp': '2023-07-14 21:45:47',\n",
       "  'hads_tense': '1',\n",
       "  'hads_slowed': '0',\n",
       "  'hads_enjoy': '0',\n",
       "  'hads_butterflies': '0',\n",
       "  'hads_frightened': '0',\n",
       "  'hads_appearance': '0',\n",
       "  'hads_laugh': '0',\n",
       "  'hads_restless': '0',\n",
       "  'hads_worrying': '1',\n",
       "  'hads_enjoyment': '0',\n",
       "  'hads_cheerful': '0',\n",
       "  'hads_panic': '0',\n",
       "  'hads_relaxed': '0',\n",
       "  'hads_tvenjoy': '0',\n",
       "  'hads_complete': '2',\n",
       "  'pre_rotation_questionnaire_timestamp': '2023-07-14 21:53:32',\n",
       "  'internal_medicine_pre': '7',\n",
       "  'surgery_pre': '6',\n",
       "  'obstetrics_gynecology_pre': '1',\n",
       "  'pediatrics_pre': '3',\n",
       "  'psychiatry_pre': '2',\n",
       "  'family_medicine_pre': '8',\n",
       "  'neurology_pre': '5',\n",
       "  'elective_pre': '4',\n",
       "  'a_pre': '9',\n",
       "  'b_pre': '9',\n",
       "  'c_pre': '5',\n",
       "  'd_pre': '7',\n",
       "  'e_pre': '1',\n",
       "  'f_pre': '3',\n",
       "  'g_pre': '7',\n",
       "  'h_pre': '2',\n",
       "  'elective': 'PMR and Gastro',\n",
       "  'identify_rotation_max_pre': '1',\n",
       "  'date_rotation_max': '1/2/24-2/24/24',\n",
       "  'identify_sec_rotation_pre': '2',\n",
       "  'date_sec_rotation_max': '10/23/23-12/16/23',\n",
       "  'identify_rotation_min_pre': '6',\n",
       "  'date_rotation_min': '6/5/23-7/15/23',\n",
       "  'pre_rotation_questionnaire_complete': '2',\n",
       "  'redcap_repeat_instance': '1',\n",
       "  'baseline_calibration_timestamp': '2023-07-27 00:39:27',\n",
       "  'calibration_checklist___1': '1',\n",
       "  'calibration_checklist___2': '1',\n",
       "  'calibration_checklist___3': '1',\n",
       "  'calibration_checklist___4': '1',\n",
       "  'calibration_checklist___5': '1',\n",
       "  'check_equipment': '1',\n",
       "  'calm_cal_x2': '4',\n",
       "  'secure_cal_x2': '4',\n",
       "  'tense_cal_x2': '2',\n",
       "  'regretful_cal_x2': '2',\n",
       "  'ease_cal_x2': '3',\n",
       "  'upset_cal_x2': '1',\n",
       "  'worrying_cal_x2': '1',\n",
       "  'rested_cal_x2': '3',\n",
       "  'anxious_cal_x2': '2',\n",
       "  'comfort_cal_x2': '4',\n",
       "  'self_conf_cal_x2': '2',\n",
       "  'nervous_cal_x2': '2',\n",
       "  'jittery_cal_x2': '1',\n",
       "  'strun_cal_x2': '1',\n",
       "  'relaxed_cal_x2': '4',\n",
       "  'content_cal_x2': '4',\n",
       "  'worried_cal_x2': '2',\n",
       "  'excited_cal_x2': '1',\n",
       "  'joyful_cal_x2': '3',\n",
       "  'pleasant_cal_x2': '3',\n",
       "  'calm_cal_y6': '4',\n",
       "  'tense_cal_y6': '1',\n",
       "  'upset_cal_y6': '1',\n",
       "  'relax_cal_y6': '4',\n",
       "  'content_cal_y6': '4',\n",
       "  'worried_cal_y6': '2',\n",
       "  'calm_cal_y6_post': '4',\n",
       "  'tense_cal_y6_post': '1',\n",
       "  'upset_cal_y6_post': '1',\n",
       "  'relax_cal_y6_post': '4',\n",
       "  'content_cal_y6_post': '4',\n",
       "  'worry_cal_y6_post': '1',\n",
       "  'calm_cal_y6_cold': '2',\n",
       "  'tense_cal_y6_cold': '3',\n",
       "  'upset_cal_y6_cold': '1',\n",
       "  'relax_cal_y6_cold': '2',\n",
       "  'content_cal_y6_cold': '3',\n",
       "  'worry_cal_y6_cold': '1',\n",
       "  'baseline_calibration_complete': '2'},\n",
       " 'local_info_dict': {'daily_checkin_week_arm_1/daily_checkin_day_1/instance1': {'daily_checkin_timestamp': '2023-08-29 01:04:36',\n",
       "   'daily_check_in_date': '2023-08-28',\n",
       "   'synce_reminder': '0',\n",
       "   'daily_feeling': '8',\n",
       "   'daily_distressed_level': '3',\n",
       "   'daily_covid_contact': '2',\n",
       "   'daily_covid_team_contact': '2',\n",
       "   'daily_contact_in_rotation': '3',\n",
       "   'daily_anxious_level': '4',\n",
       "   'daily_overall_anxiety': '3',\n",
       "   'tag_event_0': '1',\n",
       "   'daily_anxious_event': 'Meeting new doc, running late to first day',\n",
       "   'tag_event_1': '0',\n",
       "   'daily_other_event_detail': '',\n",
       "   'daily_time_anxiety': '0',\n",
       "   'daily_anxiety_recall': '',\n",
       "   'daily_anxiety_event': '',\n",
       "   'daily_checkin_complete': '2'},\n",
       "  'daily_checkin_week_arm_1/daily_checkin_day_2/instance2': {'daily_checkin_timestamp': '2023-08-29 23:03:52',\n",
       "   'daily_check_in_date': '2023-08-29',\n",
       "   'synce_reminder': '1',\n",
       "   'daily_feeling': '8',\n",
       "   'daily_distressed_level': '2',\n",
       "   'daily_covid_contact': '2',\n",
       "   'daily_covid_team_contact': '2',\n",
       "   'daily_contact_in_rotation': '3',\n",
       "   'daily_anxious_level': '2',\n",
       "   'daily_overall_anxiety': '2',\n",
       "   'tag_event_0': '1',\n",
       "   'daily_anxious_event': 'Event around 8:30 was me realizing that the doctor already went to see the patient so I didnt get to see them. Next event was struggling to put lead protection on for CT scan. Last event lasted around 10 mins and was me intervieiwing patient. Other events lasted 2 minites.',\n",
       "   'tag_event_1': '0',\n",
       "   'daily_other_event_detail': '',\n",
       "   'daily_time_anxiety': '0',\n",
       "   'daily_anxiety_recall': '',\n",
       "   'daily_anxiety_event': '',\n",
       "   'daily_checkin_complete': '2'},\n",
       "  'daily_checkin_week_arm_1/daily_checkin_day_3/instance1': {'daily_checkin_timestamp': '2023-08-30 23:20:43',\n",
       "   'daily_check_in_date': '2023-08-30',\n",
       "   'synce_reminder': '1',\n",
       "   'daily_feeling': '9',\n",
       "   'daily_distressed_level': '2',\n",
       "   'daily_covid_contact': '2',\n",
       "   'daily_covid_team_contact': '2',\n",
       "   'daily_contact_in_rotation': '2',\n",
       "   'daily_anxious_level': '2',\n",
       "   'daily_overall_anxiety': '3',\n",
       "   'tag_event_0': '1',\n",
       "   'daily_anxious_event': '8 event was waiting for doctor for 30 mins not knowing when he would come, event around 1 pm was few mins long and was anticipating a test score result back, today was my birthday so less anxiety overall',\n",
       "   'tag_event_1': '0',\n",
       "   'daily_other_event_detail': '',\n",
       "   'daily_time_anxiety': '0',\n",
       "   'daily_anxiety_recall': '',\n",
       "   'daily_anxiety_event': '',\n",
       "   'daily_checkin_complete': '2'},\n",
       "  'daily_checkin_week_arm_1/daily_checkin_day_4/instance1': {'daily_checkin_timestamp': '2023-09-01 02:06:10',\n",
       "   'daily_check_in_date': '2023-08-31',\n",
       "   'synce_reminder': '1',\n",
       "   'daily_feeling': '8',\n",
       "   'daily_distressed_level': '2',\n",
       "   'daily_covid_contact': '2',\n",
       "   'daily_covid_team_contact': '2',\n",
       "   'daily_contact_in_rotation': '2',\n",
       "   'daily_anxious_level': '2',\n",
       "   'daily_overall_anxiety': '2',\n",
       "   'tag_event_0': '1',\n",
       "   'daily_anxious_event': 'First event around 8am was me getting to the hospital too early thinking there was miscommunication on when to arrive.',\n",
       "   'tag_event_1': '0',\n",
       "   'daily_other_event_detail': '',\n",
       "   'daily_time_anxiety': '0',\n",
       "   'daily_anxiety_recall': '',\n",
       "   'daily_anxiety_event': '',\n",
       "   'daily_checkin_complete': '2'},\n",
       "  'daily_checkin_week_arm_1/daily_checkin_day_5/instance1': {'daily_checkin_timestamp': '2023-09-01 22:52:05',\n",
       "   'daily_check_in_date': '2023-09-01',\n",
       "   'synce_reminder': '1',\n",
       "   'daily_feeling': '9',\n",
       "   'daily_distressed_level': '2',\n",
       "   'daily_covid_contact': '2',\n",
       "   'daily_covid_team_contact': '2',\n",
       "   'daily_contact_in_rotation': '2',\n",
       "   'daily_anxious_level': '1',\n",
       "   'daily_overall_anxiety': '2',\n",
       "   'tag_event_0': '0',\n",
       "   'daily_anxious_event': '',\n",
       "   'tag_event_1': '0',\n",
       "   'daily_other_event_detail': '',\n",
       "   'daily_time_anxiety': '0',\n",
       "   'daily_anxiety_recall': '',\n",
       "   'daily_anxiety_event': '',\n",
       "   'daily_checkin_complete': '2'},\n",
       "  'daily_checkin_week_arm_1b/daily_checkin_day_7/instance1': {'daily_checkin_timestamp': '2023-09-05 23:12:40',\n",
       "   'daily_check_in_date': '2023-09-05',\n",
       "   'synce_reminder': '1',\n",
       "   'daily_feeling': '4',\n",
       "   'daily_distressed_level': '7',\n",
       "   'daily_covid_contact': '2',\n",
       "   'daily_covid_team_contact': '2',\n",
       "   'daily_contact_in_rotation': '2',\n",
       "   'daily_anxious_level': '4',\n",
       "   'daily_overall_anxiety': '6',\n",
       "   'tag_event_0': '1',\n",
       "   'daily_anxious_event': 'running late and in argument lasted 10 mins',\n",
       "   'tag_event_1': '0',\n",
       "   'daily_other_event_detail': '',\n",
       "   'daily_time_anxiety': '0',\n",
       "   'daily_anxiety_recall': '',\n",
       "   'daily_anxiety_event': '',\n",
       "   'daily_checkin_complete': '2'},\n",
       "  'daily_checkin_week_arm_1b/daily_checkin_day_8/instance1': {'daily_checkin_timestamp': '2023-09-06 23:22:47',\n",
       "   'daily_check_in_date': '2023-09-06',\n",
       "   'synce_reminder': '1',\n",
       "   'daily_feeling': '8',\n",
       "   'daily_distressed_level': '2',\n",
       "   'daily_covid_contact': '2',\n",
       "   'daily_covid_team_contact': '2',\n",
       "   'daily_contact_in_rotation': '2',\n",
       "   'daily_anxious_level': '2',\n",
       "   'daily_overall_anxiety': '2',\n",
       "   'tag_event_0': '0',\n",
       "   'daily_anxious_event': '',\n",
       "   'tag_event_1': '0',\n",
       "   'daily_other_event_detail': '',\n",
       "   'daily_time_anxiety': '0',\n",
       "   'daily_anxiety_recall': '',\n",
       "   'daily_anxiety_event': '',\n",
       "   'daily_checkin_complete': '2'},\n",
       "  'daily_checkin_week_arm_1b/daily_checkin_day_9/instance1': {'daily_checkin_timestamp': '2023-09-07 23:01:38',\n",
       "   'daily_check_in_date': '2023-09-07',\n",
       "   'synce_reminder': '1',\n",
       "   'daily_feeling': '9',\n",
       "   'daily_distressed_level': '2',\n",
       "   'daily_covid_contact': '2',\n",
       "   'daily_covid_team_contact': '2',\n",
       "   'daily_contact_in_rotation': '2',\n",
       "   'daily_anxious_level': '2',\n",
       "   'daily_overall_anxiety': '2',\n",
       "   'tag_event_0': '0',\n",
       "   'daily_anxious_event': '',\n",
       "   'tag_event_1': '0',\n",
       "   'daily_other_event_detail': '',\n",
       "   'daily_time_anxiety': '0',\n",
       "   'daily_anxiety_recall': '',\n",
       "   'daily_anxiety_event': '',\n",
       "   'daily_checkin_complete': '2'},\n",
       "  'daily_checkin_week_arm_1b/daily_checkin_day_10/instance1': {'daily_checkin_timestamp': '2023-09-09 01:09:35',\n",
       "   'daily_check_in_date': '2023-09-08',\n",
       "   'synce_reminder': '1',\n",
       "   'daily_feeling': '9',\n",
       "   'daily_distressed_level': '2',\n",
       "   'daily_covid_contact': '2',\n",
       "   'daily_covid_team_contact': '2',\n",
       "   'daily_contact_in_rotation': '2',\n",
       "   'daily_anxious_level': '1',\n",
       "   'daily_overall_anxiety': '2',\n",
       "   'tag_event_0': '0',\n",
       "   'daily_anxious_event': '',\n",
       "   'tag_event_1': '0',\n",
       "   'daily_other_event_detail': '',\n",
       "   'daily_time_anxiety': '0',\n",
       "   'daily_anxiety_recall': '',\n",
       "   'daily_anxiety_event': '',\n",
       "   'daily_checkin_complete': '2'},\n",
       "  'daily_checkin_week_arm_1c/daily_checkin_day_1/instance1': {}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(redcap_dict_1st[16])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>daily_check_in_date</th>\n",
       "      <th>daily_anxious_level</th>\n",
       "      <th>daily_overall_anxiety</th>\n",
       "      <th>daily_distressed_level</th>\n",
       "      <th>daily_feeling</th>\n",
       "      <th>daily_covid_contact</th>\n",
       "      <th>daily_covid_team_contact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>21</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>21</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>21</td>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>21</td>\n",
       "      <td>2023-09-07</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>21</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant daily_check_in_date  daily_anxious_level  \\\n",
       "0             7          2022-08-30                    8   \n",
       "1             7          2022-08-31                    9   \n",
       "2             7          2022-09-01                    9   \n",
       "3             7          2022-09-02                   10   \n",
       "4             7          2022-09-06                    9   \n",
       "..          ...                 ...                  ...   \n",
       "110          21          2023-08-29                    5   \n",
       "111          21          2023-08-30                    4   \n",
       "112          21          2023-08-31                    2   \n",
       "113          21          2023-09-07                    4   \n",
       "114          21          2023-09-01                    6   \n",
       "\n",
       "     daily_overall_anxiety  daily_distressed_level  daily_feeling  \\\n",
       "0                        2                       2              2   \n",
       "1                        1                       1              2   \n",
       "2                        1                       1              1   \n",
       "3                        1                       1              1   \n",
       "4                        3                       3              5   \n",
       "..                     ...                     ...            ...   \n",
       "110                      3                       3              5   \n",
       "111                      7                       4              5   \n",
       "112                      3                       5              6   \n",
       "113                      8                       6              8   \n",
       "114                      3                       4              4   \n",
       "\n",
       "     daily_covid_contact  daily_covid_team_contact  \n",
       "0                      1                         1  \n",
       "1                      2                         2  \n",
       "2                      2                         2  \n",
       "3                      2                         2  \n",
       "4                      2                         2  \n",
       "..                   ...                       ...  \n",
       "110                    2                         2  \n",
       "111                    2                         2  \n",
       "112                    2                         2  \n",
       "113                    2                         2  \n",
       "114                    2                         2  \n",
       "\n",
       "[115 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redcap_df_2nd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fb_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
