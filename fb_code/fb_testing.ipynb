{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fb testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import dask as pd\n",
    "import pandas as pd_old\n",
    "import warnings\n",
    "import utils\n",
    "import heartpy as hp\n",
    "from ECG_feature_extractor_1001 import *\n",
    "# import time \n",
    "import time\n",
    "from datetime import datetime\n",
    "from biosppy.signals import ecg\n",
    "from feature_extraction import SubjectData, compute_features, get_samples, combine_files\n",
    "\n",
    "# To ignore all warnings:\n",
    "warnings.filterwarnings(\"ignore\", module=\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_IN_SECONDS = 60\n",
    "stride = 1\n",
    "label_dict = {'baseline': 1, 'stress': 2, 'amusement': 0}\n",
    "int_to_label = {1: 'baseline', 2: 'stress', 0: 'amusement'}\n",
    "feat_names = None\n",
    "loadPath = '../data/WESAD'\n",
    "savePath = '../data/GN-WESAD'\n",
    "subject_feature_path = '/subject_feats'\n",
    "onedrive = '/mnt/d/Users/alkurdi/OneDrive - University of Illinois - Urbana/data/GN-WESAD'\n",
    "n_samples = 10 \n",
    "subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "snrs = [ 0.0001, 0.001, 0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6] #0.00001,\n",
    "fb_model_list = ['DT', 'RF', 'SVM', 'LDA', 'KNN', 'AdaBoost']\n",
    "\n",
    "if not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "if not os.path.exists(savePath + subject_feature_path):\n",
    "    os.makedirs(savePath + subject_feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed snrs :[0.0001, 0.001, 0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
      "incomplete snrs :[]\n"
     ]
    }
   ],
   "source": [
    "def get_processing_status(snrs, subject_ids, onedrive, n_samples= 10):\n",
    "    #bads are the ones that do not have the gaussian-modified data.  \n",
    "    bads = []\n",
    "    bad_snrs = []\n",
    "    bad_subjects = []\n",
    "    bad_ns = []\n",
    "    completed_snrs = []\n",
    "    for n_i in range(n_samples):\n",
    "        for snr in snrs:\n",
    "            for subject_id in subject_ids:\n",
    "                #print(snr)\n",
    "                \n",
    "                #print(f'{onedrive}/n_{n_i}/snr_{snr}/S{subject_id}/{a}')\n",
    "                try: \n",
    "                    a = os.listdir(f'{onedrive}/n_{n_i}/snr_{str(snr)}/S{subject_id}')\n",
    "                    a[0]\n",
    "                    completed_snrs.append(snr)\n",
    "                except:\n",
    "                    bads.append(f'n_{n_i}/snr_{snr}/S{subject_id}')\n",
    "                    bad_snrs.append(snr)\n",
    "                    bad_subjects.append(subject_id)\n",
    "                    bad_ns.append(n_i)\n",
    "\n",
    "    bad_snrs = sorted(set(bad_snrs))\n",
    "    bad_subjects = sorted(set(bad_subjects))\n",
    "    bad_ns = sorted(set(bad_ns))\n",
    "    completed_snrs = sorted(set(completed_snrs))\n",
    "    #printing after checking\n",
    "    print(f'completed snrs :{completed_snrs}')\n",
    "    print(f'incomplete snrs :{bad_snrs}')\n",
    "get_processing_status(snrs, subject_ids, onedrive, n_samples= n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = []\n",
    "for i in os.listdir(f'{loadPath}/subject_feats'):\n",
    "    #print (i)\n",
    "    if 'S' not in i[0]:\n",
    "        dataset_list.append(i)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "\n",
    "for each_dataset in dataset_list:\n",
    "    for snr in snrs:\n",
    "        for model in fb_model_list:\n",
    "            pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNR</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WESAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WESAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SNR Accuracy F1-Score dataset\n",
       "SVM   1        5      NaN   WESAD\n",
       "RF    1        5      NaN   WESAD"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_table = pd_old.DataFrame(columns=['SNR', 'Accuracy', 'F1-Score', 'dataset'])\n",
    "results_table.loc[str('SVM')] = pd_old.Series({'SNR':1, 'Accuracy':5, 'F1 Score':2, 'dataset':'WESAD'})\n",
    "results_table.loc[str('RF')] = pd_old.Series({'SNR':1, 'Accuracy':5, 'F1 Score':2, 'dataset':'WESAD'})\n",
    "'''\n",
    "fb_model_list = ['SVM', 'RF']\n",
    "for model in fb_model_list:\n",
    "    for i in range(len(snrs)):\n",
    "        results_table.loc[str(model) + str(snrs[i])] = pd.Series({'SNR':snrs[i], 'Accuracy':svm_accuracy[i], 'F1 Score':2, 'dataset':'WESAD'})\n",
    "'''\n",
    "display(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "ecg_biosppy = ecg\n",
    "ecg = None\n",
    "fs_ecg = 700\n",
    "fs_ppg = 64\n",
    "subject_id=2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = SubjectData(main_path=loadPath, subject_number=subject_id)\n",
    "data_dict = subject.get_wrist_and_chest_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg = data_dict['ECG'][40000:60000].flatten()\n",
    "ppg = data_dict['BVP'][int(40000/700*64):int(60000/700*64)].flatten()\n",
    "print('ecg len', len(ecg))\n",
    "print('ppg len', len(ppg))\n",
    "\n",
    "\n",
    "#testing for ECG\n",
    "\n",
    "now = time.time()\n",
    "#wd4, m4 = hp.process(ecg, fs_ecg)\n",
    "#print('hp.process execution time is %5.2fs' % (time.time()-now))\n",
    "\n",
    "now = time.time()\n",
    "#pack2, ecgout2, time_dict2 = freq_ratio_hybrid(ecg, fs_ecg, RR1, method='welch', factor = 1)\n",
    "#print('freq_ratio_hybrid execution time is %5.2fs' % (time.time()-now))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.time()\n",
    "BS_signal_analysis3, pack3, ecg_out3 = analyze_ecg(ecg, fs_ecg)\n",
    "print('analyze_ecg execution time is ', now-time.time())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg = data_dict['ECG'][10000:80000].flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2154369309.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[140], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    pack, ppg, RR, time_dict = freq_ratio( ppg, fs_ppg, method='welch', factor = 1):\u001b[0m\n\u001b[0m                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#testing for PPG\n",
    "\n",
    "now = datetime.now()\n",
    "pack, ppg, RR, time_dict = freq_ratio( ppg, fs_ppg, method='welch', factor = 1)\n",
    "print('freq_ratio execution time is ', now-time.time())\n",
    "\n",
    "now = datetime.now()\n",
    "pack, ppg, time_dict = freq_ratio_hybrid(ppg, fs_ppg, method='welch', factor = 1)\n",
    "print('freq_ratio_hybrid execution time is ', now-time.time())\n",
    "\n",
    "now = datetime.now()\n",
    "BS_signal_analysis, pack, ppg_out = analyze_ecg(ppg, fs_ppg)\n",
    "print('analyze_ecg execution time is ', now-time.time())\n",
    "\n",
    "now = datetime.now()\n",
    "wd, m = hp.process(ppg, fs_ppg)\n",
    "print('hp.process execution time is ', now-time.time())\n",
    "\n",
    "now = datetime.now()\n",
    "pack, ppg, RR = freq_ratio_fast( ppg, fs_ppg, method='welch', factor = 1)\n",
    "print('freq_ratio_fast execution time is ', now-time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "import logging\n",
    "\n",
    "\n",
    "def combine_noiZ_files(subject_ids):\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    logging.basicConfig(level=logging.DEBUG, filename=today+'-combine.log', filemode='w', force=True)\n",
    "    logging.info('Started')\n",
    "    print('total number of combines: ', len(snrs)*n_samples)\n",
    "    df_list = []\n",
    "    i = 0\n",
    "    for snr in snrs:\n",
    "        for n_i in range(n_samples):\n",
    "            for s in subject_ids:\n",
    "                df = pd_old.read_csv(f'{savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/S{s}_feats.csv', index_col=0)\n",
    "                df['subject'] = s\n",
    "                df_list.append(df)\n",
    "            df = pd_old.concat(df_list)\n",
    "            df['label'] = (df['0'].astype(str) + df['1'].astype(str) + df['2'].astype(str)).apply(lambda x: x.index('1'))\n",
    "            df.drop(['0', '1', '2'], axis=1, inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            now = datetime.now().strftime('%Y-%m-%d')\n",
    "            df.to_csv(f'{savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/{now}_feats_filt.csv')\n",
    "            i+=1\n",
    "            logging.info(f'Saved file to: {savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/{today}_feats_filt.csv  {i}/{len(snrs)*n_samples}')\n",
    "            print('Saved file to: ',f'.../n_{n_i}/snr_{snr}{subject_feature_path}/{now}_feats_filt.csv   {i}/{len(snrs)*n_samples}')\n",
    "            counts = df['label'].value_counts()\n",
    "            logging.info('Number of samples per class:')\n",
    "            logging.info('baseline: {0[1]}; stress: {1[1]}; amusement: {2[1]} '.format(*list(zip(counts.index, counts.values))))\n",
    "    logging.info('all done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of combines:  110\n",
      "Saved file to:  .../n_0/snr_0.0001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_1/snr_0.0001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_2/snr_0.0001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_3/snr_0.0001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_4/snr_0.0001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_5/snr_0.0001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_6/snr_0.0001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_7/snr_0.0001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_8/snr_0.0001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_9/snr_0.0001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_0/snr_0.001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_1/snr_0.001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_2/snr_0.001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_3/snr_0.001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_4/snr_0.001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_5/snr_0.001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_6/snr_0.001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_7/snr_0.001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_8/snr_0.001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_9/snr_0.001/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_0/snr_0.01/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_1/snr_0.01/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_2/snr_0.01/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_3/snr_0.01/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_4/snr_0.01/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_5/snr_0.01/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_6/snr_0.01/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_7/snr_0.01/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_8/snr_0.01/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_9/snr_0.01/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_0/snr_0.05/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_1/snr_0.05/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_2/snr_0.05/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_3/snr_0.05/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_4/snr_0.05/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_5/snr_0.05/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_6/snr_0.05/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_7/snr_0.05/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_8/snr_0.05/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_9/snr_0.05/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_0/snr_0.1/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_1/snr_0.1/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_2/snr_0.1/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_3/snr_0.1/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_4/snr_0.1/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_5/snr_0.1/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_6/snr_0.1/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_7/snr_0.1/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_8/snr_0.1/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_9/snr_0.1/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_0/snr_0.15/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_1/snr_0.15/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_2/snr_0.15/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_3/snr_0.15/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_4/snr_0.15/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_5/snr_0.15/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_6/snr_0.15/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_7/snr_0.15/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_8/snr_0.15/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_9/snr_0.15/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_0/snr_0.2/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_1/snr_0.2/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_2/snr_0.2/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_3/snr_0.2/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_4/snr_0.2/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_5/snr_0.2/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_6/snr_0.2/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_7/snr_0.2/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_8/snr_0.2/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_9/snr_0.2/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_0/snr_0.3/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_1/snr_0.3/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_2/snr_0.3/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_3/snr_0.3/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_4/snr_0.3/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_5/snr_0.3/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_6/snr_0.3/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_7/snr_0.3/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_8/snr_0.3/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_9/snr_0.3/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_0/snr_0.4/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_1/snr_0.4/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_2/snr_0.4/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_3/snr_0.4/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_4/snr_0.4/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_5/snr_0.4/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_6/snr_0.4/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_7/snr_0.4/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_8/snr_0.4/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_9/snr_0.4/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_0/snr_0.5/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_1/snr_0.5/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_2/snr_0.5/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_3/snr_0.5/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_4/snr_0.5/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_5/snr_0.5/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_6/snr_0.5/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_7/snr_0.5/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_8/snr_0.5/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_9/snr_0.5/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_0/snr_0.6/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_1/snr_0.6/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_2/snr_0.6/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_3/snr_0.6/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_4/snr_0.6/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_5/snr_0.6/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_6/snr_0.6/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_7/snr_0.6/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_8/snr_0.6/subject_feats/2023-11-12_feats_filt.csv\n",
      "Saved file to:  .../n_9/snr_0.6/subject_feats/2023-11-12_feats_filt.csv\n"
     ]
    }
   ],
   "source": [
    "combine_noiZ_files(subject_ids)\n",
    "# took 19m 30s to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging\n",
    "now = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "def process_subject_file(snr, n_i, s):\n",
    "    file_path = f'{savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/S{s}_feats.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path, index_col=0)\n",
    "        df['subject'] = s\n",
    "        return df\n",
    "    return None\n",
    "\n",
    "def combine_noiZ_files(subjects):\n",
    "    now = datetime.now().strftime('%Y-%m-%d')\n",
    "    logging.basicConfig(level=logging.INFO, filename=now+'-combine.log', filemode='w', force=True)\n",
    "\n",
    "    for snr in snrs:\n",
    "        for n_i in range(n_samples):\n",
    "            # Parallelize file reading\n",
    "            with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "                futures = [executor.submit(process_subject_file, snr, n_i, s) for s in subjects]\n",
    "                df_list = [future.result() for future in futures if future.result() is not None]\n",
    "\n",
    "            if df_list:\n",
    "                df = pd.concat(df_list)\n",
    "                df['label'] = df[['0', '1', '2']].idxmax(axis=1)\n",
    "                df.drop(['0', '1', '2'], axis=1, inplace=True)\n",
    "                df.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "                df.to_csv(f'{savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/{now}_feats_filt.csv')\n",
    "                logging.info('-' * 20)\n",
    "                logging.info(f'Saved file to: {savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/{now}_feats_filt.csv')\n",
    "                \n",
    "                counts = df['label'].value_counts()\n",
    "                logging.info('Number of samples per class:')\n",
    "                logging.info('baseline: {0[1]}; stress: {1[1]}; amusement: {2[1]} '.format(*list(zip(counts.index, counts.values))))\n",
    "    logging.info('all done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples per class:\n",
      "baseline: 119; stress: 61; amusement: 34 \n"
     ]
    }
   ],
   "source": [
    "n_i = 5\n",
    "s = 2\n",
    "snr = 0.6\n",
    "df = pd_old.read_csv(f'{savePath}/n_{n_i}/snr_{snr}{subject_feature_path}/S{subject_id}_feats.csv', index_col=0)\n",
    "df['subject'] = s\n",
    "#df_list.append(df)\n",
    "#f = pd_old.concat(df_list)\n",
    "df['label'] = (df['0'].astype(str) + df['1'].astype(str) + df['2'].astype(str)).apply(lambda x: x.index('1'))\n",
    "df.drop(['0', '1', '2'], axis=1, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "counts = df['label'].value_counts()\n",
    "print('Number of samples per class:')\n",
    "print('baseline: {0[1]}; stress: {1[1]}; amusement: {2[1]} '.format(*list(zip(counts.index, counts.values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_noiZ_files(subject_ids)\n",
    "#this paralellized took 34seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "def smash(s):\n",
    "    global i \n",
    "    s = s+1\n",
    "    i+=1\n",
    "    #s = damnit(s)\n",
    "    print(i)\n",
    "    return s\n",
    "def damnit(s):\n",
    "    global i \n",
    "    s = s+10\n",
    "    i=s\n",
    "    print(i)\n",
    "    return s\n",
    "\n",
    "for f in range(10):\n",
    "    smash(2)\n",
    "\n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:GN-WESAD models ran and results generated and saved in: \n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, filemode='w', force=True)\n",
    "logging.info('GN-WESAD models ran and results generated and saved in: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023.11.13-05.22AM'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now().strftime('%Y.%m.%d-%H.%M%p')\n",
    "now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fb_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
