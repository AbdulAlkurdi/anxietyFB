{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'modified by abdul alkurdi; 10/05/2023'\n",
    "\n",
    "import pandas as pd\n",
    "#import cudf\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.signal import correlate\n",
    "#import cupy as cp\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal, stats\n",
    "#import peakutils, wfdb, pywt\n",
    "import csv\n",
    "import os, statistics\n",
    "from datetime import datetime\n",
    "#import heartpy as hp\n",
    "import json\n",
    "%matplotlib widget \n",
    "# import neurokit2 as nk\n",
    "\n",
    "from syncfcns import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#####   force update ?     #####\n",
    "################################\n",
    "force_update = False\n",
    "\n",
    "\n",
    "radwear_path = '/mnt/c/Users/alkurdi/Desktop/Vansh/data/RADWear/'\n",
    "redcap_path = radwear_path + 'REDCap responses/'\n",
    "\n",
    "# load all participant meta data\n",
    "with open(radwear_path + 'all_p_metadata.json', 'rb') as f:\n",
    "    all_p_metadata = json.load(f)\n",
    "# load all participant redcap data\n",
    "\n",
    "with open(redcap_path + 'redcap_df_2nd.pkl', 'rb') as f:\n",
    "    redcap_df = pickle.load(f)\n",
    "    \n",
    "\n",
    "list_of_participants = all_p_metadata['list of participant IDs']\n",
    "completed_participants = []\n",
    "\n",
    "\n",
    "# label definitions\n",
    "calib_dict = {'meditation': 1, 'cpt': 2, 'baseline': 0, 'other': 3}\n",
    "rot_anx_dict = {'calibration': 0, 'LA': 1, 'HA': 2}\n",
    "\n",
    "p_calib = {}\n",
    "p_la = {}\n",
    "p_ha = {}\n",
    "p_all = {}\n",
    "incomplete = [guy for guy in list_of_participants if guy not in completed_participants]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fcn defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant  4  already processed.\n",
      "participant  7  already processed.\n",
      "participant  9  already processed.\n",
      "participant  12  already processed.\n",
      "participant  14  already processed.\n",
      "participant  16  already processed.\n",
      "participant  17  already processed.\n",
      "participant  18  already processed.\n",
      "participant  21  already processed.\n",
      "incomplete:  []\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# p5 HA day 8 and p9 HA day 10 will be done manually.\n",
    "# redcap is marked as 0 but data is available\n",
    "#########################\n",
    "\n",
    "incomplete = [guy for guy in list_of_participants if guy not in completed_participants]\n",
    "for p in list_of_participants:\n",
    "    # check if participant pickle file exists\n",
    "    if Path(radwear_path + 'Participant ' + str(p) + '/p_' + str(p) + '.pkl').is_file():\n",
    "        # print(radwear_path+'Participant '+str(p)+'/p_'+str(p)+'.pkl')\n",
    "        print('participant ', p, ' already processed.')\n",
    "        completed_participants.append(p)\n",
    "incomplete = [guy for guy in list_of_participants if guy not in completed_participants]\n",
    "if force_update:\n",
    "    incomplete = list_of_participants\n",
    "print('incomplete: ', incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed participants:  {4, 7, 9, 12, 14, 16, 17, 18, 21}\n"
     ]
    }
   ],
   "source": [
    "redcap_calib_dict = pd.read_pickle(radwear_path+'/REDCap responses/redcap_calib_dict.pkl')\n",
    "event_type = ['calm_cal_x2', 'secure_cal_x2', 'tense_cal_x2', \n",
    "              'regretful_cal_x2', 'ease_cal_x2', 'upset_cal_x2',\n",
    "              'worrying_cal_x2', 'rested_cal_x2', 'anxious_cal_x2',\n",
    "              'comfort_cal_x2', 'self_conf_cal_x2', 'nervous_cal_x2',\n",
    "              'jittery_cal_x2', 'strun_cal_x2', 'relaxed_cal_x2',\n",
    "              'content_cal_x2', 'worried_cal_x2', 'excited_cal_x2', \n",
    "              'joyful_cal_x2', 'pleasant_cal_x2', 'calm_cal_y6', \n",
    "              'tense_cal_y6', 'upset_cal_y6', 'relax_cal_y6',\n",
    "              'content_cal_y6', 'worried_cal_y6', 'calm_cal_y6_post',\n",
    "              'tense_cal_y6_post', 'upset_cal_y6_post', 'relax_cal_y6_post',\n",
    "              'content_cal_y6_post', 'worry_cal_y6_post', 'calm_cal_y6_cold',\n",
    "              'tense_cal_y6_cold', 'upset_cal_y6_cold', 'relax_cal_y6_cold', \n",
    "              'content_cal_y6_cold', 'worry_cal_y6_cold', 'baseline_calibration_complete']\n",
    "tag_info = {4: '',\n",
    "            7: 'skip 0',\n",
    "            9: '',\n",
    "            12: '',\n",
    "            14: 'add 60 to 2',\n",
    "            16: 'skip 0',\n",
    "            17: 'skip 0',\n",
    "            18: 'skip 01',\n",
    "            19: 'skip 0',\n",
    "            21: 'skip 0',\n",
    "}\n",
    "\n",
    "p_calib = {}\n",
    "for p in incomplete:\n",
    "    print('procesing participant: ', p, ' calibration data...')\n",
    "    p_all[p] = {}\n",
    "    p_la[p] = {}\n",
    "    p_ha[p] = {}\n",
    "    p_path = radwear_path+'Participant '+str(p)\n",
    "    # load participant e4 data\n",
    "    e4sn = all_p_metadata[str(p)]['e4sn']\n",
    "    calibration_files = all_p_metadata[str(p)]['calibration']\n",
    "    LA = all_p_metadata[str(p)]['LA']\n",
    "    HA = all_p_metadata[str(p)]['HA']\n",
    "    \n",
    "    # load calibration data\n",
    "    e4_num = all_p_metadata[str(p)]['e4sn']+'_'+all_p_metadata[str(p)]['calibration'][0]\n",
    "    hx_num = str(all_p_metadata[str(p)]['calibration'][1])\n",
    "    p_calib[p] = read_sync_return(p_path, e4_num, hx_num)\n",
    "    print('marker 1')\n",
    "    #####################\n",
    "    # calibration data\n",
    "    #####################\n",
    "    \n",
    "    p_calib[p]['rot_label'] = rot_anx_dict['calibration'] * np.ones(len(p_calib[p]['ECG'])) # add label to designate calibration segment\n",
    "    # get calibration event tags \n",
    "    tags = pd.read_csv(\n",
    "        radwear_path + 'Participant ' + str(p) + '/' + e4_num + '/tags.csv', header=None\n",
    "    )\n",
    "    #print(tag_info[p])\n",
    "    tag_command = tag_info[p].split(' ')\n",
    "    \n",
    "    if len(tag_command[-1]) ==1 and tag_command[0] == 'skip':\n",
    "        tags = tags.drop(int(tag_command[-1]))\n",
    "    elif len(tag_command[-1]) ==2:\n",
    "        #print(tag_command[-1][0], tag_command[-1][1])\n",
    "        tags.drop([int(tag_command[-1][0]),int(tag_command[-1][1])], axis=0 ,inplace=True)\n",
    "    elif len(tag_command[-1]) ==1 and tag_command[0] == 'add':\n",
    "        new_row = pd.DataFrame(tags.values[-1]+60,columns=tags.columns)\n",
    "        tags = pd.concat([tags,new_row], ignore_index=True)\n",
    "    else:\n",
    "        tag_command = None\n",
    "    tags.reset_index(drop=True, inplace=True) \n",
    "\n",
    "    print('marker 2')\n",
    "    # add label to designate calibration segment. same length as bvp to make things easier\n",
    "    p_calib[p]['calib_label'] = p_calib[p]['BVP'].copy(deep=True) # add label to designate calibration segment\n",
    "    p_calib[p]['calib_label'].drop(columns=['BVP','Second'], inplace=True)\n",
    "    p_calib[p]['calib_label']['calib_label'] = 0\n",
    "    #display(p_calib[p]['calib_label'])\n",
    "    p_calib[p]['calib_label']['calib_label'][(p_calib[p]['calib_label']['Timestamp'] > tags.iloc[0].values[0]) & \\\n",
    "                                            (p_calib[p]['calib_label']['Timestamp'] < tags.iloc[1].values[0])] \\\n",
    "                                                = calib_dict['meditation']\n",
    "    p_calib[p]['calib_label']['calib_label'][(p_calib[p]['calib_label']['Timestamp'] > tags.iloc[2].values[0]) & \\\n",
    "                                                (p_calib[p]['calib_label']['Timestamp'] < tags.iloc[3].values[0])] \\\n",
    "                                                    = calib_dict['cpt']\n",
    "                                                     \n",
    "    \n",
    "    \n",
    "    #####################\n",
    "    # HA data\n",
    "    #####################\n",
    "    if all_p_metadata[str(p)]['complete days'][0] > 0:\n",
    "        # loop for LA\n",
    "        for i in range(all_p_metadata[str(p)]['complete days'][0]): \n",
    "            if not (all_p_metadata[str(p)]['RedCap available'][0][i] == 0 or all_p_metadata[str(p)]['LA'][0][i] == 0 or all_p_metadata[str(p)]['LA'][1][i] == 0): \n",
    "                print('procesing participant: ', p, ' LA day ', i+1, '...')    \n",
    "                e4_num = all_p_metadata[str(p)]['e4sn']+'_'+all_p_metadata[str(p)]['LA'][0][i]\n",
    "                hx_num = str(all_p_metadata[str(p)]['LA'][1][i])\n",
    "                \n",
    "                p_la[p][i] = read_sync_return(p_path, e4_num, hx_num)\n",
    "                p_la[p][i]['rot_label']= rot_anx_dict['LA'] * np.ones(len(p_la[p][i]['ECG'])) \n",
    "            else:\n",
    "                p_la[p][i] = {} \n",
    "    #####################\n",
    "    # LA data\n",
    "    #####################\n",
    "    if all_p_metadata[str(p)]['complete days'][1] > 0:\n",
    "        # loop for HA    \n",
    "        for j in range(all_p_metadata[str(p)]['complete days'][1]): # loop for HA\n",
    "            if not (all_p_metadata[str(p)]['RedCap available'][1][j] == 0 or all_p_metadata[str(p)]['HA'][0][j] == 0 or all_p_metadata[str(p)]['HA'][1][j] == 0): \n",
    "                print('procesing participant: ', p, ' HA day ', j+1, '...')    \n",
    "                e4_num = all_p_metadata[str(p)]['e4sn']+'_'+all_p_metadata[str(p)]['HA'][0][j]\n",
    "                hx_num = str(all_p_metadata[str(p)]['HA'][1][j])\n",
    "                \n",
    "                p_ha[p][j] = read_sync_return(p_path, e4_num, hx_num)\n",
    "                p_ha[p][j]['rot_label']= rot_anx_dict['HA'] * np.ones(len(p_ha[p][j]['ECG']))\n",
    "            else:\n",
    "                p_ha[p][j] = {}\n",
    "    \n",
    "    print('participant ', p, ' done.')\n",
    "    if True:\n",
    "        try:\n",
    "            p_all[p]['calib']= p_calib[p]\n",
    "        except:\n",
    "            print('participant ', p, ' has no calibration data.')\n",
    "            p_all[p]['calib'] = {}\n",
    "        try:    \n",
    "            p_all[p]['LA'] = p_la[p]\n",
    "        except:\n",
    "            print('participant ', p, ' has no LA data.')\n",
    "            p_all[p]['LA'] = {}      \n",
    "        try: \n",
    "            p_all[p]['HA'] = p_ha[p]\n",
    "        except:\n",
    "            print('participant ', p, ' has no HA data.')\n",
    "            p_all[p]['HA'] = {}\n",
    "        #save this participant data to a pickle file\n",
    "        \n",
    "    with open(p_path+'/p_'+str(p)+'.pkl', 'wb') as handle:\n",
    "            pickle.dump(p_all[p], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    #p_all[p].to_parquet('/p_'+str(p)+'.parquet', engine='pyarrow')\n",
    "\n",
    "    print('participant ', p, ' pickled.')\n",
    "\n",
    "    #df = pd.DataFrame.from_dict(p_all[p])\n",
    "    #df.to_parquet(p_path+'/p_'+str(p)+'.parquet')\n",
    "    #print('participant ', p, ' parqued.')\n",
    "\n",
    "    #completed_participants.append(p)\n",
    "    print('-----------------------------------')\n",
    "    e4sn = None\n",
    "    calibration_files = None \n",
    "    LA = None\n",
    "    HA = None\n",
    "    e4_num = None\n",
    "    hx_num = None\n",
    "    tags = None\n",
    "    tag_command = None\n",
    "print('completed participants: ', set(completed_participants))\n",
    "# print('incomplete participants: ', incomplete) doesn't update after loop completes them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing participant  4  in wesad-like format...\n",
      "participant  4  loaded.\n",
      "processing participant  7  in wesad-like format...\n",
      "participant  7  loaded.\n",
      "processing participant  9  in wesad-like format...\n",
      "participant  9  loaded.\n",
      "processing participant  12  in wesad-like format...\n",
      "participant  12  loaded.\n",
      "processing participant  14  in wesad-like format...\n",
      "participant  14  loaded.\n",
      "processing participant  16  in wesad-like format...\n",
      "participant  16  loaded.\n",
      "processing participant  17  in wesad-like format...\n",
      "participant  17  loaded.\n",
      "processing participant  18  in wesad-like format...\n",
      "participant  18  loaded.\n",
      "processing participant  21  in wesad-like format...\n",
      "participant  21  loaded.\n"
     ]
    }
   ],
   "source": [
    "#calib_dict = {'meditation': 1, 'cpt': 2, 'baseline': 0, 'other': 3}\n",
    "#rot_anx_dict = {'calibration': 0, 'LA': 1, 'HA': 2}\n",
    "\n",
    "\n",
    "for p in list_of_participants:\n",
    "    p_path = radwear_path+'Participant '+str(p)\n",
    "    if os.path.isfile(radwear_path + 'wesadlike_p_' + str(p) + '.pkl'):\n",
    "        print('participant ', p, ' already processed in wesad-like format.')\n",
    "    else:\n",
    "        print('processing participant ', p, ' in wesad-like format...')\n",
    "\n",
    "        with open(p_path+'/p_'+str(p)+'.pkl','rb') as handle:\n",
    "            p_one = pickle.load(handle)\n",
    "        print('participant ', p, ' loaded.')\n",
    "        p_like_wesad = {}\n",
    "        \n",
    "        \n",
    "        p_like_wesad['subject'] = p\n",
    "        p_like_wesad['label'] = np.zeros(len(p_one['calib']['ECG']))\n",
    "        p_like_wesad['signal'] = {}\n",
    "        p_like_wesad['signal']['chest'] = {}\n",
    "        p_like_wesad['signal']['wrist'] = {}\n",
    "        \n",
    "        \n",
    "        \n",
    "        p_like_wesad['calib_label'] = pd.DataFrame(p_one['calib']['calib_label'].drop(columns=['Timestamp']).values.flatten())\n",
    "        p_like_wesad['rot_label'] = pd.DataFrame(p_one['calib']['rot_label'])\n",
    "\n",
    "        p_like_wesad['signal']['chest']['ACC'] = p_one['calib']['ACC_hx'].drop(columns=['Timestamp','Second'])\n",
    "        p_like_wesad['signal']['chest']['ECG'] = p_one['calib']['ECG'].drop(columns=['Timestamp','Second'])\n",
    "        p_like_wesad['signal']['chest']['EDA'] = p_one['calib']['EDA'].drop(columns=['Timestamp','Second'])\n",
    "        p_like_wesad['signal']['chest']['Resp'] = p_one['calib']['RESP'].drop(columns=['Timestamp','Second'])\n",
    "\n",
    "        p_like_wesad['signal']['wrist']['ACC'] = p_one['calib']['ACC_e4'].drop(columns=['Timestamp','Second'])\n",
    "        p_like_wesad['signal']['wrist']['BVP'] = p_one['calib']['BVP'].drop(columns=['Timestamp','Second'])\n",
    "        p_like_wesad['signal']['wrist']['EDA'] = p_one['calib']['EDA'].drop(columns=['Timestamp','Second'])\n",
    "        p_like_wesad['signal']['wrist']['TEMP'] = p_one['calib']['TEMP'].drop(columns=['Timestamp','Second'])\n",
    "        \n",
    "        if len(p_one['LA']) !=0: # means LA data is available\n",
    "            for day in p_one['LA']:\n",
    "                if len(p_one['LA'][day]) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    p_like_wesad['calib_label'] = pd.concat([p_like_wesad['calib_label'],\n",
    "                                                            pd.DataFrame(np.ones(len(p_one['LA'][day]['ACC_hx']))*3)], ignore_index=True)\n",
    "                    p_like_wesad['rot_label'] = pd.concat([p_like_wesad['rot_label'], \n",
    "                                                        pd.DataFrame(p_one['LA'][day]['rot_label'])])\n",
    "\n",
    "                    p_like_wesad['signal']['chest']['ACC'] = pd.concat([p_like_wesad['signal']['chest']['ACC'],\n",
    "                                                                        p_one['LA'][day]['ACC_hx'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_like_wesad['signal']['chest']['ECG'] = pd.concat([p_like_wesad['signal']['chest']['ECG'],\n",
    "                                                                        p_one['LA'][day]['ECG'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_like_wesad['signal']['chest']['EDA'] = pd.concat([p_like_wesad['signal']['chest']['EDA'],\n",
    "                                                                        p_one['LA'][day]['EDA'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_like_wesad['signal']['chest']['Resp'] = pd.concat([p_like_wesad['signal']['chest']['Resp'],\n",
    "                                                                            p_one['LA'][day]['RESP'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    \n",
    "                    p_like_wesad['signal']['wrist']['ACC'] = pd.concat([p_like_wesad['signal']['wrist']['ACC'],\n",
    "                                                                        p_one['LA'][day]['ACC_e4'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_like_wesad['signal']['wrist']['BVP'] = pd.concat([p_like_wesad['signal']['wrist']['BVP'],\n",
    "                                                                        p_one['LA'][day]['BVP'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_like_wesad['signal']['wrist']['EDA'] = pd.concat([p_like_wesad['signal']['wrist']['EDA'],\n",
    "                                                                        p_one['LA'][day]['EDA'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_like_wesad['signal']['wrist']['TEMP'] = pd.concat([p_like_wesad['signal']['wrist']['TEMP'],\n",
    "                                                                        p_one['LA'][day]['TEMP'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "        if len(p_one['HA']) !=0: # means HA data is available\n",
    "            for day in p_one['HA']:\n",
    "                if len(p_one['HA'][day]) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    p_like_wesad['calib_label'] = pd.concat([p_like_wesad['calib_label'],\n",
    "                                                            pd.DataFrame(np.ones(len(p_one['HA'][day]['ACC_hx']))*3)], ignore_index=True)\n",
    "                    p_like_wesad['rot_label'] = pd.concat([p_like_wesad['rot_label'], \n",
    "                                                        pd.DataFrame(p_one['HA'][day]['rot_label'])])\n",
    "                    \n",
    "                    p_like_wesad['signal']['chest']['ACC'] = pd.concat([p_like_wesad['signal']['chest']['ACC'],\n",
    "                                                                        p_one['HA'][day]['ACC_hx'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_like_wesad['signal']['chest']['ECG'] = pd.concat([p_like_wesad['signal']['chest']['ECG'],\n",
    "                                                                        p_one['HA'][day]['ECG'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_like_wesad['signal']['chest']['EDA'] = pd.concat([p_like_wesad['signal']['chest']['EDA'],\n",
    "                                                                        p_one['HA'][day]['EDA'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_like_wesad['signal']['chest']['Resp'] = pd.concat([p_like_wesad['signal']['chest']['Resp'],\n",
    "                                                                            p_one['HA'][day]['RESP'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    \n",
    "                    p_like_wesad['signal']['wrist']['ACC'] = pd.concat([p_like_wesad['signal']['wrist']['ACC'],\n",
    "                                                                        p_one['HA'][day]['ACC_e4'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_like_wesad['signal']['wrist']['BVP'] = pd.concat([p_like_wesad['signal']['wrist']['BVP'],\n",
    "                                                                        p_one['HA'][day]['BVP'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_like_wesad['signal']['wrist']['EDA'] = pd.concat([p_like_wesad['signal']['wrist']['EDA'],\n",
    "                                                                        p_one['HA'][day]['EDA'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_like_wesad['signal']['wrist']['TEMP'] = pd.concat([p_like_wesad['signal']['wrist']['TEMP'],\n",
    "                                                                        p_one['HA'][day]['TEMP'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "        \n",
    "            \n",
    "            \n",
    "        with open(radwear_path + 'wesadlike_p_' + str(p) + '.pkl', 'wb') as f:\n",
    "                pickle.dump(p_like_wesad, f)\n",
    "    p_one = None\n",
    "    # for this method, the signal is all concatenated under 1 length not segmented by rotational anxiety or anything else. \n",
    "    # it's on the user to look get that information from other places. \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant  4  already processed in segmented format.\n",
      "processing participant  7  in segmented format...\n",
      "participant  7  loaded.\n",
      "processing participant  9  in segmented format...\n",
      "participant  9  loaded.\n",
      "processing participant  12  in segmented format...\n",
      "participant  12  loaded.\n",
      "processing participant  14  in segmented format...\n",
      "participant  14  loaded.\n",
      "processing participant  16  in segmented format...\n",
      "participant  16  loaded.\n",
      "processing participant  17  in segmented format...\n",
      "participant  17  loaded.\n",
      "processing participant  18  in segmented format...\n",
      "participant  18  loaded.\n",
      "processing participant  21  in segmented format...\n",
      "participant  21  loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p_segmented = {}\n",
    "\n",
    "for p in list_of_participants:\n",
    "    p_path = radwear_path+'Participant '+str(p)\n",
    "    if os.path.isfile(radwear_path + 'p_segmented_' + str(p) + '.pkl'):\n",
    "        print('participant ', p, ' already processed in segmented format.')\n",
    "    else:\n",
    "        print('processing participant ', p, ' in segmented format...')\n",
    "            \n",
    "\n",
    "        with open(p_path+'/p_'+str(p)+'.pkl','rb') as handle:\n",
    "            p_one = pickle.load(handle)\n",
    "        print('participant ', p, ' loaded.')\n",
    "        p_calib = {}\n",
    "        p_segmented = {}\n",
    "        \n",
    "        p_calib['subject'] = p\n",
    "        p_calib['label'] = np.zeros(len(p_one['calib']['ECG']))\n",
    "        p_calib['signal'] = {}\n",
    "        p_calib['signal']['chest'] = {}\n",
    "        p_calib['signal']['wrist'] = {}\n",
    "        \n",
    "        \n",
    "        \n",
    "        p_calib['calib_label'] = pd.DataFrame(p_one['calib']['calib_label'].drop(columns=['Timestamp']).values.flatten())\n",
    "        p_calib['rot_label'] = pd.DataFrame(p_one['calib']['rot_label'])\n",
    "\n",
    "        p_calib['signal']['chest']['ACC'] = p_one['calib']['ACC_hx'].drop(columns=['Timestamp','Second'])\n",
    "        p_calib['signal']['chest']['ECG'] = p_one['calib']['ECG'].drop(columns=['Timestamp','Second'])\n",
    "        p_calib['signal']['chest']['EDA'] = p_one['calib']['EDA'].drop(columns=['Timestamp','Second'])\n",
    "        p_calib['signal']['chest']['Resp'] = p_one['calib']['RESP'].drop(columns=['Timestamp','Second'])\n",
    "\n",
    "        p_calib['signal']['wrist']['ACC'] = p_one['calib']['ACC_e4'].drop(columns=['Timestamp','Second'])\n",
    "        p_calib['signal']['wrist']['BVP'] = p_one['calib']['BVP'].drop(columns=['Timestamp','Second'])\n",
    "        p_calib['signal']['wrist']['EDA'] = p_one['calib']['EDA'].drop(columns=['Timestamp','Second'])\n",
    "        p_calib['signal']['wrist']['TEMP'] = p_one['calib']['TEMP'].drop(columns=['Timestamp','Second'])\n",
    "        \n",
    "        p_segmented['calib'] = p_calib \n",
    "\n",
    "        # pla\n",
    "        p_la = {}\n",
    "        p_la['subject'] = p\n",
    "        p_la['label'] = np.zeros(len(p_one['calib']['ECG']))\n",
    "        p_la['signal'] = {}\n",
    "        p_la['signal']['chest'] = {}\n",
    "        p_la['signal']['wrist'] = {}\n",
    "\n",
    "        p_la['rot_label'] = pd.DataFrame()\n",
    "\n",
    "        p_la['signal']['chest']['ACC'] = pd.DataFrame()\n",
    "        p_la['signal']['chest']['ECG'] = pd.DataFrame()\n",
    "        p_la['signal']['chest']['EDA'] = pd.DataFrame()\n",
    "        p_la['signal']['chest']['Resp'] = pd.DataFrame()\n",
    "\n",
    "        p_la['signal']['wrist']['ACC'] = pd.DataFrame()\n",
    "        p_la['signal']['wrist']['BVP'] = pd.DataFrame()\n",
    "        p_la['signal']['wrist']['EDA'] = pd.DataFrame()\n",
    "        p_la['signal']['wrist']['TEMP'] = pd.DataFrame()\n",
    "\n",
    "        if len(p_one['LA']) !=0: # means LA data is available\n",
    "            for day in p_one['LA']:\n",
    "                if len(p_one['LA'][day]) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    \n",
    "                    \n",
    "                    p_la['rot_label'] = pd.concat([p_la['rot_label'], \n",
    "                                                        pd.DataFrame(p_one['LA'][day]['rot_label'])])\n",
    "\n",
    "                    p_la['signal']['chest']['ACC'] = pd.concat([p_la['signal']['chest']['ACC'],\n",
    "                                                                        p_one['LA'][day]['ACC_hx'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_la['signal']['chest']['ECG'] = pd.concat([p_la['signal']['chest']['ECG'],\n",
    "                                                                        p_one['LA'][day]['ECG'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_la['signal']['chest']['EDA'] = pd.concat([p_la['signal']['chest']['EDA'],\n",
    "                                                                        p_one['LA'][day]['EDA'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_la['signal']['chest']['Resp'] = pd.concat([p_la['signal']['chest']['Resp'],\n",
    "                                                                            p_one['LA'][day]['RESP'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    \n",
    "                    p_la['signal']['wrist']['ACC'] = pd.concat([p_la['signal']['wrist']['ACC'],\n",
    "                                                                        p_one['LA'][day]['ACC_e4'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_la['signal']['wrist']['BVP'] = pd.concat([p_la['signal']['wrist']['BVP'],\n",
    "                                                                        p_one['LA'][day]['BVP'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_la['signal']['wrist']['EDA'] = pd.concat([p_la['signal']['wrist']['EDA'],\n",
    "                                                                        p_one['LA'][day]['EDA'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_la['signal']['wrist']['TEMP'] = pd.concat([p_la['signal']['wrist']['TEMP'],\n",
    "                                                                        p_one['LA'][day]['TEMP'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "        p_segmented['LA'] = p_la\n",
    "        \n",
    "        # pha\n",
    "        p_ha = {}\n",
    "        p_ha['subject'] = p\n",
    "        p_ha['label'] = np.zeros(len(p_one['calib']['ECG']))\n",
    "        p_ha['signal'] = {}\n",
    "        p_ha['signal']['chest'] = {}\n",
    "        p_ha['signal']['wrist'] = {}\n",
    "        \n",
    "        p_ha['rot_label'] = pd.DataFrame()\n",
    "\n",
    "        p_ha['signal']['chest']['ACC'] = pd.DataFrame()\n",
    "        p_ha['signal']['chest']['ECG'] = pd.DataFrame()\n",
    "        p_ha['signal']['chest']['EDA'] = pd.DataFrame()\n",
    "        p_ha['signal']['chest']['Resp'] = pd.DataFrame()\n",
    "\n",
    "        p_ha['signal']['wrist']['ACC'] = pd.DataFrame()\n",
    "        p_ha['signal']['wrist']['BVP'] = pd.DataFrame()\n",
    "        p_ha['signal']['wrist']['EDA'] = pd.DataFrame()\n",
    "        p_ha['signal']['wrist']['TEMP'] = pd.DataFrame()\n",
    "\n",
    "        if len(p_one['HA']) !=0: # means HA data is available\n",
    "            for day in p_one['HA']:\n",
    "                if len(p_one['HA'][day]) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    \n",
    "                    p_la['rot_label'] = pd.concat([p_la['rot_label'], \n",
    "                                                        pd.DataFrame(p_one['HA'][day]['rot_label'])])\n",
    "                    \n",
    "                    p_la['signal']['chest']['ACC'] = pd.concat([p_la['signal']['chest']['ACC'],\n",
    "                                                                        p_one['HA'][day]['ACC_hx'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_la['signal']['chest']['ECG'] = pd.concat([p_la['signal']['chest']['ECG'],\n",
    "                                                                        p_one['HA'][day]['ECG'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_la['signal']['chest']['EDA'] = pd.concat([p_la['signal']['chest']['EDA'],\n",
    "                                                                        p_one['HA'][day]['EDA'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_la['signal']['chest']['Resp'] = pd.concat([p_la['signal']['chest']['Resp'],\n",
    "                                                                            p_one['HA'][day]['RESP'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    \n",
    "                    p_la['signal']['wrist']['ACC'] = pd.concat([p_la['signal']['wrist']['ACC'],\n",
    "                                                                        p_one['HA'][day]['ACC_e4'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_la['signal']['wrist']['BVP'] = pd.concat([p_la['signal']['wrist']['BVP'],\n",
    "                                                                        p_one['HA'][day]['BVP'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_la['signal']['wrist']['EDA'] = pd.concat([p_la['signal']['wrist']['EDA'],\n",
    "                                                                        p_one['HA'][day]['EDA'].drop(columns=['Timestamp','Second'])], ignore_index=True)\n",
    "                    p_la['signal']['wrist']['TEMP'] = pd.concat([p_la['signal']['wrist']['TEMP'],\n",
    "                                                                        p_one['HA'][day]['TEMP'].drop(columns=['Timestamp','Second'])], ignore_index=True)     \n",
    "        p_segmented['HA'] = p_ha\n",
    "\n",
    "        with open(radwear_path + 'p_segmented_' + str(p) + '.pkl', 'wb') as f:\n",
    "                pickle.dump(p_segmented, f)\n",
    "        p_segmented = None\n",
    "        p_one = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p_like_wesad['calib_label'] = pd.concat([pd.DataFrame(p_one['calib']['calib_label'].drop(columns=['Timestamp']).values.flatten()),\n",
    "                                                pd.DataFrame(np.concatenate([np.ones(len(i))*3 for i in [*[p_one['LA'][i]['ACC_hx'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]]]))], ignore_index=True)\n",
    "        p_like_wesad['rot_label'] = pd.DataFrame(np.concatenate((p_one['calib']['rot_label'], *[p_one['LA'][i]['rot_label'] for i in p_one['LA']])))\n",
    "\n",
    "        p_like_wesad['signal']['chest']['ACC'] = pd.concat([*[p_one['LA'][i]['ACC_hx'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['chest']['ECG'] = pd.concat([*[p_one['LA'][i]['ECG'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['chest']['EDA'] = pd.concat([*[p_one['LA'][i]['EDA'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['chest']['Resp'] = pd.concat([*[p_one['LA'][i]['RESP'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "\n",
    "        p_like_wesad['signal']['wrist']['ACC'] = pd.concat([*[p_one['LA'][i]['ACC_e4'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['wrist']['BVP'] = pd.concat([*[p_one['LA'][i]['BVP'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['wrist']['EDA'] = pd.concat([*[p_one['LA'][i]['EDA'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['wrist']['TEMP'] = pd.concat([*[p_one['LA'][i]['TEMP'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "\n",
    "    elif len(p_one['LA']) ==0:\n",
    "        p_like_wesad['calib_label'] = pd.concat([pd.DataFrame(p_one['calib']['calib_label'].drop(columns=['Timestamp']).values.flatten()),\n",
    "                                                pd.DataFrame(np.concatenate([np.ones(len(i))*3 for i in [*[p_one['HA'][i]['ACC_hx'].drop(columns=['Timestamp','Second']) for i in p_one['HA']]]]))], ignore_index=True)\n",
    "        p_like_wesad['rot_label'] = pd.DataFrame(np.concatenate((p_one['calib']['rot_label'], *[p_one['HA'][i]['rot_label'] for i in p_one['HA']])))\n",
    "        \n",
    "        p_like_wesad['signal']['chest']['ACC'] = pd.concat([*[p_one['HA'][i]['ACC_hx'].drop(columns=['Timestamp','Second']) for i in p_one['HA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['chest']['ECG'] = pd.concat([*[p_one['HA'][i]['ECG'].drop(columns=['Timestamp','Second'])for i in p_one['HA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['chest']['EDA'] = pd.concat([*[p_one['HA'][i]['EDA'].drop(columns=['Timestamp','Second'])for i in p_one['HA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['chest']['Resp'] = pd.concat([*[p_one['HA'][i]['RESP'].drop(columns=['Timestamp','Second'])for i in p_one['HA']]], ignore_index=True)\n",
    "        \n",
    "        p_like_wesad['signal']['wrist']['ACC'] = pd.concat([*[p_one['HA'][i]['ACC_e4'].drop(columns=['Timestamp','Second'])for i in p_one['HA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['wrist']['BVP'] = pd.concat([*[p_one['HA'][i]['BVP'].drop(columns=['Timestamp','Second'])for i in p_one['HA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['wrist']['EDA'] = pd.concat([*[p_one['HA'][i]['EDA'].drop(columns=['Timestamp','Second'])for i in p_one['HA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['wrist']['TEMP'] = pd.concat([*[p_one['HA'][i]['TEMP'].drop(columns=['Timestamp','Second'])for i in p_one['HA']]], ignore_index=True)\n",
    "         \n",
    "    else:\n",
    "        #print('len la len ha',len(p_one['LA']), len(p_one['HA']))\n",
    "        p_like_wesad['calib_label'] = pd.concat([pd.DataFrame(p_one['calib']['calib_label'].drop(columns=['Timestamp']).values.flatten()),\n",
    "                                                pd.DataFrame(np.concatenate([np.ones(len(i))*3 for i in [*[p_one['LA'][i]['ACC_hx'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]]])),\n",
    "                                                pd.DataFrame(np.concatenate([np.ones(len(i))*3 for i in [*[p_one['HA'][i]['ACC_hx'].drop(columns=['Timestamp','Second']) for i in p_one['HA']]]]))], ignore_index=True)\n",
    "        p_like_wesad['rot_label'] = pd.DataFrame(np.concatenate((p_one['calib']['rot_label'], *[p_one['LA'][i]['rot_label'] for i in p_one['LA']] , *[p_one['HA'][i]['rot_label'] for i in p_one['HA']])))\n",
    "        \n",
    "        p_like_wesad['signal']['chest']['ACC'] = pd.concat([p_one['calib']['ACC_hx'], *[p_one['LA'][i]['ACC_hx'].drop(columns=['Timestamp','Second']) for i in p_one['LA']],\n",
    "                                                            *[p_one['HA'][i]['ACC_hx'].drop(columns=['Timestamp','Second']) for i in p_one['HA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['chest']['ECG'] = pd.concat([p_one['calib']['ECG'], *[p_one['LA'][i]['ECG'].drop(columns=['Timestamp','Second']) for i in p_one['LA']],\n",
    "                                                            *[p_one['HA'][i]['ECG'].drop(columns=['Timestamp','Second'])for i in p_one['HA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['chest']['EDA'] = pd.concat([p_one['calib']['EDA'], *[p_one['LA'][i]['EDA'].drop(columns=['Timestamp','Second']) for i in p_one['LA']],\n",
    "                                                            *[p_one['HA'][i]['EDA'].drop(columns=['Timestamp','Second'])for i in p_one['HA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['chest']['Resp'] = pd.concat([p_one['calib']['RESP'], *[p_one['LA'][i]['RESP'].drop(columns=['Timestamp','Second']) for i in p_one['LA']],\n",
    "                                                            *[p_one['HA'][i]['RESP'].drop(columns=['Timestamp','Second'])for i in p_one['HA']]], ignore_index=True)\n",
    "        \n",
    "        p_like_wesad['signal']['wrist']['ACC'] = pd.concat([p_one['calib']['ACC_e4'], *[p_one['LA'][i]['ACC_e4'].drop(columns=['Timestamp','Second']) for i in p_one['LA']],\n",
    "                                                            *[p_one['HA'][i]['ACC_e4'].drop(columns=['Timestamp','Second'])for i in p_one['HA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['wrist']['BVP'] = pd.concat([p_one['calib']['BVP'], *[p_one['LA'][i]['BVP'].drop(columns=['Timestamp','Second']) for i in p_one['LA']],\n",
    "                                                            *[p_one['HA'][i]['BVP'].drop(columns=['Timestamp','Second'])for i in p_one['HA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['wrist']['EDA'] = pd.concat([p_one['calib']['EDA'], *[p_one['LA'][i]['EDA'].drop(columns=['Timestamp','Second']) for i in p_one['LA']],\n",
    "                                                            *[p_one['HA'][i]['EDA'].drop(columns=['Timestamp','Second'])for i in p_one['HA']]], ignore_index=True)\n",
    "        p_like_wesad['signal']['wrist']['TEMP'] = pd.concat([p_one['calib']['TEMP'], *[p_one['LA'][i]['TEMP'].drop(columns=['Timestamp','Second']) for i in p_one['LA']],\n",
    "                                                            *[p_one['HA'][i]['TEMP'].drop(columns=['Timestamp','Second'])for i in p_one['HA']]], ignore_index=True)\n",
    "        else: # means both LA and HA data are available\n",
    "            p_like_wesad['signal']['chest']['ACC'] = pd.concat([*[p_one['LA'][i]['ACC_hx'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "            p_like_wesad['signal']['chest']['ECG'] = pd.concat([*[p_one['LA'][i]['ECG'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "            p_like_wesad['signal']['chest']['EDA'] = pd.concat([*[p_one['LA'][i]['EDA'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "            p_like_wesad['signal']['chest']['Resp'] = pd.concat([*[p_one['LA'][i]['RESP'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "\n",
    "            p_like_wesad['signal']['wrist']['ACC'] = pd.concat([*[p_one['LA'][i]['ACC_e4'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "            p_like_wesad['signal']['wrist']['BVP'] = pd.concat([*[p_one['LA'][i]['BVP'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "            p_like_wesad['signal']['wrist']['EDA'] = pd.concat([*[p_one['LA'][i]['EDA'].drop(columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)\n",
    "            p_like_wesad['signal']['wrist']['TEMP'] = pd.concat([*[p_one['LA'][i]['TEMP'].drop\n",
    "                                                                     (columns=['Timestamp','Second']) for i in p_one['LA']]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ws.keys(): ',p_like_wesad.keys())\n",
    "print(f'signal keys: {p_like_wesad[\"signal\"].keys()}')\n",
    "print(f'chest keys: {p_like_wesad[\"signal\"][\"chest\"].keys()}')\n",
    "print(f'wrist keys: {p_like_wesad[\"signal\"][\"wrist\"].keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_one.keys())\n",
    "print(p_one['calib'].keys())\n",
    "print(len(p_one['calib']['rot_label']))\n",
    "print(len(p_one['calib']['ECG']))\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('calib', (p_one['calib'].keys())) \n",
    "print('='*20)\n",
    "for key in p_one['LA']:\n",
    "    print(key, (p_one['LA'][key].keys()))\n",
    "    print('='*20)\n",
    "print('+='*20)\n",
    "for key in p_one['HA']:\n",
    "    print(key, (p_one['HA'][key].keys()))\n",
    "    print('='*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load each participant's data\n",
    "force_update = True\n",
    "for p in list_of_participants:\n",
    "    p_path = radwear_path + 'Participant ' + str(p)\n",
    "    p_df = pd.DataFrame()\n",
    "\n",
    "    # check if file exist\n",
    "    a = (\n",
    "        'available.'\n",
    "        if os.path.isfile(p_path + '/formatted_p_' + str(p) + '.pkl')\n",
    "        else ' not available.'\n",
    "    )\n",
    "    print('pickle file for participant ' + str(p) + ' is ' + a)\n",
    "\n",
    "    # all_p[p] = p_data ## this takes too much memory so i will just load each p when needed\n",
    "    if not (os.path.isfile(radwear_path + 'formatted_p_' + str(p) + '.pkl')) or force_update:\n",
    "        with open(p_path + '/formatted_p_' + str(p) + '.pkl', 'rb') as f:\n",
    "            p_data = pickle.load(f)\n",
    "        print('participant ' + str(p) + ' data loaded.')\n",
    "        print('-----------------------')\n",
    "        print('Participant: ', p)\n",
    "        print('-----------------------')\n",
    "        print('la days: ', len(p_data['HA'].keys()))\n",
    "        print('ha days: ', len(p_data['LA'].keys()))\n",
    "        print('-----------------------')\n",
    "        # e4 contains BVP, EDA, TEMP, ACC, IBI, HR, HRV, tags\n",
    "        # hx contains ECG, ACC, BR\n",
    "        p_redcap = redcap_df.loc[\n",
    "            redcap_df['participant'] == p\n",
    "        ]  # redcap data for participant p\n",
    "\n",
    "        ## this is for participant p\n",
    "\n",
    "        for day in list(p_data['LA'].keys()):\n",
    "            proceed1 = bool(len(p_data['LA'][day])) and bool(\n",
    "                all_p_metadata[str(p)]['RedCap available'][0][day]\n",
    "            )\n",
    "\n",
    "            if proceed1:\n",
    "                LA_df = p_data['LA'][day]['ECG'].copy()\n",
    "                del p_data['LA'][day]['ECG']\n",
    "                resample_ratio = round(len(LA_df))\n",
    "\n",
    "                LA_df['BVP'] = signal.resample(\n",
    "                    p_data['LA'][day]['BVP']['BVP'], resample_ratio\n",
    "                )\n",
    "                LA_df['participant'] = p\n",
    "                del p_data['LA'][day]['ECG']\n",
    "\n",
    "                LA_df['EDA'] = signal.resample(\n",
    "                    p_data['LA'][day]['EDA']['EDA'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['EDA']\n",
    "                LA_df['TEMP'] = signal.resample(\n",
    "                    p_data['LA'][day]['TEMP']['Temp'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['TEMP']\n",
    "                LA_df['BR'] = signal.resample(\n",
    "                    p_data['LA'][day]['BR']['breathing_rate'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['BR']\n",
    "                LA_df['ACCx_hx'] = signal.resample(\n",
    "                    p_data['LA'][day]['ACC_hx']['Acceleration_X'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['ACC_hx']['Acceleration_X']\n",
    "                LA_df['ACCy_hx'] = signal.resample(\n",
    "                    p_data['LA'][day]['ACC_hx']['Acceleration_Y'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['ACC_hx']['Acceleration_Y']\n",
    "                LA_df['ACCz_hx'] = signal.resample(\n",
    "                    p_data['LA'][day]['ACC_hx']['Acceleration_Z'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['ACC_hx']['Acceleration_Z']\n",
    "                LA_df['ACCx_e4'] = signal.resample(\n",
    "                    p_data['LA'][day]['ACC_e4']['Acc_X'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['ACC_e4']['Acc_X']\n",
    "                LA_df['ACCy_e4'] = signal.resample(\n",
    "                    p_data['LA'][day]['ACC_e4']['Acc_Y'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['ACC_e4']['Acc_Y']\n",
    "                LA_df['ACCz_e4'] = signal.resample(\n",
    "                    p_data['LA'][day]['ACC_e4']['Acc_Z'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['ACC_e4']['Acc_Z']\n",
    "                LA_df['rot_label'] = rot_anx_dict['LA'] * np.ones(resample_ratio)\n",
    "                LA_df['calib_label'] = np.zeros(resample_ratio)\n",
    "\n",
    "                for column in columns_list:\n",
    "                    if column == 'daily_check_in_date':\n",
    "                        A = np.chararray(resample_ratio, itemsize=15, unicode=True)\n",
    "                        A[:] = (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][\n",
    "                            column\n",
    "                        ]\n",
    "                        LA_df[column] = A\n",
    "                    else:\n",
    "                        LA_df[column] = (\n",
    "                            np.ones(resample_ratio)\n",
    "                            * (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][\n",
    "                                column\n",
    "                            ]\n",
    "                        )\n",
    "\n",
    "                print(\n",
    "                    'Done with day ',\n",
    "                    day,\n",
    "                    'date: ',\n",
    "                    (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][\n",
    "                        'daily_check_in_date'\n",
    "                    ],\n",
    "                    ' of LA rotation for participant ',\n",
    "                    p,\n",
    "                )\n",
    "                p_df = pd.concat([p_df, LA_df], ignore_index=True, sort=False)\n",
    "                # print('display LA_df after LA_df')\n",
    "                # display(LA_df)\n",
    "\n",
    "        for day in list(p_data['HA'].keys()):\n",
    "            proceed2 = bool(len(p_data['HA'][day])) and bool(\n",
    "                all_p_metadata[str(p)]['RedCap available'][1][day]\n",
    "            )\n",
    "            if proceed2:\n",
    "                HA_df = p_data['HA'][day]['BVP'].copy()\n",
    "                del p_data['HA'][day]['BVP']\n",
    "                HA_df['participant'] = p\n",
    "                resample_ratio = round(len(HA_df))\n",
    "                HA_df['ECG'] = signal.resample(\n",
    "                    p_data['HA'][day]['ECG']['ECG'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['ECG']\n",
    "                # no need to increase sampling rate of signals. pandas can accept unevenly sampled data\n",
    "                HA_df['EDA'] = signal.resample(\n",
    "                    p_data['HA'][day]['EDA']['EDA'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['EDA']\n",
    "                HA_df['TEMP'] = signal.resample(\n",
    "                    p_data['HA'][day]['TEMP']['Temp'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['TEMP']\n",
    "                HA_df['BR'] = signal.resample(\n",
    "                    p_data['HA'][day]['BR']['breathing_rate'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['BR']\n",
    "                HA_df['ACCx_hx'] = signal.resample(\n",
    "                    p_data['HA'][day]['ACC_hx']['Acceleration_X'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['ACC_hx']['Acceleration_X']\n",
    "                HA_df['ACCy_hx'] = signal.resample(\n",
    "                    p_data['HA'][day]['ACC_hx']['Acceleration_Y'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['ACC_hx']['Acceleration_Y']\n",
    "                HA_df['ACCz_hx'] = signal.resample(\n",
    "                    p_data['HA'][day]['ACC_hx']['Acceleration_Z'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['ACC_hx']['Acceleration_Z']\n",
    "                HA_df['ACCx_e4'] = signal.resample(\n",
    "                    p_data['HA'][day]['ACC_e4']['Acc_X'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['ACC_e4']['Acc_X']\n",
    "                HA_df['ACCy_e4'] = signal.resample(\n",
    "                    p_data['HA'][day]['ACC_e4']['Acc_Y'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['ACC_e4']['Acc_Y']\n",
    "                HA_df['ACCz_e4'] = signal.resample(\n",
    "                    p_data['HA'][day]['ACC_e4']['Acc_Z'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['ACC_e4']['Acc_Z']\n",
    "                HA_df['rot_label'] = rot_anx_dict['HA'] * np.ones(resample_ratio)\n",
    "                HA_df['calib_label'] = np.zeros(resample_ratio)\n",
    "\n",
    "                for column in columns_list:\n",
    "                    if column == 'daily_check_in_date':\n",
    "                        A = np.chararray(resample_ratio, itemsize=15, unicode=True)\n",
    "                        A[:] = (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][\n",
    "                            column\n",
    "                        ]\n",
    "                        HA_df[column] = A\n",
    "                    else:\n",
    "                        HA_df[column] = (\n",
    "                            np.ones(resample_ratio)\n",
    "                            * (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][\n",
    "                                column\n",
    "                            ]\n",
    "                        )\n",
    "\n",
    "                print(\n",
    "                    'Done with day ',\n",
    "                    day,\n",
    "                    'date: ',\n",
    "                    (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][\n",
    "                        'daily_check_in_date'\n",
    "                    ],\n",
    "                    ' of HA rotation for participant ',\n",
    "                    p,\n",
    "                )\n",
    "                p_df = pd.concat([p_df, HA_df], ignore_index=True, sort=False)\n",
    "\n",
    "        calib_df = p_data['calib']['BVP'].copy()\n",
    "        del p_data['calib']['BVP']\n",
    "        resample_ratio = round(len(calib_df))\n",
    "\n",
    "        calib_df['ECG'] = signal.resample(p_data['calib']['ECG']['ECG'], resample_ratio)\n",
    "        del p_data['calib']['ECG']\n",
    "        # calib_df['BVP'] = signal.resample(p_data['calib']['BVP']['BVP'], resample_ratio)\n",
    "        calib_df['EDA'] = signal.resample(p_data['calib']['EDA']['EDA'], resample_ratio)\n",
    "        del p_data['calib']['EDA']\n",
    "        calib_df['TEMP'] = signal.resample(\n",
    "            p_data['calib']['TEMP']['Temp'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['TEMP']\n",
    "        calib_df['BR'] = signal.resample(\n",
    "            p_data['calib']['BR']['breathing_rate'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['BR']\n",
    "        calib_df['ACCx_hx'] = signal.resample(\n",
    "            p_data['calib']['ACC_hx']['Acceleration_X'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['ACC_hx']['Acceleration_X']\n",
    "        calib_df['ACCy_hx'] = signal.resample(\n",
    "            p_data['calib']['ACC_hx']['Acceleration_Y'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['ACC_hx']['Acceleration_Y']\n",
    "        calib_df['ACCz_hx'] = signal.resample(\n",
    "            p_data['calib']['ACC_hx']['Acceleration_Z'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['ACC_hx']['Acceleration_Z']\n",
    "        calib_df['ACCx_e4'] = signal.resample(\n",
    "            p_data['calib']['ACC_e4']['Acc_X'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['ACC_e4']['Acc_X']\n",
    "        calib_df['ACCy_e4'] = signal.resample(\n",
    "            p_data['calib']['ACC_e4']['Acc_Y'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['ACC_e4']['Acc_Y']\n",
    "        calib_df['ACCz_e4'] = signal.resample(\n",
    "            p_data['calib']['ACC_e4']['Acc_Z'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['ACC_e4']['Acc_Z']\n",
    "        calib_df['rot_label'] = rot_anx_dict['calibration'] * np.ones(resample_ratio)\n",
    "        calib_df['calib_label'] = np.ones(resample_ratio)  # complete later\n",
    "        redcap_dfcalib = (\n",
    "            redcap_df  # a cheat for now since i don't have redcap data for calibration\n",
    "        )\n",
    "        columns_list = redcap_dfcalib.columns\n",
    "        ############################################\n",
    "        # redcap for calibration doesn't exist yet #\n",
    "        ############################################\n",
    "\n",
    "        for column in columns_list:\n",
    "            # print(column)\n",
    "            # print((redcap_dfcalib.loc[redcap_dfcalib['participant'] == p]).iloc[0][column]) # this is incorrect for now, replace with calibration data later\n",
    "            if column == 'daily_check_in_date':\n",
    "                A = np.chararray(resample_ratio, itemsize=15, unicode=True)\n",
    "                A[:] = (redcap_dfcalib.loc[redcap_dfcalib['participant'] == p]).iloc[0][\n",
    "                    column\n",
    "                ]  # this is incorrect for now, replace with calibration data later\n",
    "                calib_df[column] = A\n",
    "            else:\n",
    "                calib_df[column] = (\n",
    "                    np.ones(resample_ratio)\n",
    "                    * (redcap_dfcalib.loc[redcap_dfcalib['participant'] == p]).iloc[0][\n",
    "                        column\n",
    "                    ]\n",
    "                )  # this is incorrect for now, replace with calibration data later\n",
    "\n",
    "        p_df = pd.concat([p_df, calib_df], ignore_index=True, sort=False)\n",
    "        # print('display calib_df after calib')\n",
    "        # display(calib_df)\n",
    "        # display(calib_df)\n",
    "\n",
    "        # save the data\n",
    "        print('Pickling processed data for participant ' + str(p) + ' ...')\n",
    "        with open(radwear_path + 'df_p_' + str(p) + '.pkl', 'wb') as f:\n",
    "            pickle.dump(p_df, f)\n",
    "        print('data pickled...')\n",
    "\n",
    "    else:\n",
    "        print('processed data for participant ' + str(p) + ' is already available!')\n",
    "        # load the data\n",
    "        with open(radwear_path +'formatted_p_'+str(p)+'.pkl', 'rb') as f:\n",
    "            p_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combining into 1 DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_p_df = pd.DataFrame()\n",
    "\n",
    "for p in list_of_participants:\n",
    "    p_path = radwear_path\n",
    "    # p_df = pd.DataFrame()\n",
    "\n",
    "    # check if file exist\n",
    "    a = (\n",
    "        'available.'\n",
    "        if os.path.isfile(p_path + '/p_' + str(p) + '.pkl')\n",
    "        else ' not available.'\n",
    "    )\n",
    "    print('processed data for participant ' + str(p) + ' is ' + a)\n",
    "    print('Loading...')\n",
    "    with open(p_path + '/p_' + str(p) + '.pkl', 'rb') as f:\n",
    "        p_df = pickle.load(f)\n",
    "    print('participant ' + str(p) + ' data loaded.')\n",
    "    print('-----------------------')\n",
    "    all_p_df = pd.concat([all_p_df, p_df], ignore_index=True, sort=False)\n",
    "    display(p_df.sample(3))\n",
    "    all_p_df.columns\n",
    "print('pickling all participants file...')\n",
    "all_p_df.to_pickle(radwear_path + 'all_participants.pkl')\n",
    "print('pickling completed. ')\n",
    "print('DF for all participants is saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
