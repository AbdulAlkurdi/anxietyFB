{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'modified by abdul alkurdi; 10/05/2023'\n",
    "\n",
    "import pandas as pd\n",
    "#import cudf\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.signal import correlate\n",
    "#import cupy as cp\n",
    "from scipy.io import wavfile\n",
    "#from scipy import signal, stats\n",
    "#import peakutils, wfdb, pywt\n",
    "import csv\n",
    "import os, statistics\n",
    "from datetime import datetime\n",
    "#import heartpy as hp\n",
    "import json\n",
    "%matplotlib notebook\n",
    "# import neurokit2 as nk\n",
    "\n",
    "import process_redcap \n",
    "from syncfcns import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redcap dict exists\n",
      "redcap df exists\n",
      "redcap df pickle loaded\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "#####   force update ?     #####\n",
    "################################\n",
    "force_update = False\n",
    "\n",
    "\n",
    "radwear_path = '/projects/bbnp/Vansh/data/RADWear/'\n",
    "redcap_path = radwear_path+'REDCap responses/'\n",
    "\n",
    "# load all participant meta data\n",
    "with open(radwear_path+'all_p_metadata.json', 'rb') as f:\n",
    "            all_p_metadata = json.load(f)\n",
    "# load all participant redcap data\n",
    "redcap_df = process_redcap.process_redcap(redcap_path,all_p_metadata['list of participant IDs'])\n",
    "list_of_participants = all_p_metadata['list of participant IDs']\n",
    "completed_participants = []\n",
    "\n",
    "\n",
    "# label definitions\n",
    "calib_dict = {'meditation': 0, 'cpt': 1}\n",
    "rot_anx_dict = {'calibration': 0, 'LA': 1, 'HA': 2}\n",
    "\n",
    "p_calib = {}\n",
    "p_la = {}\n",
    "p_ha = {}\n",
    "p_all = {} \n",
    "incomplete = [guy for guy in list_of_participants if guy not in completed_participants]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fcn defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sync_return(filepath, e4_today, hx_today):\n",
    "    '''\n",
    "    usage: read_sync_return(filepath, e4_today, hx_today)\n",
    "    returns: synced_participant_data\n",
    "    '''\n",
    "    e4_dict = read_E4(filepath+'/'+e4_today, hx_today)\n",
    "    hx_dict = read_hx(filepath+'/record_'+hx_today, hx_today)\n",
    "\n",
    "    #e4sync_offset = E4sync_offset(e4_dict)\n",
    "    #hxsync_offset = Hexsync_offset(hx_dict['ECG'],hx_dict['BR'],hx_dict['accx'],hx_dict['accy'], hx_dict['accz'])\n",
    "    e4sync_offset = e4_dict\n",
    "    hxsync_offset = hx_dict\n",
    "    \n",
    "    synced_participant_data = {}\n",
    "    #cross syncing between devices but only on bvp and ecg\n",
    "    synced_participant_data['ECG'], synced_participant_data['BVP'] = doublesync_offset(hxsync_offset['ECG'], e4sync_offset['BVP'])\n",
    "    # for some reason we're losing seconds from beginning and end of hx data even though e4 is contained within it's timeframe.\n",
    "\n",
    "\n",
    "    # running syncing on rest of signals for hx (ECG, breathing_rateacc, br)\n",
    "    t0 = synced_participant_data['ECG']['Second'].iloc[0] #hx\n",
    "    tf = synced_participant_data['ECG']['Second'].iloc[-1] #hx\n",
    "    synced_participant_data['BR'] = hxsync_offset['BR'].loc[hxsync_offset['BR']['Second'] >= t0 ].loc[hxsync_offset['BR']['Second'] <= tf ]\n",
    "    del tf, t0\n",
    "\n",
    "    # running syncing on rest of signals for e4 (acc, eda, temp, hr, ibi )\n",
    "    t0 = synced_participant_data['BVP']['Second'].iloc[0] #e4\n",
    "    tf = synced_participant_data['BVP']['Second'].iloc[-1] #e4\n",
    "    synced_participant_data['TEMP'] = e4sync_offset['TEMP'].loc[e4sync_offset['TEMP']['Second'] >= t0 ].loc[e4sync_offset['TEMP']['Second'] <= tf ]\n",
    "    synced_participant_data['EDA'] = e4sync_offset['EDA'].loc[e4sync_offset['EDA']['Second'] >= t0 ].loc[e4sync_offset['EDA']['Second'] <= tf ]\n",
    "    synced_participant_data['HR'] = e4_dict['HR'].loc[e4_dict['HR']['Second'] >= t0 ].loc[e4_dict['HR']['Second'] <= tf ]\n",
    "    #synced_participant_data['IBI'] = e4sync_offset['IBI'].loc[e4sync_offset['IBI']['Second'] >= t0 ].loc[e4sync_offset['IBI']['Second'] <= tf ]\n",
    "    del tf, t0\n",
    "\n",
    "    hx_dict['ACC'] = hx_dict['accx']\n",
    "    hx_dict['ACC']['Acc_Y'] = hx_dict['accy']['Acc_Y']\n",
    "    hx_dict['ACC']['Acc_Z'] = hx_dict['accz']['Acc_Z']\n",
    "     \n",
    "    acc_dic = accsync_offset(e4sync_offset['ACC'],hxsync_offset['accx'])\n",
    "    #offset_ecg_cross, offset_bvp_cross = doublesync_offset(e4sync_offset['ECG'], e4sync_offset['BVP'])\n",
    "    synced_participant_data['ACC_hx'] = acc_dic['acc_hx']\n",
    "    synced_participant_data['ACC_e4'] = acc_dic['acc_e4']\n",
    "\n",
    "    return synced_participant_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/bbnp/Vansh/data/RADWear/Participant 4/p_4.pkl\n",
      "participant  4  already processed.\n",
      "/projects/bbnp/Vansh/data/RADWear/Participant 7/p_7.pkl\n",
      "participant  7  already processed.\n",
      "/projects/bbnp/Vansh/data/RADWear/Participant 9/p_9.pkl\n",
      "participant  9  already processed.\n",
      "/projects/bbnp/Vansh/data/RADWear/Participant 12/p_12.pkl\n",
      "participant  12  already processed.\n",
      "/projects/bbnp/Vansh/data/RADWear/Participant 14/p_14.pkl\n",
      "participant  14  already processed.\n",
      "/projects/bbnp/Vansh/data/RADWear/Participant 16/p_16.pkl\n",
      "participant  16  already processed.\n",
      "/projects/bbnp/Vansh/data/RADWear/Participant 17/p_17.pkl\n",
      "participant  17  already processed.\n",
      "/projects/bbnp/Vansh/data/RADWear/Participant 18/p_18.pkl\n",
      "participant  18  already processed.\n",
      "/projects/bbnp/Vansh/data/RADWear/Participant 21/p_21.pkl\n",
      "participant  21  already processed.\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# p5 HA day 8 and p9 HA day 10 will be done manually. redcap is marked as 0 but data is available\n",
    "#########################\n",
    "\n",
    "# wesad.keys() = dict_keys(['signal', 'label', 'subject']); label returns array subject: S$ \n",
    "incomplete = [guy for guy in list_of_participants if guy not in completed_participants]\n",
    "\n",
    "for p in list_of_participants:\n",
    "    # check if participant pickle file exists\n",
    "    if Path(radwear_path+'Participant '+str(p)+'/p_'+str(p)+'.pkl').is_file():\n",
    "        print(radwear_path+'Participant '+str(p)+'/p_'+str(p)+'.pkl')\n",
    "        print('participant ', p, ' already processed.')\n",
    "        completed_participants.append(p)\n",
    "incomplete = [guy for guy in list_of_participants if guy not in completed_participants]\n",
    "if force_update:\n",
    "    incomplete = list_of_participants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procesing participant:  12  calibration data...\n",
      "procesing participant:  12  LA day  1 ...\n",
      "procesing participant:  12  LA day  2 ...\n",
      "procesing participant:  12  LA day  3 ...\n",
      "procesing participant:  12  LA day  4 ...\n",
      "procesing participant:  12  LA day  5 ...\n",
      "procesing participant:  12  LA day  6 ...\n",
      "procesing participant:  12  LA day  7 ...\n",
      "procesing participant:  12  LA day  8 ...\n",
      "procesing participant:  12  HA day  1 ...\n",
      "procesing participant:  12  HA day  2 ...\n",
      "procesing participant:  12  HA day  3 ...\n",
      "procesing participant:  12  HA day  4 ...\n",
      "procesing participant:  12  HA day  5 ...\n",
      "procesing participant:  12  HA day  6 ...\n",
      "procesing participant:  12  HA day  7 ...\n",
      "procesing participant:  12  HA day  8 ...\n",
      "procesing participant:  12  HA day  9 ...\n",
      "procesing participant:  12  HA day  10 ...\n",
      "participant  12  done.\n",
      "participant  12  pickled.\n",
      "-----------------------------------\n",
      "completed participants:  [4, 7, 9, 12, 14, 16, 17, 18, 21, 12]\n",
      "incomplete participants:  [12]\n"
     ]
    }
   ],
   "source": [
    "for p in incomplete:\n",
    "    print('procesing participant: ', p, ' calibration data...')\n",
    "    p_all[p] = {}\n",
    "    p_la[p] = {}\n",
    "    p_ha[p] = {}\n",
    "    p_path = radwear_path+'Participant '+str(p)\n",
    "    # load participant e4 data\n",
    "    e4sn = all_p_metadata[str(p)]['e4sn']\n",
    "    calibration_files = all_p_metadata[str(p)]['calibration']\n",
    "    LA = all_p_metadata[str(p)]['LA']\n",
    "    HA = all_p_metadata[str(p)]['HA']\n",
    "    \n",
    "    # load calibration data\n",
    "    e4_num = all_p_metadata[str(p)]['e4sn']+'_'+all_p_metadata[str(p)]['calibration'][0]\n",
    "    hx_num = str(all_p_metadata[str(p)]['calibration'][1])\n",
    "    p_calib[p] = read_sync_return(p_path, e4_num, hx_num)\n",
    "    p_calib[p]['rot_label'] = rot_anx_dict['calibration'] * np.ones(len(p_calib[p]['ECG'])) # add label to designate calibration segment\n",
    "    \n",
    "    #####################\n",
    "    # for when adding labels for cpt and meditation\n",
    "    #calib_label = for \n",
    "    \n",
    "    if all_p_metadata[str(p)]['complete days'][0] > 0:\n",
    "        # loop for LA\n",
    "        for i in range(all_p_metadata[str(p)]['complete days'][0]): \n",
    "            if not (all_p_metadata[str(p)]['RedCap available'][0][i] == 0 or all_p_metadata[str(p)]['LA'][0][i] == 0 or all_p_metadata[str(p)]['LA'][1][i] == 0): \n",
    "                print('procesing participant: ', p, ' LA day ', i+1, '...')    \n",
    "                e4_num = all_p_metadata[str(p)]['e4sn']+'_'+all_p_metadata[str(p)]['LA'][0][i]\n",
    "                hx_num = str(all_p_metadata[str(p)]['LA'][1][i])\n",
    "                \n",
    "                p_la[p][i] = read_sync_return(p_path, e4_num, hx_num)\n",
    "                p_la[p][i]['rot_label']= rot_anx_dict['LA'] * np.ones(len(p_la[p][i]['ECG'])) \n",
    "            else:\n",
    "                p_la[p][i] = {} \n",
    "    if all_p_metadata[str(p)]['complete days'][1] > 0:\n",
    "        # loop for HA    \n",
    "        for j in range(all_p_metadata[str(p)]['complete days'][1]): # loop for HA\n",
    "            if not (all_p_metadata[str(p)]['RedCap available'][1][j] == 0 or all_p_metadata[str(p)]['HA'][0][j] == 0 or all_p_metadata[str(p)]['HA'][1][j] == 0): \n",
    "                print('procesing participant: ', p, ' HA day ', j+1, '...')    \n",
    "                e4_num = all_p_metadata[str(p)]['e4sn']+'_'+all_p_metadata[str(p)]['HA'][0][j]\n",
    "                hx_num = str(all_p_metadata[str(p)]['HA'][1][j])\n",
    "                \n",
    "                p_ha[p][j] = read_sync_return(p_path, e4_num, hx_num)\n",
    "                p_ha[p][j]['rot_label']= rot_anx_dict['HA'] * np.ones(len(p_ha[p][j]['ECG']))\n",
    "            else:\n",
    "                p_ha[p][j] = {}\n",
    "    \n",
    "    print('participant ', p, ' done.')\n",
    "    if True:\n",
    "        try:\n",
    "            p_all[p]['calib']= p_calib[p]\n",
    "        except:\n",
    "            print('participant ', p, ' has no calibration data.')\n",
    "            p_all[p]['calib'] = {}\n",
    "        try:    \n",
    "            p_all[p]['LA'] = p_la[p]\n",
    "        except:\n",
    "            print('participant ', p, ' has no LA data.')\n",
    "            p_all[p]['LA'] = {}      \n",
    "        try: \n",
    "            p_all[p]['HA'] = p_ha[p]\n",
    "        except:\n",
    "            print('participant ', p, ' has no HA data.')\n",
    "            p_all[p]['HA'] = {}\n",
    "        #save this participant data to a pickle file\n",
    "        \n",
    "    with open(p_path+'/p_'+str(p)+'.pkl', 'wb') as handle:\n",
    "            pickle.dump(p_all[p], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    #p_all[p].to_parquet('/p_'+str(p)+'.parquet', engine='pyarrow')\n",
    "\n",
    "    print('participant ', p, ' pickled.')\n",
    "\n",
    "    #df = pd.DataFrame.from_dict(p_all[p])\n",
    "    #df.to_parquet(p_path+'/p_'+str(p)+'.parquet')\n",
    "    #print('participant ', p, ' parqued.')\n",
    "\n",
    "        \n",
    "\n",
    "    completed_participants.append(p)\n",
    "    print('-----------------------------------')\n",
    "\n",
    "print('completed participants: ', completed_participants)\n",
    "# print('incomplete participants: ', incomplete) doesn't update after loop completes them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/bbnp/Vansh/data/RADWear/Participant 12/p_12.pkl'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_path+'/p_'+str(p)+'.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_p = {}\n",
    "#load each participant's data\n",
    "force_update = False\n",
    "for p in list_of_participants:\n",
    "    p_path = radwear_path + 'Participant '+str(p)\n",
    "    p_df = pd.DataFrame()\n",
    "    \n",
    "    #check if file exist\n",
    "    a = 'available.' if os.path.isfile(p_path + '/p_'+str(p)+'.pkl') else ' not available.'\n",
    "    print('pickle file for participant '+str(p)+ ' is '+ a)\n",
    "    \n",
    "    #all_p[p] = p_data ## this takes too much memory so i will just load each p when needed\n",
    "    if not (os.path.isfile(radwear_path +'p_'+str(p)+'.pkl')) or force_update:\n",
    "\n",
    "\n",
    "        with open(p_path +  '/p_'+str(p)+'.pkl', 'rb') as f:\n",
    "            p_data = pickle.load(f)\n",
    "        print ('participant '+str(p)+ ' data loaded.')\n",
    "        print('-----------------------') \n",
    "        print('Participant: ', p)\n",
    "        print('-----------------------')    \n",
    "        #print('p_data.keys(): ', p_data.keys())\n",
    "        #print('-----------------------')\n",
    "        print('la days: ', len(p_data['HA'].keys()))\n",
    "        print('ha days: ', len(p_data['LA'].keys()))\n",
    "        print('-----------------------')\n",
    "        #print('p_data[calib].keys(): ', p_data['calib'].keys())\n",
    "        # e4 contains BVP, EDA, TEMP, ACC, IBI, HR, HRV, tags\n",
    "        # hx contains ECG, ACC, BR\n",
    "        p_redcap = redcap_df.loc[redcap_df['participant'] == p] # redcap data for participant p\n",
    "\n",
    "\n",
    "        ## this is for participant p \n",
    "\n",
    "        for day in list(p_data['LA'].keys()): \n",
    "\n",
    "            proceed1 = bool(len(p_data['LA'][day])) and bool(all_p_metadata[str(p)]['RedCap available'][0][day])\n",
    "            \n",
    "            if proceed1:\n",
    "                \n",
    "                LA_df = p_data['LA'][day]['BVP'].copy()\n",
    "                del p_data['LA'][day]['BVP']\n",
    "                resample_ratio = round(len(LA_df))\n",
    "\n",
    "                LA_df['ECG'] = signal.resample(p_data['LA'][day]['ECG']['ECG'], resample_ratio)\n",
    "                del p_data['LA'][day]['ECG']\n",
    "                #LA_df['BVP'] = signal.resample(p_data['LA'][day]['BVP']['BVP'], resample_ratio)\n",
    "                LA_df['EDA'] = signal.resample(p_data['LA'][day]['EDA']['EDA'], resample_ratio)\n",
    "                del p_data['LA'][day]['EDA']\n",
    "                LA_df['TEMP'] = signal.resample(p_data['LA'][day]['TEMP']['Temp'], resample_ratio)\n",
    "                del p_data['LA'][day]['TEMP']\n",
    "                LA_df['BR'] = signal.resample(p_data['LA'][day]['BR']['breathing_rate'], resample_ratio)\n",
    "                del p_data['LA'][day]['BR']\n",
    "                LA_df['ACCx_hx'] = signal.resample(p_data['LA'][day]['ACC_hx']['Acceleration_X'], resample_ratio)\n",
    "                del p_data['LA'][day]['ACC_hx']['Acceleration_X']\n",
    "                LA_df['ACCy_hx'] = signal.resample(p_data['LA'][day]['ACC_hx']['Acceleration_Y'], resample_ratio)\n",
    "                del p_data['LA'][day]['ACC_hx']['Acceleration_Y']\n",
    "                LA_df['ACCz_hx'] = signal.resample(p_data['LA'][day]['ACC_hx']['Acceleration_Z'], resample_ratio)\n",
    "                del p_data['LA'][day]['ACC_hx']['Acceleration_Z']   \n",
    "                LA_df['ACCx_e4'] = signal.resample(p_data['LA'][day]['ACC_e4']['Acc_X'], resample_ratio)\n",
    "                del p_data['LA'][day]['ACC_e4']['Acc_X']\n",
    "                LA_df['ACCy_e4'] = signal.resample(p_data['LA'][day]['ACC_e4']['Acc_Y'], resample_ratio)\n",
    "                del p_data['LA'][day]['ACC_e4']['Acc_Y']\n",
    "                LA_df['ACCz_e4'] = signal.resample(p_data['LA'][day]['ACC_e4']['Acc_Z'], resample_ratio)\n",
    "                del p_data['LA'][day]['ACC_e4']['Acc_Z']\n",
    "                LA_df['rot_label'] = rot_anx_dict['LA']* np.ones(resample_ratio)\n",
    "                LA_df['calib_label'] = np.zeros(resample_ratio)\n",
    "\n",
    "                for column in columns_list:\n",
    "                    if column == 'daily_check_in_date':\n",
    "                        A = np.chararray(resample_ratio,itemsize=15,unicode=True)\n",
    "                        A[:] = ((redcap_df.loc[redcap_df['participant'] == p]).iloc[day][column])\n",
    "                        LA_df[column] = A\n",
    "                    else:\n",
    "                        LA_df[column] = np.ones(resample_ratio)* (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][column] \n",
    "                \n",
    "                print('Done with day ', day, 'date: ',(redcap_df.loc[redcap_df['participant'] == p]).iloc[day]['daily_check_in_date'],' of LA rotation for participant ', p)               \n",
    "                p_df = pd.concat([p_df, LA_df], ignore_index=True, sort=False)\n",
    "                #print('display LA_df after LA_df')\n",
    "                #display(LA_df)\n",
    "                \n",
    "\n",
    "        for day in list(p_data['HA'].keys()):\n",
    "            proceed2 = bool(len(p_data['HA'][day])) and bool(all_p_metadata[str(p)]['RedCap available'][1][day])\n",
    "            if proceed2:\n",
    "                    \n",
    "                \n",
    "                HA_df = p_data['HA'][day]['BVP'].copy()\n",
    "                del p_data['HA'][day]['BVP']\n",
    "                resample_ratio = round(len(HA_df))\n",
    "                HA_df['ECG'] = signal.resample(p_data['HA'][day]['ECG']['ECG'], resample_ratio)\n",
    "                del p_data['HA'][day]['ECG']\n",
    "                #HA_df['BVP'] = signal.resample(p_data['HA'][day]['BVP']['BVP'], resample_ratio)\n",
    "\n",
    "                HA_df['EDA'] = signal.resample(p_data['HA'][day]['EDA']['EDA'], resample_ratio)\n",
    "                del p_data['HA'][day]['EDA']\n",
    "                HA_df['TEMP'] = signal.resample(p_data['HA'][day]['TEMP']['Temp'], resample_ratio)\n",
    "                del p_data['HA'][day]['TEMP']\n",
    "                HA_df['BR'] = signal.resample(p_data['HA'][day]['BR']['breathing_rate'], resample_ratio)\n",
    "                del p_data['HA'][day]['BR']\n",
    "                HA_df['ACCx_hx'] = signal.resample(p_data['HA'][day]['ACC_hx']['Acceleration_X'], resample_ratio)\n",
    "                del p_data['HA'][day]['ACC_hx']['Acceleration_X']\n",
    "                HA_df['ACCy_hx'] = signal.resample(p_data['HA'][day]['ACC_hx']['Acceleration_Y'], resample_ratio)\n",
    "                del p_data['HA'][day]['ACC_hx']['Acceleration_Y']\n",
    "                HA_df['ACCz_hx'] = signal.resample(p_data['HA'][day]['ACC_hx']['Acceleration_Z'], resample_ratio)\n",
    "                del p_data['HA'][day]['ACC_hx']['Acceleration_Z']\n",
    "                HA_df['ACCx_e4'] = signal.resample(p_data['HA'][day]['ACC_e4']['Acc_X'], resample_ratio)\n",
    "                del p_data['HA'][day]['ACC_e4']['Acc_X']\n",
    "                HA_df['ACCy_e4'] = signal.resample(p_data['HA'][day]['ACC_e4']['Acc_Y'], resample_ratio)\n",
    "                del p_data['HA'][day]['ACC_e4']['Acc_Y']\n",
    "                HA_df['ACCz_e4'] = signal.resample(p_data['HA'][day]['ACC_e4']['Acc_Z'], resample_ratio)\n",
    "                del p_data['HA'][day]['ACC_e4']['Acc_Z']\n",
    "                HA_df['rot_label'] = rot_anx_dict['HA']* np.ones(resample_ratio) \n",
    "                HA_df['calib_label'] = np.zeros(resample_ratio)\n",
    "\n",
    "                for column in columns_list:\n",
    "                    if column == 'daily_check_in_date':\n",
    "                        A = np.chararray(resample_ratio,itemsize=15,unicode=True)\n",
    "                        A[:] = ((redcap_df.loc[redcap_df['participant'] == p]).iloc[day][column])\n",
    "                        HA_df[column] = A\n",
    "                        \n",
    "                    else:\n",
    "                        HA_df[column] = np.ones(resample_ratio)* (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][column] \n",
    "                        \n",
    "                print('Done with day ', day, 'date: ',(redcap_df.loc[redcap_df['participant'] == p]).iloc[day]['daily_check_in_date'],' of HA rotation for participant ', p)\n",
    "                p_df = pd.concat([p_df, HA_df], ignore_index=True, sort=False)\n",
    "                #print('display HA_df after HA_df')\n",
    "                #display(HA_df)\n",
    "                \n",
    "\n",
    "        \n",
    "        calib_df = p_data['calib']['BVP'].copy()\n",
    "        del p_data['calib']['BVP']\n",
    "        resample_ratio = round(len(calib_df))\n",
    "        \n",
    "        calib_df['ECG'] = signal.resample(p_data['calib']['ECG']['ECG'], resample_ratio)\n",
    "        del p_data['calib']['ECG']\n",
    "        #calib_df['BVP'] = signal.resample(p_data['calib']['BVP']['BVP'], resample_ratio)\n",
    "        calib_df['EDA'] = signal.resample(p_data['calib']['EDA']['EDA'], resample_ratio)\n",
    "        del p_data['calib']['EDA']\n",
    "        calib_df['TEMP'] = signal.resample(p_data['calib']['TEMP']['Temp'], resample_ratio)\n",
    "        del p_data['calib']['TEMP']\n",
    "        calib_df['BR'] = signal.resample(p_data['calib']['BR']['breathing_rate'], resample_ratio)\n",
    "        del p_data['calib']['BR']\n",
    "        calib_df['ACCx_hx'] = signal.resample(p_data['calib']['ACC_hx']['Acceleration_X'], resample_ratio)\n",
    "        del p_data['calib']['ACC_hx']['Acceleration_X']\n",
    "        calib_df['ACCy_hx'] = signal.resample(p_data['calib']['ACC_hx']['Acceleration_Y'], resample_ratio)\n",
    "        del p_data['calib']['ACC_hx']['Acceleration_Y']\n",
    "        calib_df['ACCz_hx'] = signal.resample(p_data['calib']['ACC_hx']['Acceleration_Z'], resample_ratio)\n",
    "        del p_data['calib']['ACC_hx']['Acceleration_Z']\n",
    "        calib_df['ACCx_e4'] = signal.resample(p_data['calib']['ACC_e4']['Acc_X'], resample_ratio)\n",
    "        del p_data['calib']['ACC_e4']['Acc_X']\n",
    "        calib_df['ACCy_e4'] = signal.resample(p_data['calib']['ACC_e4']['Acc_Y'], resample_ratio)\n",
    "        del p_data['calib']['ACC_e4']['Acc_Y']\n",
    "        calib_df['ACCz_e4'] = signal.resample(p_data['calib']['ACC_e4']['Acc_Z'], resample_ratio)\n",
    "        del p_data['calib']['ACC_e4']['Acc_Z']\n",
    "        calib_df['rot_label'] = rot_anx_dict['calibration']* np.ones(resample_ratio)\n",
    "        calib_df['calib_label'] = np.ones(resample_ratio) #complete later\n",
    "        redcap_dfcalib = redcap_df # a cheat for now since i don't have redcap data for calibration\n",
    "        columns_list = redcap_dfcalib.columns\n",
    "        ############################################\n",
    "        # redcap for calibration doesn't exist yet #\n",
    "        ############################################\n",
    "\n",
    "        for column in columns_list:\n",
    "            #print(column)\n",
    "            #print((redcap_dfcalib.loc[redcap_dfcalib['participant'] == p]).iloc[0][column]) # this is incorrect for now, replace with calibration data later\n",
    "            if column == 'daily_check_in_date':\n",
    "                A = np.chararray(resample_ratio,itemsize=15,unicode=True)\n",
    "                A[:] = ((redcap_dfcalib.loc[redcap_dfcalib['participant'] == p]).iloc[0][column]) # this is incorrect for now, replace with calibration data later\n",
    "                calib_df[column] = A\n",
    "            else:\n",
    "                calib_df[column] = np.ones(resample_ratio)* (redcap_dfcalib.loc[redcap_dfcalib['participant'] == p]).iloc[0][column] # this is incorrect for now, replace with calibration data later\n",
    "\n",
    "\n",
    "        p_df = pd.concat([p_df, calib_df], ignore_index=True, sort=False)\n",
    "        #print('display calib_df after calib')\n",
    "        #display(calib_df)\n",
    "        #display(calib_df)\n",
    "\n",
    "\n",
    "\n",
    "        # save the data\n",
    "        print('Pickling processed data for participant '+str(p)+ ' ...')\n",
    "        with open(radwear_path +'p_'+str(p)+'.pkl', 'wb') as f:\n",
    "            pickle.dump(p_df, f)\n",
    "        print('data pickled...')\n",
    "        \n",
    "    else:\n",
    "        print('processed data for participant '+str(p)+ ' is already available!')\n",
    "        # load the data\n",
    "        #with open(radwear_path +'p_'+str(p)+'.pkl', 'rb') as f:\n",
    "        #    p_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combining into 1 DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_p_df = pd.DataFrame()\n",
    "\n",
    "for p in list_of_participants:\n",
    "    p_path = radwear_path \n",
    "    #p_df = pd.DataFrame()\n",
    "    \n",
    "    #check if file exist\n",
    "    a = 'available.' if os.path.isfile(p_path + '/p_'+str(p)+'.pkl') else ' not available.'\n",
    "    print('processed data for participant '+str(p)+ ' is '+ a)\n",
    "    print('Loading...')\n",
    "    with open(p_path +  '/p_'+str(p)+'.pkl', 'rb') as f:\n",
    "        p_df = pickle.load(f)\n",
    "    print ('participant '+str(p)+ ' data loaded.')\n",
    "    print('-----------------------') \n",
    "    all_p_df = pd.concat([all_p_df, p_df], ignore_index=True, sort=False)\n",
    "    display(p_df.sample(3))\n",
    "    all_p_df.columns\n",
    "print('pickling all participants file...')\n",
    "all_p_df.to_pickle(radwear_path+'all_participants.pkl')\n",
    "print('pickling completed. ')\n",
    "print('DF for all participants is saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
