{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'modified by abdul alkurdi; 10/05/2023'\n",
    "\n",
    "import pandas as pd\n",
    "#import cudf\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.signal import correlate\n",
    "#import cupy as cp\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal, stats\n",
    "#import peakutils, wfdb, pywt\n",
    "import csv\n",
    "import os, statistics\n",
    "from datetime import datetime\n",
    "#import heartpy as hp\n",
    "import json\n",
    "%matplotlib widget \n",
    "# import neurokit2 as nk\n",
    "\n",
    "from syncfcns import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#####   force update ?     #####\n",
    "################################\n",
    "force_update = False\n",
    "\n",
    "\n",
    "radwear_path = '/mnt/c/Users/alkurdi/Desktop/Vansh/data/RADWear/'\n",
    "redcap_path = radwear_path + 'REDCap responses/'\n",
    "\n",
    "# load all participant meta data\n",
    "with open(radwear_path + 'all_p_metadata.json', 'rb') as f:\n",
    "    all_p_metadata = json.load(f)\n",
    "# load all participant redcap data\n",
    "\n",
    "with open(redcap_path + 'redcap_df_2nd.pkl', 'rb') as f:\n",
    "    redcap_df = pickle.load(f)\n",
    "    \n",
    "\n",
    "list_of_participants = all_p_metadata['list of participant IDs']\n",
    "completed_participants = []\n",
    "\n",
    "\n",
    "# label definitions\n",
    "calib_dict = {'meditation': 1, 'cpt': 2, 'baseline': 0}\n",
    "rot_anx_dict = {'calibration': 0, 'LA': 1, 'HA': 2}\n",
    "\n",
    "p_calib = {}\n",
    "p_la = {}\n",
    "p_ha = {}\n",
    "p_all = {}\n",
    "incomplete = [guy for guy in list_of_participants if guy not in completed_participants]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fcn defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant  4  already processed.\n",
      "participant  7  already processed.\n",
      "participant  9  already processed.\n",
      "participant  12  already processed.\n",
      "participant  14  already processed.\n",
      "participant  16  already processed.\n",
      "participant  17  already processed.\n",
      "participant  18  already processed.\n",
      "participant  21  already processed.\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# p5 HA day 8 and p9 HA day 10 will be done manually.\n",
    "# redcap is marked as 0 but data is available\n",
    "#########################\n",
    "\n",
    "incomplete = [guy for guy in list_of_participants if guy not in completed_participants]\n",
    "for p in list_of_participants:\n",
    "    # check if participant pickle file exists\n",
    "    if Path(radwear_path + 'Participant ' + str(p) + '/p_' + str(p) + '.pkl').is_file():\n",
    "        # print(radwear_path+'Participant '+str(p)+'/p_'+str(p)+'.pkl')\n",
    "        print('participant ', p, ' already processed.')\n",
    "        completed_participants.append(p)\n",
    "incomplete = [guy for guy in list_of_participants if guy not in completed_participants]\n",
    "if force_update:\n",
    "    incomplete = list_of_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redcap_calib_dict = pd.read_pickle(radwear_path+'/REDCap responses/redcap_calib_dict.pkl')\n",
    "event_type = ['calm_cal_x2', 'secure_cal_x2', 'tense_cal_x2', \n",
    "              'regretful_cal_x2', 'ease_cal_x2', 'upset_cal_x2',\n",
    "              'worrying_cal_x2', 'rested_cal_x2', 'anxious_cal_x2',\n",
    "              'comfort_cal_x2', 'self_conf_cal_x2', 'nervous_cal_x2',\n",
    "              'jittery_cal_x2', 'strun_cal_x2', 'relaxed_cal_x2',\n",
    "              'content_cal_x2', 'worried_cal_x2', 'excited_cal_x2', \n",
    "              'joyful_cal_x2', 'pleasant_cal_x2', 'calm_cal_y6', \n",
    "              'tense_cal_y6', 'upset_cal_y6', 'relax_cal_y6',\n",
    "              'content_cal_y6', 'worried_cal_y6', 'calm_cal_y6_post',\n",
    "              'tense_cal_y6_post', 'upset_cal_y6_post', 'relax_cal_y6_post',\n",
    "              'content_cal_y6_post', 'worry_cal_y6_post', 'calm_cal_y6_cold',\n",
    "              'tense_cal_y6_cold', 'upset_cal_y6_cold', 'relax_cal_y6_cold', \n",
    "              'content_cal_y6_cold', 'worry_cal_y6_cold', 'baseline_calibration_complete']\n",
    "tag_info = {4: '',\n",
    "            7: 'skip 0',\n",
    "            9: '',\n",
    "            12: '',\n",
    "            14: 'add 60 to 2',\n",
    "            16: 'skip 0',\n",
    "            17: 'skip 0',\n",
    "            18: 'skip 01',\n",
    "            19: 'skip 0',\n",
    "            21: 'skip 0',\n",
    "}\n",
    "\n",
    "p_calib = {}\n",
    "for p in incomplete:\n",
    "    print('procesing participant: ', p, ' calibration data...')\n",
    "    p_all[p] = {}\n",
    "    p_la[p] = {}\n",
    "    p_ha[p] = {}\n",
    "    p_path = radwear_path+'Participant '+str(p)\n",
    "    # load participant e4 data\n",
    "    e4sn = all_p_metadata[str(p)]['e4sn']\n",
    "    calibration_files = all_p_metadata[str(p)]['calibration']\n",
    "    LA = all_p_metadata[str(p)]['LA']\n",
    "    HA = all_p_metadata[str(p)]['HA']\n",
    "    \n",
    "    # load calibration data\n",
    "    e4_num = all_p_metadata[str(p)]['e4sn']+'_'+all_p_metadata[str(p)]['calibration'][0]\n",
    "    hx_num = str(all_p_metadata[str(p)]['calibration'][1])\n",
    "    p_calib[p] = read_sync_return(p_path, e4_num, hx_num)\n",
    "    print('marker 1')\n",
    "    #####################\n",
    "    # calibration data\n",
    "    #####################\n",
    "    \n",
    "    p_calib[p]['rot_label'] = rot_anx_dict['calibration'] * np.ones(len(p_calib[p]['ECG'])) # add label to designate calibration segment\n",
    "    # get calibration event tags \n",
    "    tags = pd.read_csv(\n",
    "        radwear_path + 'Participant ' + str(p) + '/' + e4_num + '/tags.csv', header=None\n",
    "    )\n",
    "    #print(tag_info[p])\n",
    "    tag_command = tag_info[p].split(' ')\n",
    "    \n",
    "    if len(tag_command[-1]) ==1 and tag_command[0] == 'skip':\n",
    "        tags = tags.drop(int(tag_command[-1]))\n",
    "    elif len(tag_command[-1]) ==2:\n",
    "        #print(tag_command[-1][0], tag_command[-1][1])\n",
    "        tags.drop([int(tag_command[-1][0]),int(tag_command[-1][1])], axis=0 ,inplace=True)\n",
    "    elif len(tag_command[-1]) ==1 and tag_command[0] == 'add':\n",
    "        new_row = pd.DataFrame(tags.values[-1]+60,columns=tags.columns)\n",
    "        tags = pd.concat([tags,new_row], ignore_index=True)\n",
    "    else:\n",
    "        tag_command = None\n",
    "    tags.reset_index(drop=True, inplace=True) \n",
    "\n",
    "    print('marker 2')\n",
    "    # add label to designate calibration segment. same length as bvp to make things easier\n",
    "    p_calib[p]['calib_label'] = p_calib[p]['BVP'].copy(deep=True) # add label to designate calibration segment\n",
    "    p_calib[p]['calib_label'].drop(columns=['BVP','Second'], inplace=True)\n",
    "    p_calib[p]['calib_label']['calib_label'] = 0\n",
    "    #display(p_calib[p]['calib_label'])\n",
    "    p_calib[p]['calib_label']['calib_label'][(p_calib[p]['calib_label']['Timestamp'] > tags.iloc[0].values[0]) & \\\n",
    "                                            (p_calib[p]['calib_label']['Timestamp'] < tags.iloc[1].values[0])] \\\n",
    "                                                = calib_dict['meditation']\n",
    "    p_calib[p]['calib_label']['calib_label'][(p_calib[p]['calib_label']['Timestamp'] > tags.iloc[2].values[0]) & \\\n",
    "                                                (p_calib[p]['calib_label']['Timestamp'] < tags.iloc[3].values[0])] \\\n",
    "                                                    = calib_dict['cpt']\n",
    "                                                     \n",
    "    \n",
    "    \n",
    "    #####################\n",
    "    # HA data\n",
    "    #####################\n",
    "    if all_p_metadata[str(p)]['complete days'][0] > 0:\n",
    "        # loop for LA\n",
    "        for i in range(all_p_metadata[str(p)]['complete days'][0]): \n",
    "            if not (all_p_metadata[str(p)]['RedCap available'][0][i] == 0 or all_p_metadata[str(p)]['LA'][0][i] == 0 or all_p_metadata[str(p)]['LA'][1][i] == 0): \n",
    "                print('procesing participant: ', p, ' LA day ', i+1, '...')    \n",
    "                e4_num = all_p_metadata[str(p)]['e4sn']+'_'+all_p_metadata[str(p)]['LA'][0][i]\n",
    "                hx_num = str(all_p_metadata[str(p)]['LA'][1][i])\n",
    "                \n",
    "                p_la[p][i] = read_sync_return(p_path, e4_num, hx_num)\n",
    "                p_la[p][i]['rot_label']= rot_anx_dict['LA'] * np.ones(len(p_la[p][i]['ECG'])) \n",
    "            else:\n",
    "                p_la[p][i] = {} \n",
    "    #####################\n",
    "    # LA data\n",
    "    #####################\n",
    "    if all_p_metadata[str(p)]['complete days'][1] > 0:\n",
    "        # loop for HA    \n",
    "        for j in range(all_p_metadata[str(p)]['complete days'][1]): # loop for HA\n",
    "            if not (all_p_metadata[str(p)]['RedCap available'][1][j] == 0 or all_p_metadata[str(p)]['HA'][0][j] == 0 or all_p_metadata[str(p)]['HA'][1][j] == 0): \n",
    "                print('procesing participant: ', p, ' HA day ', j+1, '...')    \n",
    "                e4_num = all_p_metadata[str(p)]['e4sn']+'_'+all_p_metadata[str(p)]['HA'][0][j]\n",
    "                hx_num = str(all_p_metadata[str(p)]['HA'][1][j])\n",
    "                \n",
    "                p_ha[p][j] = read_sync_return(p_path, e4_num, hx_num)\n",
    "                p_ha[p][j]['rot_label']= rot_anx_dict['HA'] * np.ones(len(p_ha[p][j]['ECG']))\n",
    "            else:\n",
    "                p_ha[p][j] = {}\n",
    "    \n",
    "    print('participant ', p, ' done.')\n",
    "    if True:\n",
    "        try:\n",
    "            p_all[p]['calib']= p_calib[p]\n",
    "        except:\n",
    "            print('participant ', p, ' has no calibration data.')\n",
    "            p_all[p]['calib'] = {}\n",
    "        try:    \n",
    "            p_all[p]['LA'] = p_la[p]\n",
    "        except:\n",
    "            print('participant ', p, ' has no LA data.')\n",
    "            p_all[p]['LA'] = {}      \n",
    "        try: \n",
    "            p_all[p]['HA'] = p_ha[p]\n",
    "        except:\n",
    "            print('participant ', p, ' has no HA data.')\n",
    "            p_all[p]['HA'] = {}\n",
    "        #save this participant data to a pickle file\n",
    "        \n",
    "    with open(p_path+'/p_'+str(p)+'.pkl', 'wb') as handle:\n",
    "            pickle.dump(p_all[p], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    #p_all[p].to_parquet('/p_'+str(p)+'.parquet', engine='pyarrow')\n",
    "\n",
    "    print('participant ', p, ' pickled.')\n",
    "\n",
    "    #df = pd.DataFrame.from_dict(p_all[p])\n",
    "    #df.to_parquet(p_path+'/p_'+str(p)+'.parquet')\n",
    "    #print('participant ', p, ' parqued.')\n",
    "\n",
    "    #completed_participants.append(p)\n",
    "    print('-----------------------------------')\n",
    "    e4sn = None\n",
    "    calibration_files = None \n",
    "    LA = None\n",
    "    HA = None\n",
    "    e4_num = None\n",
    "    hx_num = None\n",
    "    tags = None\n",
    "    tag_command = None\n",
    "print('completed participants: ', set(completed_participants))\n",
    "# print('incomplete participants: ', incomplete) doesn't update after loop completes them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ECG', 'BVP', 'BR', 'RESP', 'B_PH', 'TEMP', 'EDA', 'HR', 'ACC_hx', 'ACC_e4', 'rot_label', 'calib_label'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=16\n",
    "p_all[p]['calib'].keys()\n",
    "\n",
    "p_all_like_wesad = {}\n",
    "\n",
    "\n",
    "p_like_wesad = {}\n",
    "p_like_wesad['subject'] = p\n",
    "p_like_wesad['signal'] = {}\n",
    "p_like_wesad['signal']['chest'] = {}\n",
    "p_like_wesad['signal']['chest']['ACC'] = p_all[p]['calib']['ACC_hx']\n",
    "p_like_wesad['signal']['chest']['ECG'] = p_all[p]['calib']['ECG']\n",
    "p_like_wesad['signal']['chest']['EDA'] = p_all[p]['calib']['EDA']\n",
    "p_like_wesad['signal']['chest']['Resp'] = p_all[p]['calib']['Resp']\n",
    "p_like_wesad['signal']['wrist'] = {}\n",
    "p_like_wesad['signal']['wrist']['ACC'] = p_all[p]['calib']['ACC_e4']\n",
    "p_like_wesad['signal']['wrist']['BVP'] = p_all[p]['calib']['BVP']\n",
    "p_like_wesad['signal']['wrist']['EDA'] = p_all[p]['calib']['EDA']\n",
    "p_like_wesad['signal']['wrist']['TEMP'] = p_all[p]['calib']['TEMP']\n",
    "p_like_wesad['label'] = {}\n",
    "p_like_wesad['label']['activity'] = p_all[p]['calib_label']\n",
    "p_like_wesad['label']['valence'] = p_all[p]['rot_label']\n",
    "\n",
    "\n",
    "\n",
    "p_all_like_wesad[p] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_p = {}\n",
    "# load each participant's data\n",
    "force_update = True\n",
    "for p in list_of_participants:\n",
    "    p_path = radwear_path + 'Participant ' + str(p)\n",
    "    p_df = pd.DataFrame()\n",
    "\n",
    "    # check if file exist\n",
    "    a = (\n",
    "        'available.'\n",
    "        if os.path.isfile(p_path + '/formatted_p_' + str(p) + '.pkl')\n",
    "        else ' not available.'\n",
    "    )\n",
    "    print('pickle file for participant ' + str(p) + ' is ' + a)\n",
    "\n",
    "    # all_p[p] = p_data ## this takes too much memory so i will just load each p when needed\n",
    "    if not (os.path.isfile(radwear_path + 'formatted_p_' + str(p) + '.pkl')) or force_update:\n",
    "        with open(p_path + '/formatted_p_' + str(p) + '.pkl', 'rb') as f:\n",
    "            p_data = pickle.load(f)\n",
    "        print('participant ' + str(p) + ' data loaded.')\n",
    "        print('-----------------------')\n",
    "        print('Participant: ', p)\n",
    "        print('-----------------------')\n",
    "        print('la days: ', len(p_data['HA'].keys()))\n",
    "        print('ha days: ', len(p_data['LA'].keys()))\n",
    "        print('-----------------------')\n",
    "        # e4 contains BVP, EDA, TEMP, ACC, IBI, HR, HRV, tags\n",
    "        # hx contains ECG, ACC, BR\n",
    "        p_redcap = redcap_df.loc[\n",
    "            redcap_df['participant'] == p\n",
    "        ]  # redcap data for participant p\n",
    "\n",
    "        ## this is for participant p\n",
    "\n",
    "        for day in list(p_data['LA'].keys()):\n",
    "            proceed1 = bool(len(p_data['LA'][day])) and bool(\n",
    "                all_p_metadata[str(p)]['RedCap available'][0][day]\n",
    "            )\n",
    "\n",
    "            if proceed1:\n",
    "                LA_df = p_data['LA'][day]['ECG'].copy()\n",
    "                del p_data['LA'][day]['ECG']\n",
    "                resample_ratio = round(len(LA_df))\n",
    "\n",
    "                LA_df['BVP'] = signal.resample(\n",
    "                    p_data['LA'][day]['BVP']['BVP'], resample_ratio\n",
    "                )\n",
    "                LA_df['participant'] = p\n",
    "                del p_data['LA'][day]['ECG']\n",
    "\n",
    "                LA_df['EDA'] = signal.resample(\n",
    "                    p_data['LA'][day]['EDA']['EDA'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['EDA']\n",
    "                LA_df['TEMP'] = signal.resample(\n",
    "                    p_data['LA'][day]['TEMP']['Temp'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['TEMP']\n",
    "                LA_df['BR'] = signal.resample(\n",
    "                    p_data['LA'][day]['BR']['breathing_rate'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['BR']\n",
    "                LA_df['ACCx_hx'] = signal.resample(\n",
    "                    p_data['LA'][day]['ACC_hx']['Acceleration_X'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['ACC_hx']['Acceleration_X']\n",
    "                LA_df['ACCy_hx'] = signal.resample(\n",
    "                    p_data['LA'][day]['ACC_hx']['Acceleration_Y'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['ACC_hx']['Acceleration_Y']\n",
    "                LA_df['ACCz_hx'] = signal.resample(\n",
    "                    p_data['LA'][day]['ACC_hx']['Acceleration_Z'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['ACC_hx']['Acceleration_Z']\n",
    "                LA_df['ACCx_e4'] = signal.resample(\n",
    "                    p_data['LA'][day]['ACC_e4']['Acc_X'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['ACC_e4']['Acc_X']\n",
    "                LA_df['ACCy_e4'] = signal.resample(\n",
    "                    p_data['LA'][day]['ACC_e4']['Acc_Y'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['ACC_e4']['Acc_Y']\n",
    "                LA_df['ACCz_e4'] = signal.resample(\n",
    "                    p_data['LA'][day]['ACC_e4']['Acc_Z'], resample_ratio\n",
    "                )\n",
    "                del p_data['LA'][day]['ACC_e4']['Acc_Z']\n",
    "                LA_df['rot_label'] = rot_anx_dict['LA'] * np.ones(resample_ratio)\n",
    "                LA_df['calib_label'] = np.zeros(resample_ratio)\n",
    "\n",
    "                for column in columns_list:\n",
    "                    if column == 'daily_check_in_date':\n",
    "                        A = np.chararray(resample_ratio, itemsize=15, unicode=True)\n",
    "                        A[:] = (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][\n",
    "                            column\n",
    "                        ]\n",
    "                        LA_df[column] = A\n",
    "                    else:\n",
    "                        LA_df[column] = (\n",
    "                            np.ones(resample_ratio)\n",
    "                            * (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][\n",
    "                                column\n",
    "                            ]\n",
    "                        )\n",
    "\n",
    "                print(\n",
    "                    'Done with day ',\n",
    "                    day,\n",
    "                    'date: ',\n",
    "                    (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][\n",
    "                        'daily_check_in_date'\n",
    "                    ],\n",
    "                    ' of LA rotation for participant ',\n",
    "                    p,\n",
    "                )\n",
    "                p_df = pd.concat([p_df, LA_df], ignore_index=True, sort=False)\n",
    "                # print('display LA_df after LA_df')\n",
    "                # display(LA_df)\n",
    "\n",
    "        for day in list(p_data['HA'].keys()):\n",
    "            proceed2 = bool(len(p_data['HA'][day])) and bool(\n",
    "                all_p_metadata[str(p)]['RedCap available'][1][day]\n",
    "            )\n",
    "            if proceed2:\n",
    "                HA_df = p_data['HA'][day]['BVP'].copy()\n",
    "                del p_data['HA'][day]['BVP']\n",
    "                HA_df['participant'] = p\n",
    "                resample_ratio = round(len(HA_df))\n",
    "                HA_df['ECG'] = signal.resample(\n",
    "                    p_data['HA'][day]['ECG']['ECG'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['ECG']\n",
    "                # no need to increase sampling rate of signals. pandas can accept unevenly sampled data\n",
    "                HA_df['EDA'] = signal.resample(\n",
    "                    p_data['HA'][day]['EDA']['EDA'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['EDA']\n",
    "                HA_df['TEMP'] = signal.resample(\n",
    "                    p_data['HA'][day]['TEMP']['Temp'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['TEMP']\n",
    "                HA_df['BR'] = signal.resample(\n",
    "                    p_data['HA'][day]['BR']['breathing_rate'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['BR']\n",
    "                HA_df['ACCx_hx'] = signal.resample(\n",
    "                    p_data['HA'][day]['ACC_hx']['Acceleration_X'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['ACC_hx']['Acceleration_X']\n",
    "                HA_df['ACCy_hx'] = signal.resample(\n",
    "                    p_data['HA'][day]['ACC_hx']['Acceleration_Y'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['ACC_hx']['Acceleration_Y']\n",
    "                HA_df['ACCz_hx'] = signal.resample(\n",
    "                    p_data['HA'][day]['ACC_hx']['Acceleration_Z'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['ACC_hx']['Acceleration_Z']\n",
    "                HA_df['ACCx_e4'] = signal.resample(\n",
    "                    p_data['HA'][day]['ACC_e4']['Acc_X'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['ACC_e4']['Acc_X']\n",
    "                HA_df['ACCy_e4'] = signal.resample(\n",
    "                    p_data['HA'][day]['ACC_e4']['Acc_Y'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['ACC_e4']['Acc_Y']\n",
    "                HA_df['ACCz_e4'] = signal.resample(\n",
    "                    p_data['HA'][day]['ACC_e4']['Acc_Z'], resample_ratio\n",
    "                )\n",
    "                del p_data['HA'][day]['ACC_e4']['Acc_Z']\n",
    "                HA_df['rot_label'] = rot_anx_dict['HA'] * np.ones(resample_ratio)\n",
    "                HA_df['calib_label'] = np.zeros(resample_ratio)\n",
    "\n",
    "                for column in columns_list:\n",
    "                    if column == 'daily_check_in_date':\n",
    "                        A = np.chararray(resample_ratio, itemsize=15, unicode=True)\n",
    "                        A[:] = (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][\n",
    "                            column\n",
    "                        ]\n",
    "                        HA_df[column] = A\n",
    "                    else:\n",
    "                        HA_df[column] = (\n",
    "                            np.ones(resample_ratio)\n",
    "                            * (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][\n",
    "                                column\n",
    "                            ]\n",
    "                        )\n",
    "\n",
    "                print(\n",
    "                    'Done with day ',\n",
    "                    day,\n",
    "                    'date: ',\n",
    "                    (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][\n",
    "                        'daily_check_in_date'\n",
    "                    ],\n",
    "                    ' of HA rotation for participant ',\n",
    "                    p,\n",
    "                )\n",
    "                p_df = pd.concat([p_df, HA_df], ignore_index=True, sort=False)\n",
    "\n",
    "        calib_df = p_data['calib']['BVP'].copy()\n",
    "        del p_data['calib']['BVP']\n",
    "        resample_ratio = round(len(calib_df))\n",
    "\n",
    "        calib_df['ECG'] = signal.resample(p_data['calib']['ECG']['ECG'], resample_ratio)\n",
    "        del p_data['calib']['ECG']\n",
    "        # calib_df['BVP'] = signal.resample(p_data['calib']['BVP']['BVP'], resample_ratio)\n",
    "        calib_df['EDA'] = signal.resample(p_data['calib']['EDA']['EDA'], resample_ratio)\n",
    "        del p_data['calib']['EDA']\n",
    "        calib_df['TEMP'] = signal.resample(\n",
    "            p_data['calib']['TEMP']['Temp'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['TEMP']\n",
    "        calib_df['BR'] = signal.resample(\n",
    "            p_data['calib']['BR']['breathing_rate'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['BR']\n",
    "        calib_df['ACCx_hx'] = signal.resample(\n",
    "            p_data['calib']['ACC_hx']['Acceleration_X'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['ACC_hx']['Acceleration_X']\n",
    "        calib_df['ACCy_hx'] = signal.resample(\n",
    "            p_data['calib']['ACC_hx']['Acceleration_Y'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['ACC_hx']['Acceleration_Y']\n",
    "        calib_df['ACCz_hx'] = signal.resample(\n",
    "            p_data['calib']['ACC_hx']['Acceleration_Z'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['ACC_hx']['Acceleration_Z']\n",
    "        calib_df['ACCx_e4'] = signal.resample(\n",
    "            p_data['calib']['ACC_e4']['Acc_X'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['ACC_e4']['Acc_X']\n",
    "        calib_df['ACCy_e4'] = signal.resample(\n",
    "            p_data['calib']['ACC_e4']['Acc_Y'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['ACC_e4']['Acc_Y']\n",
    "        calib_df['ACCz_e4'] = signal.resample(\n",
    "            p_data['calib']['ACC_e4']['Acc_Z'], resample_ratio\n",
    "        )\n",
    "        del p_data['calib']['ACC_e4']['Acc_Z']\n",
    "        calib_df['rot_label'] = rot_anx_dict['calibration'] * np.ones(resample_ratio)\n",
    "        calib_df['calib_label'] = np.ones(resample_ratio)  # complete later\n",
    "        redcap_dfcalib = (\n",
    "            redcap_df  # a cheat for now since i don't have redcap data for calibration\n",
    "        )\n",
    "        columns_list = redcap_dfcalib.columns\n",
    "        ############################################\n",
    "        # redcap for calibration doesn't exist yet #\n",
    "        ############################################\n",
    "\n",
    "        for column in columns_list:\n",
    "            # print(column)\n",
    "            # print((redcap_dfcalib.loc[redcap_dfcalib['participant'] == p]).iloc[0][column]) # this is incorrect for now, replace with calibration data later\n",
    "            if column == 'daily_check_in_date':\n",
    "                A = np.chararray(resample_ratio, itemsize=15, unicode=True)\n",
    "                A[:] = (redcap_dfcalib.loc[redcap_dfcalib['participant'] == p]).iloc[0][\n",
    "                    column\n",
    "                ]  # this is incorrect for now, replace with calibration data later\n",
    "                calib_df[column] = A\n",
    "            else:\n",
    "                calib_df[column] = (\n",
    "                    np.ones(resample_ratio)\n",
    "                    * (redcap_dfcalib.loc[redcap_dfcalib['participant'] == p]).iloc[0][\n",
    "                        column\n",
    "                    ]\n",
    "                )  # this is incorrect for now, replace with calibration data later\n",
    "\n",
    "        p_df = pd.concat([p_df, calib_df], ignore_index=True, sort=False)\n",
    "        # print('display calib_df after calib')\n",
    "        # display(calib_df)\n",
    "        # display(calib_df)\n",
    "\n",
    "        # save the data\n",
    "        print('Pickling processed data for participant ' + str(p) + ' ...')\n",
    "        with open(radwear_path + 'formatted_p_' + str(p) + '.pkl', 'wb') as f:\n",
    "            pickle.dump(p_df, f)\n",
    "        print('data pickled...')\n",
    "\n",
    "    else:\n",
    "        print('processed data for participant ' + str(p) + ' is already available!')\n",
    "        # load the data\n",
    "        with open(radwear_path +'formatted_p_'+str(p)+'.pkl', 'rb') as f:\n",
    "            p_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combining into 1 DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_p_df = pd.DataFrame()\n",
    "\n",
    "for p in list_of_participants:\n",
    "    p_path = radwear_path\n",
    "    # p_df = pd.DataFrame()\n",
    "\n",
    "    # check if file exist\n",
    "    a = (\n",
    "        'available.'\n",
    "        if os.path.isfile(p_path + '/p_' + str(p) + '.pkl')\n",
    "        else ' not available.'\n",
    "    )\n",
    "    print('processed data for participant ' + str(p) + ' is ' + a)\n",
    "    print('Loading...')\n",
    "    with open(p_path + '/p_' + str(p) + '.pkl', 'rb') as f:\n",
    "        p_df = pickle.load(f)\n",
    "    print('participant ' + str(p) + ' data loaded.')\n",
    "    print('-----------------------')\n",
    "    all_p_df = pd.concat([all_p_df, p_df], ignore_index=True, sort=False)\n",
    "    display(p_df.sample(3))\n",
    "    all_p_df.columns\n",
    "print('pickling all participants file...')\n",
    "all_p_df.to_pickle(radwear_path + 'all_participants.pkl')\n",
    "print('pickling completed. ')\n",
    "print('DF for all participants is saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
