{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUTDATED\n",
    "look at version without 't2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, json\n",
    "import process_redcap \n",
    "from scipy import signal\n",
    "import os.path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get RedCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redcap dict exists\n",
      "redcap df exists\n",
      "redcap df pickle loaded\n"
     ]
    }
   ],
   "source": [
    "radwear_path = '/projects/bbnp/Vansh/data/RADWear/'\n",
    "redcap_path = radwear_path+'REDCap responses/'\n",
    "\n",
    "# load all participant meta data\n",
    "with open(radwear_path+'all_p_metadata.json', 'rb') as f:\n",
    "            all_p_metadata = json.load(f)\n",
    "# load all participant redcap data\n",
    "redcap_df = process_redcap.process_redcap(redcap_path,all_p_metadata['list of participant IDs'])\n",
    "redcap_dfcalib = redcap_df.copy() # a cheat for now since i don't have redcap data for calibration\n",
    "columns_list = redcap_dfcalib.columns\n",
    "\n",
    "###################\n",
    "# these are temporary fixes for the redcap data. if main redcap data is updated, these fixes should be removed\n",
    "# #fixed for p7 \n",
    "#redcap_df.at[28, 'daily_check_in_date'] = '2022-09-12'\n",
    "#redcap_df.at[30, 'daily_check_in_date'] = '2022-09-13'\n",
    "#redcap_df.iloc[29], redcap_df.iloc[30] =  redcap_df.iloc[30].copy(), redcap_df.iloc[29].copy()\n",
    "#redcap_df.drop([44], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original list of participants:  [4, 7, 9, 12, 14, 16, 17, 18, 21]\n",
      "list of participants to process:  [7, 9, 12, 14, 16, 17, 21]\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "radwear_path = '/projects/bbnp/Vansh/data/RADWear/'\n",
    "# load the data\n",
    "\n",
    "#import all_p_metadata.json\n",
    "with open(radwear_path + 'all_p_metadata.json') as f:\n",
    "    all_p_metadata = json.load(f)\n",
    "\n",
    "list_of_participants = all_p_metadata['list of participant IDs'].copy()\n",
    "print('original list of participants: ',list_of_participants)\n",
    "list_of_participants.remove(4) # remote calibration only participants for now until i add the redcap data for them\n",
    "list_of_participants.remove(18) # remote calibration only participants for now until i add the redcap data for them\n",
    "\n",
    "\n",
    "print('list of participants to process: ', list_of_participants)\n",
    "print('-----------------------')\n",
    "fs = all_p_metadata['fs']\n",
    "\n",
    "rot_anx_dict = {'calibration': 0, 'LA': 1, 'HA': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/bbnp/Vansh/data/RADWear/Participant 7\n"
     ]
    }
   ],
   "source": [
    "p = 7\n",
    "p_path = radwear_path + 'Participant '+str(p)\n",
    "print(p_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 17, 21]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_participants[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load each P data and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file for participant 16 is available.\n",
      "participant 16 data loaded.\n",
      "-----------------------\n",
      "Participant:  16\n",
      "-----------------------\n",
      "p_data.keys():  dict_keys(['calib', 'LA', 'HA'])\n",
      "-----------------------\n",
      "la days:  0\n",
      "ha days:  9\n",
      "-----------------------\n",
      "Done with day  0 date:  2023-08-28  of LA rotation for participant  16\n",
      "Done with day  1 date:  2023-08-29  of LA rotation for participant  16\n",
      "Done with day  2 date:  2023-08-30  of LA rotation for participant  16\n",
      "Done with day  3 date:  2023-08-31  of LA rotation for participant  16\n",
      "Done with day  4 date:  2023-09-01  of LA rotation for participant  16\n",
      "Done with day  5 date:  2023-09-05  of LA rotation for participant  16\n",
      "Done with day  6 date:  2023-09-06  of LA rotation for participant  16\n",
      "Done with day  7 date:  2023-09-07  of LA rotation for participant  16\n",
      "Done with day  8 date:  2023-09-08  of LA rotation for participant  16\n",
      "Pickling processed data for participant 16 ...\n",
      "data pickled...\n",
      "pickle file for participant 17 is available.\n",
      "participant 17 data loaded.\n",
      "-----------------------\n",
      "Participant:  17\n",
      "-----------------------\n",
      "p_data.keys():  dict_keys(['calib', 'LA', 'HA'])\n",
      "-----------------------\n",
      "la days:  10\n",
      "ha days:  10\n",
      "-----------------------\n",
      "Done with day  0 date:  8/7/2023  of LA rotation for participant  17\n",
      "Done with day  1 date:  8/8/2023  of LA rotation for participant  17\n",
      "Done with day  2 date:  8/9/2023  of LA rotation for participant  17\n",
      "Done with day  3 date:  8/10/2023  of LA rotation for participant  17\n",
      "Done with day  4 date:  8/11/2023  of LA rotation for participant  17\n",
      "Done with day  5 date:  8/14/2023  of LA rotation for participant  17\n",
      "Done with day  6 date:  8/15/2023  of LA rotation for participant  17\n",
      "Done with day  7 date:  8/16/2023  of LA rotation for participant  17\n",
      "Done with day  9 date:  8/18/2023  of LA rotation for participant  17\n",
      "Done with day  0 date:  8/7/2023  of HA rotation for participant  17\n",
      "Done with day  1 date:  8/8/2023  of HA rotation for participant  17\n",
      "Done with day  2 date:  8/9/2023  of HA rotation for participant  17\n",
      "Done with day  3 date:  8/10/2023  of HA rotation for participant  17\n",
      "Done with day  4 date:  8/11/2023  of HA rotation for participant  17\n",
      "Done with day  5 date:  8/14/2023  of HA rotation for participant  17\n",
      "Done with day  6 date:  8/15/2023  of HA rotation for participant  17\n",
      "Done with day  7 date:  8/16/2023  of HA rotation for participant  17\n",
      "Done with day  8 date:  8/17/2023  of HA rotation for participant  17\n",
      "Done with day  9 date:  8/18/2023  of HA rotation for participant  17\n",
      "Pickling processed data for participant 17 ...\n",
      "data pickled...\n",
      "pickle file for participant 21 is available.\n",
      "participant 21 data loaded.\n",
      "-----------------------\n",
      "Participant:  21\n",
      "-----------------------\n",
      "p_data.keys():  dict_keys(['calib', 'LA', 'HA'])\n",
      "-----------------------\n",
      "la days:  0\n",
      "ha days:  9\n",
      "-----------------------\n",
      "Done with day  0 date:  2023-08-21  of LA rotation for participant  21\n",
      "Done with day  1 date:  2023-08-22  of LA rotation for participant  21\n",
      "Done with day  2 date:  2023-08-23  of LA rotation for participant  21\n",
      "Done with day  3 date:  2023-08-24  of LA rotation for participant  21\n",
      "Done with day  4 date:  2023-08-25  of LA rotation for participant  21\n",
      "Done with day  5 date:  2023-08-28  of LA rotation for participant  21\n",
      "Done with day  6 date:  2023-08-29  of LA rotation for participant  21\n",
      "Done with day  7 date:  2023-08-30  of LA rotation for participant  21\n",
      "Done with day  8 date:  2023-08-31  of LA rotation for participant  21\n",
      "Pickling processed data for participant 21 ...\n",
      "data pickled...\n"
     ]
    }
   ],
   "source": [
    "#all_p = {}\n",
    "#load each participant's data\n",
    "force_update = True\n",
    "for p in list_of_participants[4:]:\n",
    "    p_path = radwear_path + 'Participant '+str(p)\n",
    "    p_df = pd.DataFrame()\n",
    "    \n",
    "    #check if file exist\n",
    "    a = 'available.' if os.path.isfile(p_path + '/p_'+str(p)+'.pkl') else ' not available.'\n",
    "    print('pickle file for participant '+str(p)+ ' is '+ a)\n",
    "    with open(p_path +  '/p_'+str(p)+'.pkl', 'rb') as f:\n",
    "        p_data = pickle.load(f)\n",
    "    print ('participant '+str(p)+ ' data loaded.')\n",
    "    print('-----------------------') \n",
    "    #all_p[p] = p_data ## this takes too much memory so i will just load each p when needed\n",
    "    if not (os.path.isfile(radwear_path +'p_'+str(p)+'.pkl')) or force_update:\n",
    "\n",
    "        print('Participant: ', p)\n",
    "        print('-----------------------')    \n",
    "        print('p_data.keys(): ', p_data.keys())\n",
    "        print('-----------------------')\n",
    "        print('la days: ', len(p_data['HA'].keys()))\n",
    "        print('ha days: ', len(p_data['LA'].keys()))\n",
    "        print('-----------------------')\n",
    "        #print('p_data[calib].keys(): ', p_data['calib'].keys())\n",
    "        # e4 contains BVP, EDA, TEMP, ACC, IBI, HR, HRV, tags\n",
    "        # hx contains ECG, ACC, BR\n",
    "        p_redcap = redcap_df.loc[redcap_df['participant'] == p] # redcap data for participant p\n",
    "\n",
    "\n",
    "        ## this is for participant p \n",
    "\n",
    "        for day in list(p_data['LA'].keys()): \n",
    "\n",
    "            proceed1 = bool(len(p_data['LA'][day])) and bool(all_p_metadata[str(p)]['RedCap available'][0][day])\n",
    "            \n",
    "            if proceed1:\n",
    "                \n",
    "                LA_df = p_data['LA'][day]['BVP'].copy()\n",
    "                del p_data['LA'][day]['BVP']\n",
    "                resample_ratio = round(len(LA_df))\n",
    "\n",
    "                LA_df['ECG'] = signal.resample(p_data['LA'][day]['ECG']['ECG'], resample_ratio)\n",
    "                del p_data['LA'][day]['ECG']\n",
    "                #LA_df['BVP'] = signal.resample(p_data['LA'][day]['BVP']['BVP'], resample_ratio)\n",
    "                LA_df['EDA'] = signal.resample(p_data['LA'][day]['EDA']['EDA'], resample_ratio)\n",
    "                del p_data['LA'][day]['EDA']\n",
    "                LA_df['TEMP'] = signal.resample(p_data['LA'][day]['TEMP']['Temp'], resample_ratio)\n",
    "                del p_data['LA'][day]['TEMP']\n",
    "                LA_df['BR'] = signal.resample(p_data['LA'][day]['BR']['breathing_rate'], resample_ratio)\n",
    "                del p_data['LA'][day]['BR']\n",
    "                LA_df['ACCx_hx'] = signal.resample(p_data['LA'][day]['ACC_hx']['Acceleration_X'], resample_ratio)\n",
    "                del p_data['LA'][day]['ACC_hx']['Acceleration_X']\n",
    "                LA_df['ACCy_hx'] = signal.resample(p_data['LA'][day]['ACC_hx']['Acceleration_Y'], resample_ratio)\n",
    "                del p_data['LA'][day]['ACC_hx']['Acceleration_Y']\n",
    "                LA_df['ACCz_hx'] = signal.resample(p_data['LA'][day]['ACC_hx']['Acceleration_Z'], resample_ratio)\n",
    "                del p_data['LA'][day]['ACC_hx']['Acceleration_Z']   \n",
    "                LA_df['ACCx_e4'] = signal.resample(p_data['LA'][day]['ACC_e4']['Acc_X'], resample_ratio)\n",
    "                del p_data['LA'][day]['ACC_e4']['Acc_X']\n",
    "                LA_df['ACCy_e4'] = signal.resample(p_data['LA'][day]['ACC_e4']['Acc_Y'], resample_ratio)\n",
    "                del p_data['LA'][day]['ACC_e4']['Acc_Y']\n",
    "                LA_df['ACCz_e4'] = signal.resample(p_data['LA'][day]['ACC_e4']['Acc_Z'], resample_ratio)\n",
    "                del p_data['LA'][day]['ACC_e4']['Acc_Z']\n",
    "                LA_df['rot_label'] = rot_anx_dict['LA']* np.ones(resample_ratio)\n",
    "                LA_df['calib_label'] = np.zeros(resample_ratio)\n",
    "\n",
    "                for column in columns_list:\n",
    "                    if column == 'daily_check_in_date':\n",
    "                        A = np.chararray(resample_ratio,itemsize=15,unicode=True)\n",
    "                        A[:] = ((redcap_df.loc[redcap_df['participant'] == p]).iloc[day][column])\n",
    "                        LA_df[column] = A\n",
    "                    else:\n",
    "                        LA_df[column] = np.ones(resample_ratio)* (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][column] \n",
    "                \n",
    "                print('Done with day ', day, 'date: ',(redcap_df.loc[redcap_df['participant'] == p]).iloc[day]['daily_check_in_date'],' of LA rotation for participant ', p)               \n",
    "                p_df = pd.concat([p_df, LA_df], ignore_index=True, sort=False)\n",
    "                #print('display LA_df after LA_df')\n",
    "                #display(LA_df)\n",
    "                \n",
    "\n",
    "        for day in list(p_data['HA'].keys()):\n",
    "            proceed2 = bool(len(p_data['HA'][day])) and bool(all_p_metadata[str(p)]['RedCap available'][1][day])\n",
    "            if proceed2:\n",
    "                    \n",
    "                \n",
    "                HA_df = p_data['HA'][day]['BVP'].copy()\n",
    "                del p_data['HA'][day]['BVP']\n",
    "                resample_ratio = round(len(HA_df))\n",
    "                HA_df['ECG'] = signal.resample(p_data['HA'][day]['ECG']['ECG'], resample_ratio)\n",
    "                del p_data['HA'][day]['ECG']\n",
    "                #HA_df['BVP'] = signal.resample(p_data['HA'][day]['BVP']['BVP'], resample_ratio)\n",
    "\n",
    "                HA_df['EDA'] = signal.resample(p_data['HA'][day]['EDA']['EDA'], resample_ratio)\n",
    "                del p_data['HA'][day]['EDA']\n",
    "                HA_df['TEMP'] = signal.resample(p_data['HA'][day]['TEMP']['Temp'], resample_ratio)\n",
    "                del p_data['HA'][day]['TEMP']\n",
    "                HA_df['BR'] = signal.resample(p_data['HA'][day]['BR']['breathing_rate'], resample_ratio)\n",
    "                del p_data['HA'][day]['BR']\n",
    "                HA_df['ACCx_hx'] = signal.resample(p_data['HA'][day]['ACC_hx']['Acceleration_X'], resample_ratio)\n",
    "                del p_data['HA'][day]['ACC_hx']['Acceleration_X']\n",
    "                HA_df['ACCy_hx'] = signal.resample(p_data['HA'][day]['ACC_hx']['Acceleration_Y'], resample_ratio)\n",
    "                del p_data['HA'][day]['ACC_hx']['Acceleration_Y']\n",
    "                HA_df['ACCz_hx'] = signal.resample(p_data['HA'][day]['ACC_hx']['Acceleration_Z'], resample_ratio)\n",
    "                del p_data['HA'][day]['ACC_hx']['Acceleration_Z']\n",
    "                HA_df['ACCx_e4'] = signal.resample(p_data['HA'][day]['ACC_e4']['Acc_X'], resample_ratio)\n",
    "                del p_data['HA'][day]['ACC_e4']['Acc_X']\n",
    "                HA_df['ACCy_e4'] = signal.resample(p_data['HA'][day]['ACC_e4']['Acc_Y'], resample_ratio)\n",
    "                del p_data['HA'][day]['ACC_e4']['Acc_Y']\n",
    "                HA_df['ACCz_e4'] = signal.resample(p_data['HA'][day]['ACC_e4']['Acc_Z'], resample_ratio)\n",
    "                del p_data['HA'][day]['ACC_e4']['Acc_Z']\n",
    "                HA_df['rot_label'] = rot_anx_dict['HA']* np.ones(resample_ratio) \n",
    "                HA_df['calib_label'] = np.zeros(resample_ratio)\n",
    "\n",
    "                for column in columns_list:\n",
    "                    if column == 'daily_check_in_date':\n",
    "                        A = np.chararray(resample_ratio,itemsize=15,unicode=True)\n",
    "                        A[:] = ((redcap_df.loc[redcap_df['participant'] == p]).iloc[day][column])\n",
    "                        HA_df[column] = A\n",
    "                        \n",
    "                    else:\n",
    "                        HA_df[column] = np.ones(resample_ratio)* (redcap_df.loc[redcap_df['participant'] == p]).iloc[day][column] \n",
    "                        \n",
    "                print('Done with day ', day, 'date: ',(redcap_df.loc[redcap_df['participant'] == p]).iloc[day]['daily_check_in_date'],' of HA rotation for participant ', p)\n",
    "                p_df = pd.concat([p_df, HA_df], ignore_index=True, sort=False)\n",
    "                #print('display HA_df after HA_df')\n",
    "                #display(HA_df)\n",
    "                \n",
    "\n",
    "        \n",
    "        calib_df = p_data['calib']['BVP'].copy()\n",
    "        del p_data['calib']['BVP']\n",
    "        resample_ratio = round(len(calib_df))\n",
    "        \n",
    "        calib_df['ECG'] = signal.resample(p_data['calib']['ECG']['ECG'], resample_ratio)\n",
    "        del p_data['calib']['ECG']\n",
    "        #calib_df['BVP'] = signal.resample(p_data['calib']['BVP']['BVP'], resample_ratio)\n",
    "        calib_df['EDA'] = signal.resample(p_data['calib']['EDA']['EDA'], resample_ratio)\n",
    "        del p_data['calib']['EDA']\n",
    "        calib_df['TEMP'] = signal.resample(p_data['calib']['TEMP']['Temp'], resample_ratio)\n",
    "        del p_data['calib']['TEMP']\n",
    "        calib_df['BR'] = signal.resample(p_data['calib']['BR']['breathing_rate'], resample_ratio)\n",
    "        del p_data['calib']['BR']\n",
    "        calib_df['ACCx_hx'] = signal.resample(p_data['calib']['ACC_hx']['Acceleration_X'], resample_ratio)\n",
    "        del p_data['calib']['ACC_hx']['Acceleration_X']\n",
    "        calib_df['ACCy_hx'] = signal.resample(p_data['calib']['ACC_hx']['Acceleration_Y'], resample_ratio)\n",
    "        del p_data['calib']['ACC_hx']['Acceleration_Y']\n",
    "        calib_df['ACCz_hx'] = signal.resample(p_data['calib']['ACC_hx']['Acceleration_Z'], resample_ratio)\n",
    "        del p_data['calib']['ACC_hx']['Acceleration_Z']\n",
    "        calib_df['ACCx_e4'] = signal.resample(p_data['calib']['ACC_e4']['Acc_X'], resample_ratio)\n",
    "        del p_data['calib']['ACC_e4']['Acc_X']\n",
    "        calib_df['ACCy_e4'] = signal.resample(p_data['calib']['ACC_e4']['Acc_Y'], resample_ratio)\n",
    "        del p_data['calib']['ACC_e4']['Acc_Y']\n",
    "        calib_df['ACCz_e4'] = signal.resample(p_data['calib']['ACC_e4']['Acc_Z'], resample_ratio)\n",
    "        del p_data['calib']['ACC_e4']['Acc_Z']\n",
    "        calib_df['rot_label'] = rot_anx_dict['calibration']* np.ones(resample_ratio)\n",
    "        calib_df['calib_label'] = np.ones(resample_ratio) #complete later\n",
    "        redcap_dfcalib = redcap_df # a cheat for now since i don't have redcap data for calibration\n",
    "        columns_list = redcap_dfcalib.columns\n",
    "        ############################################\n",
    "        # redcap for calibration doesn't exist yet #\n",
    "        ############################################\n",
    "\n",
    "        for column in columns_list:\n",
    "            #print(column)\n",
    "            #print((redcap_dfcalib.loc[redcap_dfcalib['participant'] == p]).iloc[0][column]) # this is incorrect for now, replace with calibration data later\n",
    "            if column == 'daily_check_in_date':\n",
    "                A = np.chararray(resample_ratio,itemsize=15,unicode=True)\n",
    "                A[:] = ((redcap_dfcalib.loc[redcap_dfcalib['participant'] == p]).iloc[0][column]) # this is incorrect for now, replace with calibration data later\n",
    "                calib_df[column] = A\n",
    "            else:\n",
    "                calib_df[column] = np.ones(resample_ratio)* (redcap_dfcalib.loc[redcap_dfcalib['participant'] == p]).iloc[0][column] # this is incorrect for now, replace with calibration data later\n",
    "\n",
    "\n",
    "        p_df = pd.concat([p_df, calib_df], ignore_index=True, sort=False)\n",
    "        #print('display calib_df after calib')\n",
    "        #display(calib_df)\n",
    "        #display(calib_df)\n",
    "\n",
    "\n",
    "\n",
    "        # save the data\n",
    "        print('Pickling processed data for participant '+str(p)+ ' ...')\n",
    "        with open(radwear_path +'p_'+str(p)+'.pkl', 'wb') as f:\n",
    "            pickle.dump(p_df, f)\n",
    "        print('data pickled...')\n",
    "    else:\n",
    "        print('processed data for participant '+str(p)+ ' is available.')\n",
    "        #load the data\n",
    "        #with open(radwear_path +'p_'+str(p)+'.pkl', 'rb') as f:\n",
    "        #    p_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HA_df.columns)\n",
    "display(LA_df.columns)\n",
    "display(calib_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for p in list_of_participants:\n",
    "    p_path = radwear_path + 'Participant '+str(p)\n",
    "    p_df = pd.DataFrame()\n",
    "    \n",
    "    #check if file exist\n",
    "    a = 'available.' if os.path.isfile(p_path + '/p_'+str(p)+'.pkl') else ' not available.'\n",
    "    print('processed data for participant '+str(p)+ ' is '+ a)\n",
    "    print('Loading...')\n",
    "    with open(p_path +  '/p_'+str(p)+'.pkl', 'rb') as f:\n",
    "        p_data = pickle.load(f)\n",
    "    print ('participant '+str(p)+ ' data loaded.')\n",
    "    print('-----------------------') \n",
    "    \n",
    "    #all_p[p] = p_data ## this takes too much memory so i will just load each p when needed\n",
    "    print('participant ',p)\n",
    "    \n",
    "    if  not (os.path.isfile(radwear_path +'p_'+str(p)+'.pkl')):\n",
    "        print('processing participant '+str(p)+ ' data...')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(radwear_path)\n",
    "os.listdir(radwear_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 7\n",
    "#p = 18\n",
    "p_df = [] \n",
    "p_df = pd.read_pickle(radwear_path +'p_'+str(p)+'.pkl')\n",
    "display(p_data)\n",
    "\n",
    "sys.getsizeof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFwesad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
